{
  
    
        "post0": {
            "title": "정규 표현식3",
            "content": "정규식을 컴파일할 때 다음 옵션을 사용할 수 있다. DOTALL(S) - .이 줄바꿈 문자를 포함하여 모든 문자와 매치할 수 있도록 한다. | IGNORCASE(I) - 대소문자에 관계없이 매치할 수 있도록 한다. | MULTILINE(M) - 여러줄과 매치할 수 있도록 한다.(^,$ 메타 문자의 사용과 관계거가 있는 옵션이다.) | VERBOSE (X) - verbose 모드를 사용할 수 있도록 한다. (정규식을 보기 편하게 만들 수 있고 주석 등을 사용할 수 있게 된다.) | . | 옵션을 사용할 때는 re.DOTALL처럼 전체 옵션 이름을 써도 되고, re.S처럼 약어를 써도 된다. | 위에서 괄호 안에 있는 문자들이 약어이다. | . . DOTALL(S) .메타 문자는 줄바꿈 문자( n)를 제외한 모든 문자와 매치되는 규칙이 있다. 만약 n 문자도 포함하여 매치하고 싶다면 re.DOTALL 또는 re.S 옵션을 사용해 정규식을 컴파일하면 된다. | . | . import re p = re.compile(&#39;a.b&#39;) m = p.match(&#39;a nb&#39;) print(m) . None . 정규식이 a.b인 경우 문자연 a nb는 매치되지 않음을 알 수 있다. 왜냐하면 n은 .메타문자와 매치되지 않기 때문이다. n 문자와도 매치되게 하려면 다음과 같이 re.DOTALL 옵션을 사용해야 한다. | . p = re.compile(&#39;a.b&#39;,re.DOTALL) m = p.match(&#39;a nb&#39;) print(m) . &lt;re.Match object; span=(0, 3), match=&#39;a nb&#39;&gt; . 보통 re.DOTALL 옵션은 여러 줄로 이루어진 문자열에서 n에 상관없이 검색할 때 많이 사용한다. | . . IGNORECASE(I) re.IGNORECASE 또는 re.I 옵션은 대소문자와 구별 없이 매치를 수행할 때 사용하는 옵션이다. | . | . p = re.compile(&#39;[a-z]+&#39;,re.I) p.match(&#39;python&#39;) p.match(&#39;Python&#39;) p.match(&#39;pYthon&#39;) . &lt;re.Match object; span=(0, 6), match=&#39;pYthon&#39;&gt; . [a-z]+ 정규식은 소문자만을 의미하지만 re.I 옵션으로 대소문자 구별 없이 매치된다. | . . MULTILINE(M) re.MULTILINE 또는 re.M 옵션은 조금 후에 설명할 메타 문자인 ^,$ 와 연관된 옵션이다. 이 메타 문자에 대해 간단히 설명하자면 ^는 문자열의 처음을 의미하고 $는 문자열의 마지막을 의미한다. 예를 들어 정규식이 ^python인 경우 문자열의 처음은 항상 python으로 시작해야 매치되고, 만약 정규식이 python$ 이라면 문자열의 마지막은 항상 python으로 끝나야 매치된다는 의미이다. | . | . import re p = re.compile(&#39;^python s w+&#39;) data = &quot;&quot;&quot;python one life is too short python two you need python python three&quot;&quot;&quot; print(p.findall(data)) . [&#39;python one&#39;] . 정규식 &#39;^python s w+&#39;은 python이라는 문자열로 시작하고 그 뒤에 whitespace, 그 뒤에 단어가 와야 한다는 의미이다. 검색할 문자열 data는 여러 줄로 이루어져 있다. | 따라서 위와 같은 결과가 반환되는 것이다. | ^ 메타 문자에 의해 python이라는 문자열을 사용한 첫 번째 줄만 매치된 것이다. | 하지만 ^ 메타 문자를 문자열 전체의 처음이 아니라 각 라인의 처음으로 인식시키고 싶은 경우도 있을 것이다. 이럴 때 사용할 수 있는 옵션이 바로 re.MULTILINE 또는 re.M이다. | . import re p = re.compile(&quot;^python s w+&quot;, re.MULTILINE) data = &quot;&quot;&quot;python one life is too short python two you need python python three&quot;&quot;&quot; print(p.findall(data)) . [&#39;python one&#39;, &#39;python two&#39;, &#39;python three&#39;] . re.MULTILINE 옵션으로 인해 ^ 메타 문자가 문자열 전체가 아닌 각 줄의 처음이라는 의미를 갖게 되었다. 이 스크립트를 실행하면 위와 같은 결과가 출력된다.- | 즉 re.MULTILINE 옵션은 ^, $ 메타 문자를 문자열의 각 줄마다 적용해 주는 것이다. | . . VERBOSE(X) 이해하기 어려운 정규식을 주석 또는 줄 단위로 구분할 수 있다면 얼마나 보기 좋고 이해하기 쉬울 것이다. 이를 위해 re.VERBOSE 또는 re.X 옵션을 사용하면 된다. | 다음 예를 보자 | . | . charref = re.compile(r&#39;&amp;[#](0[0-7]+|[0-9]+|x[0-9a-fA-F]+);&#39;) . 이해하기 어렵다 | 다음 예를 보자 | . charref = re.compile(r&quot;&quot;&quot; &amp;[#] # Start of a numeric entity reference ( 0[0-7]+ # Octal form | [0-9]+ # Decimal form | x[0-9a-fA-F]+ # Hexadecimal form ) ; # Trailing semicolon &quot;&quot;&quot;, re.VERBOSE) . 첫 번째와 두 번째 예를 비교해 보면 컴파일 된 패턴 객체인 charref는 모두 동일한 역할을 한다. 하지만 정규식이 복잡할 경우 두 번째처럼 주석을 적고 여러줄로 표현하는 것이 훨씬 가독성이 좋다는 것을 알 수 있다. | re.VERBOSE 옵션을 사용하면 문자열에 사용된 whitespace는 컴파일할 때 제거된다.(단 []안에 사용된 whitespace는 제외) 그리고 줄 단위로 # 기호를 사용하여 주석문을 작성할 수 있다. | . . 백슬래시 issue 정규 표현식을 파이썬에서 사용할 때 혼란을 주는 요소가 한 가지 있는데 바로 백슬래시이다. | 예를 들어보자 | &quot; selection&quot;문자열을 찾기 위한 정규식을 만든다고 가정해보자 selection . | 이 정규식은 s 문자가 whitespace로 해석되어 의도한 대로 매치가 이루어지지 않는다. | 위 표현은 다음과 동일한 의미이다. [ t n r f v]ection . | 의도한 대로 매치하고 싶다면 다음과 같이 변경해야 한다. section . | 즉 위 정규식에서 사용한 문자가 문자열 자체임을 알려주기 위해 백슬래시 2개를 상요하여 이스케이프 처리를 해야한다 | 다라서 위 정규식을 컴파일 하려면 다음과 같이 작성하는 것이 올바르다 | . | . p = re.compile(&#39; section&#39;) . 그러나 이처럼 정규식을 만들어서 컴파일하면 실제 파이썬 정규식 엔진에는 파이썬 문자열 리터럴 규칙에 따라 이 로 변경되어 section이 전달된다. | 결국 정규식 엔진에 문자를 전달하려면 파이썬은 처럼 백슬래시를 4개 사용해야한다. | . p = re.compile(&#39; section&#39;) . 이렇게 해야만 원하는 결과를 얻을 수 있다. | 상당히 복잡해보이기에 파이썬 정규식에는 Raw String 규칙이 생겨나게 되었다. | 즉 컴파일해야 하는 정규식이 Raw String임을 알려줄 수 있도록 파이썬 문법을 만든 것이다. | 방법은 다음과 같다. | . p = re.compile(r&#39; section&#39;) . 위와 같이 정규식 문자열 앞에 r문자를 삽입하면 이 정규식은 RawString 규칙에 의하여 백슬래시 2개 대신 1개만 써도 2개를 쓴 것과 동일한 의미를 갖게 된다. | 만약 백슬래시를 사용하지 않는 정규식이라면 r의 유무에 상관없이 동일한 정규식이 될 것이다. | .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/31/meta.html",
            "relUrl": "/2022/01/31/meta.html",
            "date": " • Jan 31, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "정규 표현식2",
            "content": "파이썬은 정규 표현식을 지원하기 위해 re(regular expression) 모듈을 제공한다. re모듈은 파이썬을 설치할 때 자동으로 설치는 기본 라이브러리로 사용방법은 다음과 같다. | . import re p = re.compile(&#39;ab*&#39;) . re.compile을 사용하여 정규 표현식을 컴파일한다. re.compile의 결과로 돌려주는 객체 p를 사용하여 그 이후의 작업을 수행할 것이다. 정규식을 컴파일할 때 특정 옵션을 주는 것도 가능한데 이에 대해서는 뒤에서 자세히 살펴본다 | 패턴이란 정규식을 컴파일한 결과이다. | . | . 정규식을 이용한 문자열 검색 이제 컴파일된 패턴 객체를 사용하여 문자열 검색을 수행해보자. 컴파일된 패턴 객체는 다음과 같은 4가지 메서드를 제공한다. match() : 문자열의 처음부터 정규식과 매치되는지 조사한다. | search() : 문자열 전체를 검색하여 정규식과 매치되는지 조사한다. | findall() : 정규식과 매치되는 모든 문자열을 리스트로 돌려준다. | finditer() : 정규식과 매치되는 모든 문자열을 반복 가능한 객체로 돌려준다. | . | match, search는 정규식과 매치될 때 match 객체를 돌려주고, 매치되지 않을 땐 None을 돌려준다. 이들 메서드에 대한 간단한 예를 들어보자 match 객체란 정규식의 검색 결과로 돌려주는 객체이다 | . | 우선 다음과 같은 패턴을 만들어보자 | . | . import re p = re.compile(&#39;[a-z]+&#39;) . match : match 메서드는 문자열의 처음부터 정규식과 매치되는지 조사한다. 위 패턴에 match 메서드를 수행해보자 | . m = p.match(&quot;python&quot;) print(m) m.group() . &lt;re.Match object; span=(0, 6), match=&#39;python&#39;&gt; . &#39;python&#39; . &quot;python&quot; 문자열은 [a-z]+ 정규식에 부합되므로 match 객체를 돌려준다. | . m = p.match(&quot;3 python&quot;) print(m) # m.group() # None이라서 반환하지 못함 . None . &quot;3 python&quot; 문자열은 처음에 나오는 문자 3이 [a-z]+에 부합되지 않으므로 None을 반환해준다. | match의 결과로 match객체 또는 None을 돌려주기 때문에 파이썬 정규식 프로그램은 보통 다음과 같은 흐름으로 작성한다. | . p = re.compile(정규표현식) m = p.match(&#39;string goes here&#39;) if m: print(&#39;match found: &#39;, m.group()) else : print(&#39;No match&#39;) . if는 bool형을 읽는다. 즉, m이 뭔가 있단 얘기는 이를 True로 해석할 것이고 m이 None이 나오면 False와 진배 다를 바 없기 때문에 else로 넘어가서 수행할 것이다. | . search : 컴파일된 패턴 객체 p를 가지고 이번에는 search 메서드를 수행해보자 | . m = p.search(&#39;python&#39;) print(m) . &lt;re.Match object; span=(0, 6), match=&#39;python&#39;&gt; . match 메서드와 동일하게 매치된다. | . m = p.search(&#39;3 python&#39;) print(m) . &lt;re.Match object; span=(2, 8), match=&#39;python&#39;&gt; . &#39;3 python&#39; 문자열의 첫 번째 문자는 &#39;3&#39;이지만 search는 문자열의 처음부터 검색하는 것이 아니라 문자열 전체를 검색하기 때문에 &#39;3&#39; 이후의 &#39;python&#39; 문자열과 매치된다. | 이렇듯 match 메서드와 search 메서드는 문자열의 처음부터 검색할지의 여부에 따라 다르게 사용해야 한다. | . . findall | . result = p.findall(&#39;life is too short&#39;) print(result) . [&#39;life&#39;, &#39;is&#39;, &#39;too&#39;, &#39;short&#39;] . &#39;life is too short&#39;문자열의 각 단어들을 각각 [a-z]+ 정규식과 매치해서 리스트로 돌려준다. | . . finditer | . result = p.finditer(&quot;life is too short&quot;) print(result) for r in result: print(r) . &lt;callable_iterator object at 0x000001E8A6348790&gt; &lt;re.Match object; span=(0, 4), match=&#39;life&#39;&gt; &lt;re.Match object; span=(5, 7), match=&#39;is&#39;&gt; &lt;re.Match object; span=(8, 11), match=&#39;too&#39;&gt; &lt;re.Match object; span=(12, 17), match=&#39;short&#39;&gt; . finditer는 findall과 동일하지만 그 결과를 이용하여 반복 가능한 객체(iterator object)로 돌려준다. 반복 가능한 객체가 포함하는 각각의 요소는 match 객체이다. | . match 객체의 메서드 : match 메서드와 search 메서드를 수행한 결과로 돌려준 match 객체에 대해 알아보자. 앞에서 정규식을 사용한 문자열 검색을 수행하면서 아마도 다음과 같은 궁금증이 생겼을 것이다. | 왜냐면 반환해준 결과가 알아먹기 힘들게 나왔기 때문이다 어떤 문자열이 매치 되었는가? | 매치된 문자열의 인덱스는 어디서부터 어디까지인가? | . | match객체의 메서드를 사용하면 이 같은 궁금증을 해결할 수 있다. group() : 매치된 문자열을 돌려준다. | start() : 매치된 문자열의 시작 위치를 돌려준다. | end() : 매치된 문자열의 끝 위치를 돌려준다. | span() : 매치된 문자열의 (시작, 끝)에 해당하는 튜플을 돌려준다. | 예를 들어 확인해보자 | . | . m = p.match(&quot;python&quot;) print(m.group()) print(m.start()) print(m.end()) print(m.span()) . python 0 6 (0, 6) . match 객체의 start()의 결과값은 항상 0일 수 밖에 없다 | search도 확인해보자 | . m = p.search(&quot;3 python&quot;) print(m.group()) print(m.start()) print(m.end()) print(m.span()) . python 2 8 (2, 8) . 모듈 단위로 수행하기 지금까지 우리는 re.compile을 사용하여 컴파일된 패턴 객체로 그 이후의 작업을 수행했다. re 모듈은 이것을 좀 축약한 형태로 사용할 수 있는 방법을 제공한다. p = re.compile(&#39;[a-z]+&#39;) m = p.match(&quot;python&quot;) . | 이렇게 사용했다면m = re.match(&#39;[a-z]+&#39;, &quot;python&quot;) . | 이처럼 사용하면 컴파일과 match 메서드를 한 번에 수행할 수 있다. | 보통 한 번 만든 패턴 객체를 여러번 사용할 때는 이 방법보다 첫 번째 방법이 유용할 때가 있다. | . | . 컴파일 옵션은 다음시간 | .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/29/intro4.html",
            "relUrl": "/2022/01/29/intro4.html",
            "date": " • Jan 29, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "정규 표현식1",
            "content": ". 정규 표현식에서 사용하는 메타 문자에는 다음과 같은 것이 있다. 메타 문자란 원래 그 문자가 가진 뜻이 아닌 특별한 용도로 사용하는 문자를 말한다. 다음과 같은 것들이 있다. . ^ $ * + ? { } [ ] | ( )) | . | 정규 표현식에 위 메타 문자를 사용하면 특별한 의미를 갖게 된다. | 지금부터 가장 간단한 정규 표현식부터 시작해 각 메타 문자의 의미와 사용법을 알아보자 | . | . . 문자 클래스 [] 가장 먼저 살펴본 메타 문자는 바로 문자 클래스인 []이다. 문자 클래스로 만들어진 정규식은 &quot;[] 사이의 문자들과 매치&quot;라는 의미를 가진다. 문자 클래스를 만드는 메타 문자인 [] 사이에는 어떤 문자도 들어갈 수 있다. | . | 즉 정규 표현식이 [abc]라면 이 표현식의 의미는 &quot;a,b,c 중 한 개의 문자와 매치&quot;를 뜻한다. | 이해를 돕기 위해 문자열 &quot;a&quot;,&quot;before&quot;,&quot;dude&quot;가 정규식[abc]와 어떻게 매치되는지 살펴보자 &quot;a&quot;는 정규식과 일치하는 문자인 &quot;a&quot;가 있으므로 매치 | &quot;before&quot;는 정규식과 일치하는 문자인 &quot;b&quot;가 있으므로 매치 | &quot;dude&quot;는 정규식과 일치하는 문자인 a,b,c중 어느 하나도 포함하고 있지 않으므로 매치되지 않음 | . | [] 안의 두 문자 사이에 하이픈을 사용하면 두 문자 사이의 범위(From-To)를 의미한다. | 예를 들어 [a-c]라는 정규 표현식은 [abc]와 동일하고 [0-5]는 [012345]와 동일하다.(위에서 문자 클래스를 만드는 메타 문자인 []사이에는 어떤 문자도 들어갈 수 있다고 했다.) | 다음은 하이픈(-)을 사용한 문자 클래스의 사용 예이다. [a-zA-Z] : 알파벳 모두 | [0-9] : 숫자 | . | 문자클래스([])안에는 어떤 문자나 메타 문자도 사용할 수 있지만 주의해야 할 메타 문자가 1가지 있다. 그것은 바로 ^인데, 문자 클래스 안에 ^메타 문자를 사용할 경우에는 반대(not)라는 의미를 갖는다. 예를 들어 [^0-9]라는 정규 표현식은 숫자가 아닌 문자만 매치된다. | . | . 자주 사용하는 문자 클래스에 대해 알아보자 [0-9] 또는 [a-zA-Z]등은 무척 자주 사용하는 정규 표현식이다. 이렇게 자주 사용하는 정규식은 별도의 표기법으로 표현할 수 있다. 다음을 기억해 두자 d : 숫자와 매치, 따라서 [0-9]와 동일한 표현식이다. | D : 숫자가 아닌 것과 매치, 따라서 [^0-9]와 동일한 표현식이다. | s : whitespace 문자와 매치, [ t n r f v]와 동일한 표현식이다. 맨 앞의 빈 칸은 공백문자(space)를 의미한다. | S : whitespace 문자가 아닌 것과 매치, [^ t n r f v]와 동일한 표현식이다. | w : 문자+숫자와 매치,[a-zA-Z0-9]와 동일한 표현식이다. | W : 문자+숫자가 아닌 문자와 매치, [^a-zA-Z0-9]와 동일한 표현식이다. | . | . | . . Dot(.) 정규 표현식의 Dot(.) 메타 문자는 줄바꿈 문자인 n을 제외한 모든 문자와 매치됨을 의미한다. (참고 : 정규식을 작성할 때 re.DOTALL 옵션을 주면 n 문자와도 매치된다.) | 다음 정규식을 보자a.b . | 위 정규식의 의미 : &quot;a+모든문자+b&quot; | 즉 a와 b라는 문자 사이에 어떤 문자가 들어가도 모두 매치된다는 의미이다. | 간단한 예를 들어보자 | 문자열 &quot;aab&quot;,&quot;a0c&quot;,&quot;abc&quot;가 정규식 a.b와 어떻게 매치되는지 살펴보자 &quot;aab&quot;는 가운데 문자 &quot;a&quot;가 모든 문자를 의미하는 .과 일치하므로 정규식과 매치된다. | &quot;a0b&quot;는 가운데 문자 &quot;0&quot;이 모든 문자를 의미하는 .과 일치하므로 정규식과 매치된다. | &quot;abc&quot;는 &quot;a&quot;문자와 &quot;b&quot;문자 사이에 어떤 문자라도 하나는 있어야 하는 이 정규식과 일치하지 않으므로 매치되지 않는다. | 비교해보자 : 만약 다음과 같은 정규식이 있다고 해보자a[.]b . | 이 정규식의 의미 : &quot;a+Dot(.)문자+b&quot; | 따라서 해당 정규식은&quot;a.b&quot; 문자열과 매치되고, &quot;a0b&quot; 문자열과는 매치되지 않는다. | 앞에서 살펴본 문자 클래스[] 내에 Dot(.) 메타 문자가 사용된다면 이것은 &quot;모든 문자&quot;라는 의미가 아닌 문자 &quot;.&quot; 그대로를 의미한다. 혼동하지 않도록 주의하자. | . | . | . . 반복(*) . ca*t . 위 정규식에는 반복을 의미하는 메타 문자가 사용되었다. 여기에서 사용한 은 *바로 앞에 있는 문자 a가 0부터 무한대로 반복될 수 있따는 의미이다.(사실 메모리 제한으로 2억 개 정도만 가능하다고 한다.) | 즉 다음과 같은 문자열이 매치될 수 있을 것이다. ct : &quot;a&quot;가 0번 반복되어 매치 | cat : &quot;a&quot;가 0번 이상 반복되어 매치 | caaat : &quot;a&quot;가 0번 이상 즉 3번 반복되어 매치 | . | . | 반복(+) . 반복을 나타내는 또 다른 메타 문자로 +가 있다. 하지만 +는 최소 1번 이상 반복될 때 사용한다. 즉, *가 반복 횟수 0부터라면 +는 반복 횟수 1부터인 것이다. | 다음 정규식을 보자 ca+t . | 이 정규식의 의미는 다음과 같다. | &quot;c + a(1번 이상 반복) + t&quot; | 따라서 위 정규식은 다음과 매치될 수 있을 것이다. | ct는 &quot;a&quot;가 0번 반복되어 매치되지 않고 cat,caaat는 1번이상 반복되었기 때문에 매치될 수 있다. | 그런데 반복횟수를 제한하고 싶을 수 있다. | . | 반복({m,n},?) . {} 이 메타문자를 사용하면 반복 횟수를 고정할 수 있다. {m,n} 정규식을 사용하면 반복 횟수가 m부터 n까지 매치할 수 있다. 또한 m또는 n을 생략할 수도 있다. 만약 {3,}처럼 사용하면 반복횟수가 3이상인 경우이고 {,3}처럼 사용하면 반복 횟수가 3이하를 의미한다. 생력된 m은 0과 동일하며, 생략된 n은 무한개의 의미를 갖는다. {1,}은 +와 동일하고 {0,}은 *와 동일하다. | . | 몇 가지 정규식을 살펴보자 | ca{2}t : &quot;c + a(반드시 2번 반복) + t&quot; | ca{2,5}t : &quot;c + a(2~5회 반복) + t&quot; | . | ? . 반복은 아니지만 이와 비슷한 개념이다. | ?이 의미하는 것은 {0,1}이다.ab?c . | 이 정규식의 의미 : &quot;a + b(있어도 되고 없어도 된다) + c&quot; | . | . . , +, ? 메타 문자는 모두 {m, n} 형태로 고쳐 쓰는 것이 가능하지만 가급적 이해하기 쉽고 표현도 간결한 , +, ? 메타 문자를 사용하는 것이 좋다. | .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/27/meta.html",
            "relUrl": "/2022/01/27/meta.html",
            "date": " • Jan 27, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "2022/01/16/SUN",
            "content": "qqplot . qqplot은 분위수대조도로 불리는 정규모집단 가정을 하는 방법 중 하나이다. | 수집 데이터를 표준정규분포의 분위수와 비교하여 그리는 그래프로 데이터의 정규성 가정에 대한 검토를 가능하게 한다. | 모집단이 정규성을 따른다면 직선의 형태로 그려지게 된다. | qqplot은 표준정규분포의 분위수와 이에 대응하는 분포(측정한 실제 데이터의 분포)의 분위수를 x,y 좌표평면에 plotting 하는 방법이다. | x축, y축 및 (대략) 예상 분위수에 따라 정렬된 샘플 값을 살펴볼 때, 그림의 일부 섹션에 있는 값이 이론적인 분포에서 가정하는 것보다 더 집중되어 있는지 아니면 덜 집중되어 있는지를 확인할 수 있다. | 정규 분포와 마찬가지로 t 분포의 모양도 매끄럽다. | 정규 분포와 마찬가지로 t 분포도 대칭형이다. | 표준 정규 분포(또는 z 분포)와 마찬가지로 t 분포의 평균도 0이다. | 정규 분포에서는 모집단 표준편차를 알고 있다고 가정하지만 t 분포에서는 이러한 가정을 내리지 않는다. | t 분포는 자유도에 의해 정의된다. 자유도는 표본 크기와 관련이 있다. | 자유도가 높은 곡선은 더 높이 올라가고 꼬리가 얇습니다 | t 분포는 모집단 표준편차를 알 수 없거나 두 가지 모두 적용될 때 작은 표본 크기에 가장 유용하다. | 표본 크기가 커질수록 t 분포가 정규 분포와 비슷해진다. | 표본 표준편차를 근거로 한다. | z분포 더 두꺼운 꼬리를 갖는다. | 자유도가 클수록 곡선이 z 분포에 더 근접 | 일반적으로 표본크기가 30이상인 경우 t분포 대신 z분포를 사용할 수 있다. 예를 들어 자유도가 30정도이면 t분포는 z분포와 매우 유사. | 표본 평균을 이용해 정규 분포의 평균을 해석할 때 주로 사용 | qqplot은 두 변수간의 분포를 비교하기 위해 사용되는 그래프이다. 일반적으로 주어진 데이터와 정규분포를 비교하여 정규분포 가정이 적정한지에 대해 검토하는 데 널리 사용된다. 하지만 정규분포에 국한할 필요없이 두 분포의 비교에 활용할 수 있다. | . import numpy as np import matplotlib.pyplot as plt import pandas as pd import seaborn as sns from scipy import stats . np.random.seed(990310) x=np.random.normal(size=1000,loc=2,scale=1.5) y=stats.t.rvs(df=10,size=1000)/np.sqrt(10/8)*1.5 + 2 . - 우리가 관측한 $x_1, dots,x_{1000}$이 $N(2,1.5^2)$에서 나온 샘플인지 알아보고 싶다고 해보자 . (1) 관측한 값을 순서대로 나열하여 $x_{(1)},x_{(2)}, dots, x_{(1000)}$을 만든다. . x[:2] . array([-2.57649273, -2.52319957]) . $x_1=0.2315625, quad x_2=2.28762212$ | . x.sort() . 오름차순으로 정렬中, 내림차순은 reverse=True입력 | . x[:2] . array([-2.57649273, -2.52319957]) . $x_{(1)}= -2.57649273, quad x_{(2)}=-2.52319957$ | . (2) 파이썬이나 R로 $N(2,1.5^2)$에서 1000개의 정규분포를 생성. 그리고 순서대로 나열하여 $ tilde{x}_{(1)}, tilde{x}_{(2)}, dots, tilde{x}_{(1000)}$를 만든다. . (3) $x_{(1)} approx tilde{x}_{(1)}, dots , x_{(1000)} approx tilde{x}_{(1000)}$ 이면 x는 정규분포일것 . - 그런데 $ tilde{x}_{(1)}, tilde{x}_{(2)}, dots, tilde{x}_{(1000)}$은 시뮬레이션을 할때마다 다른값이 나올테니까 불안정한 느낌이 든다. $ to$ 이론적인 값을 계산하자. . xx는 표준정규분포 . xx = (x-np.mean(x)) / np.std(x,ddof=1) # ddof = 모표준편차 xx[:2] . array([-3.08865331, -3.0520052 ]) . 실제우리가 관측한값 | . print(stats.norm.ppf(0.001)) print(stats.norm.ppf(0.002)) . -3.090232306167813 -2.878161739095483 . 이론적인 값 | . - 분위수 . m=[i/1000 for i in np.arange(1000)+1] . q=[] for i in range(len(m)): q=q+[stats.norm.ppf(m[i])] . q[:2] . [-3.090232306167813, -2.878161739095483] . - $xx approx q$ 을 확인하기 위해서 $(q,q)$그래프와 $(q,xx)$의 그래프를 그려서 겹쳐보자. . plt.plot(q,xx,&#39;o&#39;) plt.plot(q,q,&#39;-&#39;) . [&lt;matplotlib.lines.Line2D at 0x240ce9d3070&gt;] . 해석: 점들이 주황색선 근처에 모여있을수록 정규분포에 가깝다. | . 결국은 &quot;정규분포 sample에서 나온 게 맞는 것 같다&quot;라는 결론 | . - 아래와 같이 쉽게 그릴수도 있다. (우리가 그린그림과 조금 다르게 보인다) . - stats.probplot 함수를 통해서 주어진 데이터와 정규분포(다른 분포도 가능)와의 qqplot을 그릴 수 있다. . _ = stats.probplot(x,plot=plt) . 자세히보면 조금 다르게 그려지긴 하는데 이는 $m=( frac{1}{1000}, dots, frac{999}{1000}, frac{1000}{1000})$와 같이 계산하지 않고 약간 보정한값을 계산하기 때문임 | stats.probplot? 을 통하여 확인한 결과 아래와 같은 코드로 구현됨### 보정하는방법1 n=len(xx) m=[((i+1)-0.3175)/(n+0.365) for i in range(n)] m[-n]=0.5**(1/n) m[0]=1-m[-n] . | 프로그램에 따라서 아래와 같이 보정하는 경우도 있음### 보정하는방법2 m=[(i-3/8)/(n+1/4) for i in np.arange(1000)+1] . | 또 자세히보면 stats.probplot은 y축에 표준화 전의 x값이 있음을 알 수 있음. | . - 정규분포와 t분포의 qqplot을 그려서 비교해보자. . 정규분포 | . _ = stats.probplot(x,plot=plt) . t분포: 푸른점들이 대체로 붉은선위에 놓여있는듯 하지만 양끝단에서는 그렇지 않다. (중앙부근은 정규분포와 비슷하지만, 꼬리부분은 정규분포와 확실히 다르다) | 왼쪽꼬리: 이론적으로 나와야 할 값보다 더 작은값이 실제로 관측됨 | 오른쪽꼬리: 이론적으로 나와야 할 값보다 더 큰값이 실제로 관측됨 | 해석: 이 분포는 정규분포보다 두꺼운 꼬리를 가진다. | . _ = stats.probplot(y,plot=plt) # t분포 . fig , (ax1,ax2) = plt.subplots(1,2) . _ = stats.probplot(x,plot=ax1) _ = stats.probplot(y,plot=ax2) . fig . fig.set_figwidth(8) . fig . ax1.set_title(&#39;normal dist&#39;) ax2.set_title(&#39;t dist&#39;) . Text(0.5, 1.0, &#39;t dist&#39;) . fig . - 박스플랏, 히스토그램, qqplot을 그려보자. . fig, ax =plt.subplots(2,3) . ax . array([[&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;], [&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;]], dtype=object) . (ax1,ax2,ax3), (ax4,ax5,ax6) = ax . sns.boxplot(x,ax=ax1) sns.histplot(x,kde=True,ax=ax2) _ = stats.probplot(x,plot=ax3) sns.boxplot(y,ax=ax4) sns.histplot(y,kde=True,ax=ax5) _ = stats.probplot(y,plot=ax6) . C: Users ehfus Anaconda3 envs dv2021 lib site-packages seaborn _decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. warnings.warn( C: Users ehfus Anaconda3 envs dv2021 lib site-packages seaborn _decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. warnings.warn( . fig . fig.set_figwidth(10) fig.set_figheight(8) fig.tight_layout() . fig . Appendix(&#48512;&#47197;) : &#48516;&#50948;&#49688;&#47484; &#44396;&#54616;&#45716; &#45796;&#50577;&#54620;&#48169;&#48277; . m = [i/1000 for i in np.arange(1000)+1] . $m= big { frac{i}{1000}: i in {1,2,3, dots,1000 } big }= big { frac{1}{1000}, frac{2}{1000}, dots, frac{1000}{1000} big }$ | . - 방법1 . q=[] for i in range(len(m)): q=q+[stats.norm.ppf(m[i])] q[:5] . [-3.090232306167813, -2.878161739095483, -2.7477813854449926, -2.6520698079021954, -2.575829303548901] . - 방법2 . q=[stats.norm.ppf(m[i]) for i in range(len(m))] . q[:5] . [-3.090232306167813, -2.878161739095483, -2.7477813854449926, -2.6520698079021954, -2.575829303548901] . - 방법3 . q=list(map(stats.norm.ppf, m)) q[:5] . [-3.090232306167813, -2.878161739095483, -2.7477813854449926, -2.6520698079021954, -2.575829303548901] . - 방법4 . stats.norm.ppf(m)[:5] . array([-3.09023231, -2.87816174, -2.74778139, -2.65206981, -2.5758293 ]) .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/16/intro2.html",
            "relUrl": "/2022/01/16/intro2.html",
            "date": " • Jan 16, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "2022/01/15/SAT",
            "content": "import numpy as np import pandas as pd import warnings from IPython.display import HTML def show(fig): return HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;,include_mathjax=False, config=dict({&#39;scrollZoom&#39;:False}))) . pie . &#50696;&#51228;1 (matplotlib) . df = pd.read_csv(&#39;https://raw.githubusercontent.com/kalilurrahman/datasets/main/mobilephonemktshare2020.csv&#39;) df # 지금은 인덱스가 0~12로 되어있으니 아래 셀에서 Date로 인덱스를 변경해줄것임 . Date Samsung Apple Huawei Xiaomi Oppo Mobicel Motorola LG Others Realme Google Nokia Lenovo OnePlus Sony Asus . 0 2019-10 | 31.49 | 22.09 | 10.02 | 7.79 | 4.10 | 3.15 | 2.41 | 2.40 | 9.51 | 0.54 | 2.35 | 0.95 | 0.96 | 0.70 | 0.84 | 0.74 | . 1 2019-11 | 31.36 | 22.90 | 10.18 | 8.16 | 4.42 | 3.41 | 2.40 | 2.40 | 9.10 | 0.78 | 0.66 | 0.97 | 0.97 | 0.73 | 0.83 | 0.75 | . 2 2019-12 | 31.37 | 24.79 | 9.95 | 7.73 | 4.23 | 3.19 | 2.50 | 2.54 | 8.13 | 0.84 | 0.75 | 0.90 | 0.87 | 0.74 | 0.77 | 0.70 | . 3 2020-01 | 31.29 | 24.76 | 10.61 | 8.10 | 4.25 | 3.02 | 2.42 | 2.40 | 7.55 | 0.88 | 0.69 | 0.88 | 0.86 | 0.79 | 0.80 | 0.69 | . 4 2020-02 | 30.91 | 25.89 | 10.98 | 7.80 | 4.31 | 2.89 | 2.36 | 2.34 | 7.06 | 0.89 | 0.70 | 0.81 | 0.77 | 0.78 | 0.80 | 0.69 | . 5 2020-03 | 30.80 | 27.03 | 10.70 | 7.70 | 4.30 | 2.87 | 2.35 | 2.28 | 6.63 | 0.93 | 0.73 | 0.72 | 0.74 | 0.78 | 0.76 | 0.66 | . 6 2020-04 | 30.41 | 28.79 | 10.28 | 7.60 | 4.20 | 2.75 | 2.51 | 2.28 | 5.84 | 0.90 | 0.75 | 0.69 | 0.71 | 0.80 | 0.76 | 0.70 | . 7 2020-05 | 30.18 | 26.72 | 10.39 | 8.36 | 4.70 | 3.12 | 2.46 | 2.19 | 6.31 | 1.04 | 0.70 | 0.73 | 0.77 | 0.81 | 0.78 | 0.76 | . 8 2020-06 | 31.06 | 25.26 | 10.69 | 8.55 | 4.65 | 3.18 | 2.57 | 2.11 | 6.39 | 1.04 | 0.68 | 0.74 | 0.75 | 0.77 | 0.78 | 0.75 | . 9 2020-07 | 30.95 | 24.82 | 10.75 | 8.94 | 4.69 | 3.46 | 2.45 | 2.03 | 6.41 | 1.13 | 0.65 | 0.76 | 0.74 | 0.76 | 0.75 | 0.72 | . 10 2020-08 | 31.04 | 25.15 | 10.73 | 8.90 | 4.69 | 3.38 | 2.39 | 1.96 | 6.31 | 1.18 | 0.63 | 0.74 | 0.72 | 0.75 | 0.73 | 0.70 | . 11 2020-09 | 30.57 | 24.98 | 10.58 | 9.49 | 4.94 | 3.50 | 2.27 | 1.88 | 6.12 | 1.45 | 0.63 | 0.74 | 0.67 | 0.81 | 0.69 | 0.67 | . 12 2020-10 | 30.25 | 26.53 | 10.44 | 9.67 | 4.83 | 2.54 | 2.21 | 1.79 | 6.04 | 1.55 | 0.63 | 0.69 | 0.65 | 0.85 | 0.67 | 0.64 | . df.set_index(&#39;Date&#39;) . Samsung Apple Huawei Xiaomi Oppo Mobicel Motorola LG Others Realme Google Nokia Lenovo OnePlus Sony Asus . Date . 2019-10 31.49 | 22.09 | 10.02 | 7.79 | 4.10 | 3.15 | 2.41 | 2.40 | 9.51 | 0.54 | 2.35 | 0.95 | 0.96 | 0.70 | 0.84 | 0.74 | . 2019-11 31.36 | 22.90 | 10.18 | 8.16 | 4.42 | 3.41 | 2.40 | 2.40 | 9.10 | 0.78 | 0.66 | 0.97 | 0.97 | 0.73 | 0.83 | 0.75 | . 2019-12 31.37 | 24.79 | 9.95 | 7.73 | 4.23 | 3.19 | 2.50 | 2.54 | 8.13 | 0.84 | 0.75 | 0.90 | 0.87 | 0.74 | 0.77 | 0.70 | . 2020-01 31.29 | 24.76 | 10.61 | 8.10 | 4.25 | 3.02 | 2.42 | 2.40 | 7.55 | 0.88 | 0.69 | 0.88 | 0.86 | 0.79 | 0.80 | 0.69 | . 2020-02 30.91 | 25.89 | 10.98 | 7.80 | 4.31 | 2.89 | 2.36 | 2.34 | 7.06 | 0.89 | 0.70 | 0.81 | 0.77 | 0.78 | 0.80 | 0.69 | . 2020-03 30.80 | 27.03 | 10.70 | 7.70 | 4.30 | 2.87 | 2.35 | 2.28 | 6.63 | 0.93 | 0.73 | 0.72 | 0.74 | 0.78 | 0.76 | 0.66 | . 2020-04 30.41 | 28.79 | 10.28 | 7.60 | 4.20 | 2.75 | 2.51 | 2.28 | 5.84 | 0.90 | 0.75 | 0.69 | 0.71 | 0.80 | 0.76 | 0.70 | . 2020-05 30.18 | 26.72 | 10.39 | 8.36 | 4.70 | 3.12 | 2.46 | 2.19 | 6.31 | 1.04 | 0.70 | 0.73 | 0.77 | 0.81 | 0.78 | 0.76 | . 2020-06 31.06 | 25.26 | 10.69 | 8.55 | 4.65 | 3.18 | 2.57 | 2.11 | 6.39 | 1.04 | 0.68 | 0.74 | 0.75 | 0.77 | 0.78 | 0.75 | . 2020-07 30.95 | 24.82 | 10.75 | 8.94 | 4.69 | 3.46 | 2.45 | 2.03 | 6.41 | 1.13 | 0.65 | 0.76 | 0.74 | 0.76 | 0.75 | 0.72 | . 2020-08 31.04 | 25.15 | 10.73 | 8.90 | 4.69 | 3.38 | 2.39 | 1.96 | 6.31 | 1.18 | 0.63 | 0.74 | 0.72 | 0.75 | 0.73 | 0.70 | . 2020-09 30.57 | 24.98 | 10.58 | 9.49 | 4.94 | 3.50 | 2.27 | 1.88 | 6.12 | 1.45 | 0.63 | 0.74 | 0.67 | 0.81 | 0.69 | 0.67 | . 2020-10 30.25 | 26.53 | 10.44 | 9.67 | 4.83 | 2.54 | 2.21 | 1.79 | 6.04 | 1.55 | 0.63 | 0.69 | 0.65 | 0.85 | 0.67 | 0.64 | . df.set_index(&#39;Date&#39;).plot.pie(y=&#39;Apple&#39;) . &lt;AxesSubplot:ylabel=&#39;Apple&#39;&gt; . . df.set_index(&#39;Date&#39;).plot.pie(x=&#39;2019-10&#39;) . 이렇게 하면 y축도 내놓으라해서 그냥 아래로 T변환후에 시각화해주는 듯 . . df.set_index(&#39;Date&#39;).T . Date 2019-10 2019-11 2019-12 2020-01 2020-02 2020-03 2020-04 2020-05 2020-06 2020-07 2020-08 2020-09 2020-10 . Samsung 31.49 | 31.36 | 31.37 | 31.29 | 30.91 | 30.80 | 30.41 | 30.18 | 31.06 | 30.95 | 31.04 | 30.57 | 30.25 | . Apple 22.09 | 22.90 | 24.79 | 24.76 | 25.89 | 27.03 | 28.79 | 26.72 | 25.26 | 24.82 | 25.15 | 24.98 | 26.53 | . Huawei 10.02 | 10.18 | 9.95 | 10.61 | 10.98 | 10.70 | 10.28 | 10.39 | 10.69 | 10.75 | 10.73 | 10.58 | 10.44 | . Xiaomi 7.79 | 8.16 | 7.73 | 8.10 | 7.80 | 7.70 | 7.60 | 8.36 | 8.55 | 8.94 | 8.90 | 9.49 | 9.67 | . Oppo 4.10 | 4.42 | 4.23 | 4.25 | 4.31 | 4.30 | 4.20 | 4.70 | 4.65 | 4.69 | 4.69 | 4.94 | 4.83 | . Mobicel 3.15 | 3.41 | 3.19 | 3.02 | 2.89 | 2.87 | 2.75 | 3.12 | 3.18 | 3.46 | 3.38 | 3.50 | 2.54 | . Motorola 2.41 | 2.40 | 2.50 | 2.42 | 2.36 | 2.35 | 2.51 | 2.46 | 2.57 | 2.45 | 2.39 | 2.27 | 2.21 | . LG 2.40 | 2.40 | 2.54 | 2.40 | 2.34 | 2.28 | 2.28 | 2.19 | 2.11 | 2.03 | 1.96 | 1.88 | 1.79 | . Others 9.51 | 9.10 | 8.13 | 7.55 | 7.06 | 6.63 | 5.84 | 6.31 | 6.39 | 6.41 | 6.31 | 6.12 | 6.04 | . Realme 0.54 | 0.78 | 0.84 | 0.88 | 0.89 | 0.93 | 0.90 | 1.04 | 1.04 | 1.13 | 1.18 | 1.45 | 1.55 | . Google 2.35 | 0.66 | 0.75 | 0.69 | 0.70 | 0.73 | 0.75 | 0.70 | 0.68 | 0.65 | 0.63 | 0.63 | 0.63 | . Nokia 0.95 | 0.97 | 0.90 | 0.88 | 0.81 | 0.72 | 0.69 | 0.73 | 0.74 | 0.76 | 0.74 | 0.74 | 0.69 | . Lenovo 0.96 | 0.97 | 0.87 | 0.86 | 0.77 | 0.74 | 0.71 | 0.77 | 0.75 | 0.74 | 0.72 | 0.67 | 0.65 | . OnePlus 0.70 | 0.73 | 0.74 | 0.79 | 0.78 | 0.78 | 0.80 | 0.81 | 0.77 | 0.76 | 0.75 | 0.81 | 0.85 | . Sony 0.84 | 0.83 | 0.77 | 0.80 | 0.80 | 0.76 | 0.76 | 0.78 | 0.78 | 0.75 | 0.73 | 0.69 | 0.67 | . Asus 0.74 | 0.75 | 0.70 | 0.69 | 0.69 | 0.66 | 0.70 | 0.76 | 0.75 | 0.72 | 0.70 | 0.67 | 0.64 | . df.set_index(&#39;Date&#39;).T.plot.pie(y=&#39;2019-10&#39;,legend=False) . &lt;AxesSubplot:ylabel=&#39;2019-10&#39;&gt; . df.set_index(&#39;Date&#39;).T.plot.pie(legend=False,subplots=True,layout=(4,4),figsize=(20,20)) . array([[&lt;AxesSubplot:ylabel=&#39;2019-10&#39;&gt;, &lt;AxesSubplot:ylabel=&#39;2019-11&#39;&gt;, &lt;AxesSubplot:ylabel=&#39;2019-12&#39;&gt;, &lt;AxesSubplot:ylabel=&#39;2020-01&#39;&gt;], [&lt;AxesSubplot:ylabel=&#39;2020-02&#39;&gt;, &lt;AxesSubplot:ylabel=&#39;2020-03&#39;&gt;, &lt;AxesSubplot:ylabel=&#39;2020-04&#39;&gt;, &lt;AxesSubplot:ylabel=&#39;2020-05&#39;&gt;], [&lt;AxesSubplot:ylabel=&#39;2020-06&#39;&gt;, &lt;AxesSubplot:ylabel=&#39;2020-07&#39;&gt;, &lt;AxesSubplot:ylabel=&#39;2020-08&#39;&gt;, &lt;AxesSubplot:ylabel=&#39;2020-09&#39;&gt;], [&lt;AxesSubplot:ylabel=&#39;2020-10&#39;&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;]], dtype=object) . boxplot . - plotly, matplotlib 백엔드 모두 지원 . &#50696;&#51228;1(matplotlib) . df = pd.read_csv(&#39;https://raw.githubusercontent.com/kalilurrahman/datasets/main/mobilephonemktshare2020.csv&#39;) df . Date Samsung Apple Huawei Xiaomi Oppo Mobicel Motorola LG Others Realme Google Nokia Lenovo OnePlus Sony Asus . 0 2019-10 | 31.49 | 22.09 | 10.02 | 7.79 | 4.10 | 3.15 | 2.41 | 2.40 | 9.51 | 0.54 | 2.35 | 0.95 | 0.96 | 0.70 | 0.84 | 0.74 | . 1 2019-11 | 31.36 | 22.90 | 10.18 | 8.16 | 4.42 | 3.41 | 2.40 | 2.40 | 9.10 | 0.78 | 0.66 | 0.97 | 0.97 | 0.73 | 0.83 | 0.75 | . 2 2019-12 | 31.37 | 24.79 | 9.95 | 7.73 | 4.23 | 3.19 | 2.50 | 2.54 | 8.13 | 0.84 | 0.75 | 0.90 | 0.87 | 0.74 | 0.77 | 0.70 | . 3 2020-01 | 31.29 | 24.76 | 10.61 | 8.10 | 4.25 | 3.02 | 2.42 | 2.40 | 7.55 | 0.88 | 0.69 | 0.88 | 0.86 | 0.79 | 0.80 | 0.69 | . 4 2020-02 | 30.91 | 25.89 | 10.98 | 7.80 | 4.31 | 2.89 | 2.36 | 2.34 | 7.06 | 0.89 | 0.70 | 0.81 | 0.77 | 0.78 | 0.80 | 0.69 | . 5 2020-03 | 30.80 | 27.03 | 10.70 | 7.70 | 4.30 | 2.87 | 2.35 | 2.28 | 6.63 | 0.93 | 0.73 | 0.72 | 0.74 | 0.78 | 0.76 | 0.66 | . 6 2020-04 | 30.41 | 28.79 | 10.28 | 7.60 | 4.20 | 2.75 | 2.51 | 2.28 | 5.84 | 0.90 | 0.75 | 0.69 | 0.71 | 0.80 | 0.76 | 0.70 | . 7 2020-05 | 30.18 | 26.72 | 10.39 | 8.36 | 4.70 | 3.12 | 2.46 | 2.19 | 6.31 | 1.04 | 0.70 | 0.73 | 0.77 | 0.81 | 0.78 | 0.76 | . 8 2020-06 | 31.06 | 25.26 | 10.69 | 8.55 | 4.65 | 3.18 | 2.57 | 2.11 | 6.39 | 1.04 | 0.68 | 0.74 | 0.75 | 0.77 | 0.78 | 0.75 | . 9 2020-07 | 30.95 | 24.82 | 10.75 | 8.94 | 4.69 | 3.46 | 2.45 | 2.03 | 6.41 | 1.13 | 0.65 | 0.76 | 0.74 | 0.76 | 0.75 | 0.72 | . 10 2020-08 | 31.04 | 25.15 | 10.73 | 8.90 | 4.69 | 3.38 | 2.39 | 1.96 | 6.31 | 1.18 | 0.63 | 0.74 | 0.72 | 0.75 | 0.73 | 0.70 | . 11 2020-09 | 30.57 | 24.98 | 10.58 | 9.49 | 4.94 | 3.50 | 2.27 | 1.88 | 6.12 | 1.45 | 0.63 | 0.74 | 0.67 | 0.81 | 0.69 | 0.67 | . 12 2020-10 | 30.25 | 26.53 | 10.44 | 9.67 | 4.83 | 2.54 | 2.21 | 1.79 | 6.04 | 1.55 | 0.63 | 0.69 | 0.65 | 0.85 | 0.67 | 0.64 | . - 점유율의 차이를 구하자. . df.set_index(&#39;Date&#39;).diff() . Samsung Apple Huawei Xiaomi Oppo Mobicel Motorola LG Others Realme Google Nokia Lenovo OnePlus Sony Asus . Date . 2019-10 NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 2019-11 -0.13 | 0.81 | 0.16 | 0.37 | 0.32 | 0.26 | -0.01 | 0.00 | -0.41 | 0.24 | -1.69 | 0.02 | 0.01 | 0.03 | -0.01 | 0.01 | . 2019-12 0.01 | 1.89 | -0.23 | -0.43 | -0.19 | -0.22 | 0.10 | 0.14 | -0.97 | 0.06 | 0.09 | -0.07 | -0.10 | 0.01 | -0.06 | -0.05 | . 2020-01 -0.08 | -0.03 | 0.66 | 0.37 | 0.02 | -0.17 | -0.08 | -0.14 | -0.58 | 0.04 | -0.06 | -0.02 | -0.01 | 0.05 | 0.03 | -0.01 | . 2020-02 -0.38 | 1.13 | 0.37 | -0.30 | 0.06 | -0.13 | -0.06 | -0.06 | -0.49 | 0.01 | 0.01 | -0.07 | -0.09 | -0.01 | 0.00 | 0.00 | . 2020-03 -0.11 | 1.14 | -0.28 | -0.10 | -0.01 | -0.02 | -0.01 | -0.06 | -0.43 | 0.04 | 0.03 | -0.09 | -0.03 | 0.00 | -0.04 | -0.03 | . 2020-04 -0.39 | 1.76 | -0.42 | -0.10 | -0.10 | -0.12 | 0.16 | 0.00 | -0.79 | -0.03 | 0.02 | -0.03 | -0.03 | 0.02 | 0.00 | 0.04 | . 2020-05 -0.23 | -2.07 | 0.11 | 0.76 | 0.50 | 0.37 | -0.05 | -0.09 | 0.47 | 0.14 | -0.05 | 0.04 | 0.06 | 0.01 | 0.02 | 0.06 | . 2020-06 0.88 | -1.46 | 0.30 | 0.19 | -0.05 | 0.06 | 0.11 | -0.08 | 0.08 | 0.00 | -0.02 | 0.01 | -0.02 | -0.04 | 0.00 | -0.01 | . 2020-07 -0.11 | -0.44 | 0.06 | 0.39 | 0.04 | 0.28 | -0.12 | -0.08 | 0.02 | 0.09 | -0.03 | 0.02 | -0.01 | -0.01 | -0.03 | -0.03 | . 2020-08 0.09 | 0.33 | -0.02 | -0.04 | 0.00 | -0.08 | -0.06 | -0.07 | -0.10 | 0.05 | -0.02 | -0.02 | -0.02 | -0.01 | -0.02 | -0.02 | . 2020-09 -0.47 | -0.17 | -0.15 | 0.59 | 0.25 | 0.12 | -0.12 | -0.08 | -0.19 | 0.27 | 0.00 | 0.00 | -0.05 | 0.06 | -0.04 | -0.03 | . 2020-10 -0.32 | 1.55 | -0.14 | 0.18 | -0.11 | -0.96 | -0.06 | -0.09 | -0.08 | 0.10 | 0.00 | -0.05 | -0.02 | 0.04 | -0.02 | -0.03 | . df.set_index(&#39;Date&#39;).diff().dropna().boxplot(figsize=(20,5)) . &lt;AxesSubplot:&gt; . &#50696;&#51228;2 (plotly) . - 위와 동일한 그림을 plotly backend로도 그릴수 있음 (plotly가 조금 융통성이 있음) . # show(fig) . - 회사를 색깔별로 구분하여 범주를 만들고 싶다? . df.set_index(&#39;Date&#39;).diff().dropna() . Samsung Apple Huawei Xiaomi Oppo Mobicel Motorola LG Others Realme Google Nokia Lenovo OnePlus Sony Asus . Date . 2019-11 -0.13 | 0.81 | 0.16 | 0.37 | 0.32 | 0.26 | -0.01 | 0.00 | -0.41 | 0.24 | -1.69 | 0.02 | 0.01 | 0.03 | -0.01 | 0.01 | . 2019-12 0.01 | 1.89 | -0.23 | -0.43 | -0.19 | -0.22 | 0.10 | 0.14 | -0.97 | 0.06 | 0.09 | -0.07 | -0.10 | 0.01 | -0.06 | -0.05 | . 2020-01 -0.08 | -0.03 | 0.66 | 0.37 | 0.02 | -0.17 | -0.08 | -0.14 | -0.58 | 0.04 | -0.06 | -0.02 | -0.01 | 0.05 | 0.03 | -0.01 | . 2020-02 -0.38 | 1.13 | 0.37 | -0.30 | 0.06 | -0.13 | -0.06 | -0.06 | -0.49 | 0.01 | 0.01 | -0.07 | -0.09 | -0.01 | 0.00 | 0.00 | . 2020-03 -0.11 | 1.14 | -0.28 | -0.10 | -0.01 | -0.02 | -0.01 | -0.06 | -0.43 | 0.04 | 0.03 | -0.09 | -0.03 | 0.00 | -0.04 | -0.03 | . 2020-04 -0.39 | 1.76 | -0.42 | -0.10 | -0.10 | -0.12 | 0.16 | 0.00 | -0.79 | -0.03 | 0.02 | -0.03 | -0.03 | 0.02 | 0.00 | 0.04 | . 2020-05 -0.23 | -2.07 | 0.11 | 0.76 | 0.50 | 0.37 | -0.05 | -0.09 | 0.47 | 0.14 | -0.05 | 0.04 | 0.06 | 0.01 | 0.02 | 0.06 | . 2020-06 0.88 | -1.46 | 0.30 | 0.19 | -0.05 | 0.06 | 0.11 | -0.08 | 0.08 | 0.00 | -0.02 | 0.01 | -0.02 | -0.04 | 0.00 | -0.01 | . 2020-07 -0.11 | -0.44 | 0.06 | 0.39 | 0.04 | 0.28 | -0.12 | -0.08 | 0.02 | 0.09 | -0.03 | 0.02 | -0.01 | -0.01 | -0.03 | -0.03 | . 2020-08 0.09 | 0.33 | -0.02 | -0.04 | 0.00 | -0.08 | -0.06 | -0.07 | -0.10 | 0.05 | -0.02 | -0.02 | -0.02 | -0.01 | -0.02 | -0.02 | . 2020-09 -0.47 | -0.17 | -0.15 | 0.59 | 0.25 | 0.12 | -0.12 | -0.08 | -0.19 | 0.27 | 0.00 | 0.00 | -0.05 | 0.06 | -0.04 | -0.03 | . 2020-10 -0.32 | 1.55 | -0.14 | 0.18 | -0.11 | -0.96 | -0.06 | -0.09 | -0.08 | 0.10 | 0.00 | -0.05 | -0.02 | 0.04 | -0.02 | -0.03 | . df.set_index(&#39;Date&#39;).diff().dropna().melt() . variable value . 0 Samsung | -0.13 | . 1 Samsung | 0.01 | . 2 Samsung | -0.08 | . 3 Samsung | -0.38 | . 4 Samsung | -0.11 | . ... ... | ... | . 187 Asus | -0.01 | . 188 Asus | -0.03 | . 189 Asus | -0.02 | . 190 Asus | -0.03 | . 191 Asus | -0.03 | . 192 rows × 2 columns . #plot.box(backend=&#39;plotly&#39;,x=&#39;variable&#39;,color=&#39;variable&#39;,y=&#39;value&#39;) #show(fig) . &#50696;&#51228;3 (plotly) . import plotly.express as px df = px.data.tips() # 내장된 data인가봄 df # 타이디 데이터 . total_bill tip sex smoker day time size . 0 16.99 | 1.01 | Female | No | Sun | Dinner | 2 | . 1 10.34 | 1.66 | Male | No | Sun | Dinner | 3 | . 2 21.01 | 3.50 | Male | No | Sun | Dinner | 3 | . 3 23.68 | 3.31 | Male | No | Sun | Dinner | 2 | . 4 24.59 | 3.61 | Female | No | Sun | Dinner | 4 | . ... ... | ... | ... | ... | ... | ... | ... | . 239 29.03 | 5.92 | Male | No | Sat | Dinner | 3 | . 240 27.18 | 2.00 | Female | Yes | Sat | Dinner | 2 | . 241 22.67 | 2.00 | Male | Yes | Sat | Dinner | 2 | . 242 17.82 | 1.75 | Male | No | Sat | Dinner | 2 | . 243 18.78 | 3.00 | Female | No | Thur | Dinner | 2 | . 244 rows × 7 columns . - 팁은 대체로 얼마나 받는지? . # show(fig) . - 점심/저녁에 따라서 팁의 분포가 다를까? . # show(fig) . 저녁에 좀더 잘주는것 같음 | . - 성별에 따라서도 팁을 주는것이 다를까? . # show(fig) . points=&#39;all&#39; | . # show(fig) . boxplot의 아웃라이어가 사라지고, 데이터를 더 리치하게 볼 수 있다. | . - 요일에 따라서도 달라질까? . #show(fig) . - 흡연유무에 따라서도 달라질까? . #show(fig) . tidydata로 한번 만들어 두니 너무 쉽게 생각하는 대로 구현가능 | . tidydata가 확실히 고차원 자료를 그리기에 유리함. matplotlib은 위와 같은 형태를 그리는것 자체가 불가능 . hist, kde, density . &#50696;&#51228;1 (matplotlib) . - 시뮬레이션예제: 정규분포를 만들어서 제곱한뒤에 3개씩, 4개씩, ... , 10개까지 더함 $ to$ 카이제곱분포 . - 일단 3개부터 구현해보자. . X = np.random.normal(size=(1000,3),loc=0,scale=1) X . array([[ 1.55206654, -0.63914829, 1.57183278], [ 0.68304602, -0.20688318, 0.35819181], [ 1.47085428, 0.81133151, -0.5744874 ], ..., [ 1.40359129, -0.65010241, 0.47624468], [ 0.03466939, -0.7774873 , 0.68491511], [-1.21877598, 0.05928286, 1.32481268]]) . X**2 # 이제 카이제곱 분포를 따른다 . array([[2.40891054e+00, 4.08510541e-01, 2.47065829e+00], [4.66551869e-01, 4.28006512e-02, 1.28301370e-01], [2.16341231e+00, 6.58258819e-01, 3.30035776e-01], ..., [1.97006850e+00, 4.22633142e-01, 2.26808996e-01], [1.20196631e-03, 6.04486503e-01, 4.69108708e-01], [1.48541489e+00, 3.51445752e-03, 1.75512863e+00]]) . . - 코드를 정리하면 . # ((np.random.normal(size=(1000,4),loc=0,scale=1))**2).sum(axis=1) # ... # ((np.random.normal(size=(1000,10),loc=0,scale=1))**2).sum(axis=1) . _arr = [3,4,5,6,7,8,9,10] df= pd.DataFrame([((np.random.normal(size=(1000,_arr[i]),loc=0,scale=1))**2).sum(axis=1).tolist() for i in range(len(_arr))]).T df . 0 1 2 3 4 5 6 7 . 0 5.196671 | 2.073253 | 7.256207 | 0.912066 | 6.190578 | 6.594515 | 7.069170 | 12.084896 | . 1 8.763815 | 2.773966 | 3.015868 | 4.860482 | 4.146444 | 7.742799 | 16.964332 | 9.376459 | . 2 3.293716 | 3.043589 | 1.294319 | 4.905373 | 8.232812 | 10.626497 | 5.012941 | 10.656208 | . 3 1.162761 | 1.256967 | 2.704866 | 9.572457 | 7.053241 | 5.572123 | 3.280732 | 9.305952 | . 4 4.195460 | 3.777258 | 12.706358 | 3.889861 | 4.839483 | 6.489378 | 24.064284 | 10.843205 | . ... ... | ... | ... | ... | ... | ... | ... | ... | . 995 4.723027 | 2.775728 | 0.886107 | 1.453307 | 5.658189 | 2.890155 | 20.358523 | 27.900246 | . 996 5.916433 | 4.379810 | 4.450089 | 3.111495 | 2.695229 | 7.811263 | 5.052450 | 11.098986 | . 997 0.661397 | 3.076920 | 9.576774 | 9.713117 | 8.424721 | 9.593768 | 7.854476 | 17.334970 | . 998 0.445096 | 7.051000 | 4.651447 | 9.421335 | 7.365830 | 6.639832 | 5.496892 | 9.536662 | . 999 2.615014 | 7.536859 | 2.548289 | 10.028903 | 6.195696 | 6.076087 | 5.851520 | 25.364383 | . 1000 rows × 8 columns . 컬럼 0이 의미하는것은 정규분포를 제곱하여 3개씩 더하여 나온값이고 컬럼1이 의미하는것은 정규분포를 제곱해서 4개씩 더해서 나온값임 $ to$ 열의 이름을 지어주자. | . df.columns = _arr . df . 3 4 5 6 7 8 9 10 . 0 5.196671 | 2.073253 | 7.256207 | 0.912066 | 6.190578 | 6.594515 | 7.069170 | 12.084896 | . 1 8.763815 | 2.773966 | 3.015868 | 4.860482 | 4.146444 | 7.742799 | 16.964332 | 9.376459 | . 2 3.293716 | 3.043589 | 1.294319 | 4.905373 | 8.232812 | 10.626497 | 5.012941 | 10.656208 | . 3 1.162761 | 1.256967 | 2.704866 | 9.572457 | 7.053241 | 5.572123 | 3.280732 | 9.305952 | . 4 4.195460 | 3.777258 | 12.706358 | 3.889861 | 4.839483 | 6.489378 | 24.064284 | 10.843205 | . ... ... | ... | ... | ... | ... | ... | ... | ... | . 995 4.723027 | 2.775728 | 0.886107 | 1.453307 | 5.658189 | 2.890155 | 20.358523 | 27.900246 | . 996 5.916433 | 4.379810 | 4.450089 | 3.111495 | 2.695229 | 7.811263 | 5.052450 | 11.098986 | . 997 0.661397 | 3.076920 | 9.576774 | 9.713117 | 8.424721 | 9.593768 | 7.854476 | 17.334970 | . 998 0.445096 | 7.051000 | 4.651447 | 9.421335 | 7.365830 | 6.639832 | 5.496892 | 9.536662 | . 999 2.615014 | 7.536859 | 2.548289 | 10.028903 | 6.195696 | 6.076087 | 5.851520 | 25.364383 | . 1000 rows × 8 columns . - 분포를 그려보자. . df.plot.hist() . &lt;AxesSubplot:ylabel=&#39;Frequency&#39;&gt; . - bins와 투명도 조절 . df.plot.hist(alpha=0.2,bins=50) . &lt;AxesSubplot:ylabel=&#39;Frequency&#39;&gt; . - 서브플랏 . import matplotlib.pyplot as plt df.plot.hist(alpha=0.2,bins=50,layout=(2,4),subplots=True,figsize=(15,5)) plt.tight_layout() . - kde 플랏 . df.plot.kde(layout=(2,4),subplots=True,figsize=(15,5)) plt.tight_layout() . df.plot.kde(layout=(2,4),subplots=True,bw_method=0.01,figsize=(15,5)) plt.tight_layout() . df.plot.kde(layout=(2,4),subplots=True,bw_method=5,figsize=(15,5)) plt.tight_layout() . df.plot.kde(layout=(2,4),subplots=True,figsize=(15,5),ls=&#39;--&#39;) plt.tight_layout() . &#50696;&#51228;2 (plotly) . - 다시 tips 예제로 돌아오자. . import plotly.express as px df = px.data.tips() df . total_bill tip sex smoker day time size . 0 16.99 | 1.01 | Female | No | Sun | Dinner | 2 | . 1 10.34 | 1.66 | Male | No | Sun | Dinner | 3 | . 2 21.01 | 3.50 | Male | No | Sun | Dinner | 3 | . 3 23.68 | 3.31 | Male | No | Sun | Dinner | 2 | . 4 24.59 | 3.61 | Female | No | Sun | Dinner | 4 | . ... ... | ... | ... | ... | ... | ... | ... | . 239 29.03 | 5.92 | Male | No | Sat | Dinner | 3 | . 240 27.18 | 2.00 | Female | Yes | Sat | Dinner | 2 | . 241 22.67 | 2.00 | Male | Yes | Sat | Dinner | 2 | . 242 17.82 | 1.75 | Male | No | Sat | Dinner | 2 | . 243 18.78 | 3.00 | Female | No | Thur | Dinner | 2 | . 244 rows × 7 columns . - 성별에 따라서 팁을 주는게 다를까? . # show(fig) . 빈도가 잘 보인다는 측면에서 박스플랏보다 좋은것 같음 | . - 시간에 따라서도 다른지? . # show(fig) . tidydata가 확실히 자료를 처리하기 편리함 | . area plot . - 주류플랏은 아님 . &#50696;&#51228;1 (matplotlib) . - 다시 핸드폰예제 . df = pd.read_csv(&#39;https://raw.githubusercontent.com/kalilurrahman/datasets/main/mobilephonemktshare2020.csv&#39;) df . Date Samsung Apple Huawei Xiaomi Oppo Mobicel Motorola LG Others Realme Google Nokia Lenovo OnePlus Sony Asus . 0 2019-10 | 31.49 | 22.09 | 10.02 | 7.79 | 4.10 | 3.15 | 2.41 | 2.40 | 9.51 | 0.54 | 2.35 | 0.95 | 0.96 | 0.70 | 0.84 | 0.74 | . 1 2019-11 | 31.36 | 22.90 | 10.18 | 8.16 | 4.42 | 3.41 | 2.40 | 2.40 | 9.10 | 0.78 | 0.66 | 0.97 | 0.97 | 0.73 | 0.83 | 0.75 | . 2 2019-12 | 31.37 | 24.79 | 9.95 | 7.73 | 4.23 | 3.19 | 2.50 | 2.54 | 8.13 | 0.84 | 0.75 | 0.90 | 0.87 | 0.74 | 0.77 | 0.70 | . 3 2020-01 | 31.29 | 24.76 | 10.61 | 8.10 | 4.25 | 3.02 | 2.42 | 2.40 | 7.55 | 0.88 | 0.69 | 0.88 | 0.86 | 0.79 | 0.80 | 0.69 | . 4 2020-02 | 30.91 | 25.89 | 10.98 | 7.80 | 4.31 | 2.89 | 2.36 | 2.34 | 7.06 | 0.89 | 0.70 | 0.81 | 0.77 | 0.78 | 0.80 | 0.69 | . 5 2020-03 | 30.80 | 27.03 | 10.70 | 7.70 | 4.30 | 2.87 | 2.35 | 2.28 | 6.63 | 0.93 | 0.73 | 0.72 | 0.74 | 0.78 | 0.76 | 0.66 | . 6 2020-04 | 30.41 | 28.79 | 10.28 | 7.60 | 4.20 | 2.75 | 2.51 | 2.28 | 5.84 | 0.90 | 0.75 | 0.69 | 0.71 | 0.80 | 0.76 | 0.70 | . 7 2020-05 | 30.18 | 26.72 | 10.39 | 8.36 | 4.70 | 3.12 | 2.46 | 2.19 | 6.31 | 1.04 | 0.70 | 0.73 | 0.77 | 0.81 | 0.78 | 0.76 | . 8 2020-06 | 31.06 | 25.26 | 10.69 | 8.55 | 4.65 | 3.18 | 2.57 | 2.11 | 6.39 | 1.04 | 0.68 | 0.74 | 0.75 | 0.77 | 0.78 | 0.75 | . 9 2020-07 | 30.95 | 24.82 | 10.75 | 8.94 | 4.69 | 3.46 | 2.45 | 2.03 | 6.41 | 1.13 | 0.65 | 0.76 | 0.74 | 0.76 | 0.75 | 0.72 | . 10 2020-08 | 31.04 | 25.15 | 10.73 | 8.90 | 4.69 | 3.38 | 2.39 | 1.96 | 6.31 | 1.18 | 0.63 | 0.74 | 0.72 | 0.75 | 0.73 | 0.70 | . 11 2020-09 | 30.57 | 24.98 | 10.58 | 9.49 | 4.94 | 3.50 | 2.27 | 1.88 | 6.12 | 1.45 | 0.63 | 0.74 | 0.67 | 0.81 | 0.69 | 0.67 | . 12 2020-10 | 30.25 | 26.53 | 10.44 | 9.67 | 4.83 | 2.54 | 2.21 | 1.79 | 6.04 | 1.55 | 0.63 | 0.69 | 0.65 | 0.85 | 0.67 | 0.64 | . df.set_index(&#39;Date&#39;).plot.area(figsize=(20,10),alpha=0.6) . &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt; . 시간에 따른 점유을의 변화를 보기에 적절한것 같다. | . &#50696;&#51228;2 (plotly) . - plotly를 쓰기 위해서 tidydata로 바꾸자 . df . Date Samsung Apple Huawei Xiaomi Oppo Mobicel Motorola LG Others Realme Google Nokia Lenovo OnePlus Sony Asus . 0 2019-10 | 31.49 | 22.09 | 10.02 | 7.79 | 4.10 | 3.15 | 2.41 | 2.40 | 9.51 | 0.54 | 2.35 | 0.95 | 0.96 | 0.70 | 0.84 | 0.74 | . 1 2019-11 | 31.36 | 22.90 | 10.18 | 8.16 | 4.42 | 3.41 | 2.40 | 2.40 | 9.10 | 0.78 | 0.66 | 0.97 | 0.97 | 0.73 | 0.83 | 0.75 | . 2 2019-12 | 31.37 | 24.79 | 9.95 | 7.73 | 4.23 | 3.19 | 2.50 | 2.54 | 8.13 | 0.84 | 0.75 | 0.90 | 0.87 | 0.74 | 0.77 | 0.70 | . 3 2020-01 | 31.29 | 24.76 | 10.61 | 8.10 | 4.25 | 3.02 | 2.42 | 2.40 | 7.55 | 0.88 | 0.69 | 0.88 | 0.86 | 0.79 | 0.80 | 0.69 | . 4 2020-02 | 30.91 | 25.89 | 10.98 | 7.80 | 4.31 | 2.89 | 2.36 | 2.34 | 7.06 | 0.89 | 0.70 | 0.81 | 0.77 | 0.78 | 0.80 | 0.69 | . 5 2020-03 | 30.80 | 27.03 | 10.70 | 7.70 | 4.30 | 2.87 | 2.35 | 2.28 | 6.63 | 0.93 | 0.73 | 0.72 | 0.74 | 0.78 | 0.76 | 0.66 | . 6 2020-04 | 30.41 | 28.79 | 10.28 | 7.60 | 4.20 | 2.75 | 2.51 | 2.28 | 5.84 | 0.90 | 0.75 | 0.69 | 0.71 | 0.80 | 0.76 | 0.70 | . 7 2020-05 | 30.18 | 26.72 | 10.39 | 8.36 | 4.70 | 3.12 | 2.46 | 2.19 | 6.31 | 1.04 | 0.70 | 0.73 | 0.77 | 0.81 | 0.78 | 0.76 | . 8 2020-06 | 31.06 | 25.26 | 10.69 | 8.55 | 4.65 | 3.18 | 2.57 | 2.11 | 6.39 | 1.04 | 0.68 | 0.74 | 0.75 | 0.77 | 0.78 | 0.75 | . 9 2020-07 | 30.95 | 24.82 | 10.75 | 8.94 | 4.69 | 3.46 | 2.45 | 2.03 | 6.41 | 1.13 | 0.65 | 0.76 | 0.74 | 0.76 | 0.75 | 0.72 | . 10 2020-08 | 31.04 | 25.15 | 10.73 | 8.90 | 4.69 | 3.38 | 2.39 | 1.96 | 6.31 | 1.18 | 0.63 | 0.74 | 0.72 | 0.75 | 0.73 | 0.70 | . 11 2020-09 | 30.57 | 24.98 | 10.58 | 9.49 | 4.94 | 3.50 | 2.27 | 1.88 | 6.12 | 1.45 | 0.63 | 0.74 | 0.67 | 0.81 | 0.69 | 0.67 | . 12 2020-10 | 30.25 | 26.53 | 10.44 | 9.67 | 4.83 | 2.54 | 2.21 | 1.79 | 6.04 | 1.55 | 0.63 | 0.69 | 0.65 | 0.85 | 0.67 | 0.64 | . df.melt(id_vars=&#39;Date&#39;) . Date variable value . 0 2019-10 | Samsung | 31.49 | . 1 2019-11 | Samsung | 31.36 | . 2 2019-12 | Samsung | 31.37 | . 3 2020-01 | Samsung | 31.29 | . 4 2020-02 | Samsung | 30.91 | . ... ... | ... | ... | . 203 2020-06 | Asus | 0.75 | . 204 2020-07 | Asus | 0.72 | . 205 2020-08 | Asus | 0.70 | . 206 2020-09 | Asus | 0.67 | . 207 2020-10 | Asus | 0.64 | . 208 rows × 3 columns . # show(fig) . &#50696;&#51228;3 (matplotlib) . 상당히 raw한 dataset | . df=pd.read_html(&#39;https://ko.wikipedia.org/wiki/%EB%8C%80%ED%95%9C%EB%AF%BC%EA%B5%AD%EC%9D%98_%EC%9D%B8%EA%B5%AC&#39;)[19] df . 행정구역별 2021. 06 2015 2010 2005 2000 . 행정구역별 비율 인구 비율 인구 비율 인구 비율 인구 비율 인구 . 0 전국 | 16.7 | 8652198 | 13.1 | 6775101 | 10.9 | 5506352 | 8.9 | 4324524 | 7.0 | 3355614 | . 1 서울특별시 | 16.4 | 1568769 | 12.6 | 1262436 | 9.7 | 1002770 | 7.2 | 731349 | 5.4 | 558566 | . 2 부산광역시 | 19.8 | 666644 | 14.6 | 514630 | 11.3 | 401784 | 8.3 | 302784 | 6.0 | 229075 | . 3 대구광역시 | 17.0 | 408235 | 12.7 | 316122 | 10.0 | 252084 | 7.8 | 195419 | 5.9 | 149045 | . 4 인천광역시 | 14.4 | 422658 | 10.7 | 312905 | 8.6 | 237805 | 6.9 | 178602 | 5.4 | 138316 | . 5 광주광역시 | 14.5 | 208879 | 11.3 | 166389 | 9.0 | 130457 | 7.1 | 99389 | 5.6 | 77325 | . 6 대전광역시 | 14.8 | 215997 | 10.9 | 165528 | 8.7 | 130245 | 6.9 | 99811 | 5.5 | 75769 | . 7 울산광역시 | 13.1 | 147811 | 8.8 | 103205 | 6.8 | 76800 | 5.3 | 57797 | 4.0 | 42119 | . 8 세종특별자치시 | 10.0 | 36194 | 10.6 | 22399 | - | - | - | - | - | - | . 9 경기도 | 13.5 | 1825846 | 10.5 | 1318882 | 8.7 | 1022456 | 7.1 | 755511 | 5.7 | 524807 | . 10 강원도 | 21.2 | 325579 | 16.9 | 261671 | 14.8 | 226505 | 12.1 | 183471 | 9.3 | 143945 | . 11 충청북도 | 18.4 | 294530 | 14.8 | 234813 | 13.2 | 204470 | 11.3 | 168670 | 9.1 | 136160 | . 12 충청남도 | 19.5 | 412504 | 16.4 | 341214 | 14.9 | 308556 | 13.3 | 261800 | 11.2 | 215059 | . 13 전라북도 | 21.8 | 391178 | 17.8 | 333524 | 15.2 | 284373 | 12.9 | 243721 | 10.3 | 205807 | . 14 전라남도 | 23.9 | 440014 | 20.5 | 391837 | 18.3 | 350900 | 15.6 | 306439 | 11.9 | 254370 | . 15 경상북도 | 22.2 | 585088 | 17.7 | 479634 | 15.6 | 418858 | 13.4 | 360068 | 10.7 | 300614 | . 16 경상남도 | 17.9 | 594154 | 13.8 | 464019 | 11.8 | 388648 | 10.2 | 323898 | 8.4 | 261303 | . 17 제주특별자치도 | 16.0 | 108118 | 13.8 | 85893 | 12.2 | 69641 | 10.0 | 55795 | 8.0 | 43334 | . - 첫번째 row(=전국)는 일단 제외 . df.iloc[1:] . 행정구역별 2021. 06 2015 2010 2005 2000 . 행정구역별 비율 인구 비율 인구 비율 인구 비율 인구 비율 인구 . 1 서울특별시 | 16.4 | 1568769 | 12.6 | 1262436 | 9.7 | 1002770 | 7.2 | 731349 | 5.4 | 558566 | . 2 부산광역시 | 19.8 | 666644 | 14.6 | 514630 | 11.3 | 401784 | 8.3 | 302784 | 6.0 | 229075 | . 3 대구광역시 | 17.0 | 408235 | 12.7 | 316122 | 10.0 | 252084 | 7.8 | 195419 | 5.9 | 149045 | . 4 인천광역시 | 14.4 | 422658 | 10.7 | 312905 | 8.6 | 237805 | 6.9 | 178602 | 5.4 | 138316 | . 5 광주광역시 | 14.5 | 208879 | 11.3 | 166389 | 9.0 | 130457 | 7.1 | 99389 | 5.6 | 77325 | . 6 대전광역시 | 14.8 | 215997 | 10.9 | 165528 | 8.7 | 130245 | 6.9 | 99811 | 5.5 | 75769 | . 7 울산광역시 | 13.1 | 147811 | 8.8 | 103205 | 6.8 | 76800 | 5.3 | 57797 | 4.0 | 42119 | . 8 세종특별자치시 | 10.0 | 36194 | 10.6 | 22399 | - | - | - | - | - | - | . 9 경기도 | 13.5 | 1825846 | 10.5 | 1318882 | 8.7 | 1022456 | 7.1 | 755511 | 5.7 | 524807 | . 10 강원도 | 21.2 | 325579 | 16.9 | 261671 | 14.8 | 226505 | 12.1 | 183471 | 9.3 | 143945 | . 11 충청북도 | 18.4 | 294530 | 14.8 | 234813 | 13.2 | 204470 | 11.3 | 168670 | 9.1 | 136160 | . 12 충청남도 | 19.5 | 412504 | 16.4 | 341214 | 14.9 | 308556 | 13.3 | 261800 | 11.2 | 215059 | . 13 전라북도 | 21.8 | 391178 | 17.8 | 333524 | 15.2 | 284373 | 12.9 | 243721 | 10.3 | 205807 | . 14 전라남도 | 23.9 | 440014 | 20.5 | 391837 | 18.3 | 350900 | 15.6 | 306439 | 11.9 | 254370 | . 15 경상북도 | 22.2 | 585088 | 17.7 | 479634 | 15.6 | 418858 | 13.4 | 360068 | 10.7 | 300614 | . 16 경상남도 | 17.9 | 594154 | 13.8 | 464019 | 11.8 | 388648 | 10.2 | 323898 | 8.4 | 261303 | . 17 제주특별자치도 | 16.0 | 108118 | 13.8 | 85893 | 12.2 | 69641 | 10.0 | 55795 | 8.0 | 43334 | . - 서울~제주를 인덱스로 설정하고 다시 스택해보자 . df.iloc[1:].columns # columns 이름이 튜플 형태로 저장되어 있음 # MultiIndex . MultiIndex([( &#39;행정구역별&#39;, &#39;행정구역별&#39;), (&#39;2021. 06&#39;, &#39;비율&#39;), (&#39;2021. 06&#39;, &#39;인구&#39;), ( &#39;2015&#39;, &#39;비율&#39;), ( &#39;2015&#39;, &#39;인구&#39;), ( &#39;2010&#39;, &#39;비율&#39;), ( &#39;2010&#39;, &#39;인구&#39;), ( &#39;2005&#39;, &#39;비율&#39;), ( &#39;2005&#39;, &#39;인구&#39;), ( &#39;2000&#39;, &#39;비율&#39;), ( &#39;2000&#39;, &#39;인구&#39;)], ) . df.iloc[1:].set_index((&#39;행정구역별&#39;,&#39;행정구역별&#39;)) . 2021. 06 2015 2010 2005 2000 . 비율 인구 비율 인구 비율 인구 비율 인구 비율 인구 . (행정구역별, 행정구역별) . 서울특별시 16.4 | 1568769 | 12.6 | 1262436 | 9.7 | 1002770 | 7.2 | 731349 | 5.4 | 558566 | . 부산광역시 19.8 | 666644 | 14.6 | 514630 | 11.3 | 401784 | 8.3 | 302784 | 6.0 | 229075 | . 대구광역시 17.0 | 408235 | 12.7 | 316122 | 10.0 | 252084 | 7.8 | 195419 | 5.9 | 149045 | . 인천광역시 14.4 | 422658 | 10.7 | 312905 | 8.6 | 237805 | 6.9 | 178602 | 5.4 | 138316 | . 광주광역시 14.5 | 208879 | 11.3 | 166389 | 9.0 | 130457 | 7.1 | 99389 | 5.6 | 77325 | . 대전광역시 14.8 | 215997 | 10.9 | 165528 | 8.7 | 130245 | 6.9 | 99811 | 5.5 | 75769 | . 울산광역시 13.1 | 147811 | 8.8 | 103205 | 6.8 | 76800 | 5.3 | 57797 | 4.0 | 42119 | . 세종특별자치시 10.0 | 36194 | 10.6 | 22399 | - | - | - | - | - | - | . 경기도 13.5 | 1825846 | 10.5 | 1318882 | 8.7 | 1022456 | 7.1 | 755511 | 5.7 | 524807 | . 강원도 21.2 | 325579 | 16.9 | 261671 | 14.8 | 226505 | 12.1 | 183471 | 9.3 | 143945 | . 충청북도 18.4 | 294530 | 14.8 | 234813 | 13.2 | 204470 | 11.3 | 168670 | 9.1 | 136160 | . 충청남도 19.5 | 412504 | 16.4 | 341214 | 14.9 | 308556 | 13.3 | 261800 | 11.2 | 215059 | . 전라북도 21.8 | 391178 | 17.8 | 333524 | 15.2 | 284373 | 12.9 | 243721 | 10.3 | 205807 | . 전라남도 23.9 | 440014 | 20.5 | 391837 | 18.3 | 350900 | 15.6 | 306439 | 11.9 | 254370 | . 경상북도 22.2 | 585088 | 17.7 | 479634 | 15.6 | 418858 | 13.4 | 360068 | 10.7 | 300614 | . 경상남도 17.9 | 594154 | 13.8 | 464019 | 11.8 | 388648 | 10.2 | 323898 | 8.4 | 261303 | . 제주특별자치도 16.0 | 108118 | 13.8 | 85893 | 12.2 | 69641 | 10.0 | 55795 | 8.0 | 43334 | . df.iloc[1:].set_index((&#39;행정구역별&#39;,&#39;행정구역별&#39;)).stack() . 2000 2005 2010 2015 2021. 06 . (행정구역별, 행정구역별) . 서울특별시 비율 5.4 | 7.2 | 9.7 | 12.6 | 16.4 | . 인구 558566 | 731349 | 1002770 | 1262436.0 | 1568769.0 | . 부산광역시 비율 6.0 | 8.3 | 11.3 | 14.6 | 19.8 | . 인구 229075 | 302784 | 401784 | 514630.0 | 666644.0 | . 대구광역시 비율 5.9 | 7.8 | 10.0 | 12.7 | 17.0 | . 인구 149045 | 195419 | 252084 | 316122.0 | 408235.0 | . 인천광역시 비율 5.4 | 6.9 | 8.6 | 10.7 | 14.4 | . 인구 138316 | 178602 | 237805 | 312905.0 | 422658.0 | . 광주광역시 비율 5.6 | 7.1 | 9.0 | 11.3 | 14.5 | . 인구 77325 | 99389 | 130457 | 166389.0 | 208879.0 | . 대전광역시 비율 5.5 | 6.9 | 8.7 | 10.9 | 14.8 | . 인구 75769 | 99811 | 130245 | 165528.0 | 215997.0 | . 울산광역시 비율 4.0 | 5.3 | 6.8 | 8.8 | 13.1 | . 인구 42119 | 57797 | 76800 | 103205.0 | 147811.0 | . 세종특별자치시 비율 - | - | - | 10.6 | 10.0 | . 인구 - | - | - | 22399.0 | 36194.0 | . 경기도 비율 5.7 | 7.1 | 8.7 | 10.5 | 13.5 | . 인구 524807 | 755511 | 1022456 | 1318882.0 | 1825846.0 | . 강원도 비율 9.3 | 12.1 | 14.8 | 16.9 | 21.2 | . 인구 143945 | 183471 | 226505 | 261671.0 | 325579.0 | . 충청북도 비율 9.1 | 11.3 | 13.2 | 14.8 | 18.4 | . 인구 136160 | 168670 | 204470 | 234813.0 | 294530.0 | . 충청남도 비율 11.2 | 13.3 | 14.9 | 16.4 | 19.5 | . 인구 215059 | 261800 | 308556 | 341214.0 | 412504.0 | . 전라북도 비율 10.3 | 12.9 | 15.2 | 17.8 | 21.8 | . 인구 205807 | 243721 | 284373 | 333524.0 | 391178.0 | . 전라남도 비율 11.9 | 15.6 | 18.3 | 20.5 | 23.9 | . 인구 254370 | 306439 | 350900 | 391837.0 | 440014.0 | . 경상북도 비율 10.7 | 13.4 | 15.6 | 17.7 | 22.2 | . 인구 300614 | 360068 | 418858 | 479634.0 | 585088.0 | . 경상남도 비율 8.4 | 10.2 | 11.8 | 13.8 | 17.9 | . 인구 261303 | 323898 | 388648 | 464019.0 | 594154.0 | . 제주특별자치도 비율 8.0 | 10.0 | 12.2 | 13.8 | 16.0 | . 인구 43334 | 55795 | 69641 | 85893.0 | 108118.0 | . df.iloc[1:].set_index((&#39;행정구역별&#39;,&#39;행정구역별&#39;)).stack().reset_index() . (행정구역별, 행정구역별) level_1 2000 2005 2010 2015 2021. 06 . 0 서울특별시 | 비율 | 5.4 | 7.2 | 9.7 | 12.6 | 16.4 | . 1 서울특별시 | 인구 | 558566 | 731349 | 1002770 | 1262436.0 | 1568769.0 | . 2 부산광역시 | 비율 | 6.0 | 8.3 | 11.3 | 14.6 | 19.8 | . 3 부산광역시 | 인구 | 229075 | 302784 | 401784 | 514630.0 | 666644.0 | . 4 대구광역시 | 비율 | 5.9 | 7.8 | 10.0 | 12.7 | 17.0 | . 5 대구광역시 | 인구 | 149045 | 195419 | 252084 | 316122.0 | 408235.0 | . 6 인천광역시 | 비율 | 5.4 | 6.9 | 8.6 | 10.7 | 14.4 | . 7 인천광역시 | 인구 | 138316 | 178602 | 237805 | 312905.0 | 422658.0 | . 8 광주광역시 | 비율 | 5.6 | 7.1 | 9.0 | 11.3 | 14.5 | . 9 광주광역시 | 인구 | 77325 | 99389 | 130457 | 166389.0 | 208879.0 | . 10 대전광역시 | 비율 | 5.5 | 6.9 | 8.7 | 10.9 | 14.8 | . 11 대전광역시 | 인구 | 75769 | 99811 | 130245 | 165528.0 | 215997.0 | . 12 울산광역시 | 비율 | 4.0 | 5.3 | 6.8 | 8.8 | 13.1 | . 13 울산광역시 | 인구 | 42119 | 57797 | 76800 | 103205.0 | 147811.0 | . 14 세종특별자치시 | 비율 | - | - | - | 10.6 | 10.0 | . 15 세종특별자치시 | 인구 | - | - | - | 22399.0 | 36194.0 | . 16 경기도 | 비율 | 5.7 | 7.1 | 8.7 | 10.5 | 13.5 | . 17 경기도 | 인구 | 524807 | 755511 | 1022456 | 1318882.0 | 1825846.0 | . 18 강원도 | 비율 | 9.3 | 12.1 | 14.8 | 16.9 | 21.2 | . 19 강원도 | 인구 | 143945 | 183471 | 226505 | 261671.0 | 325579.0 | . 20 충청북도 | 비율 | 9.1 | 11.3 | 13.2 | 14.8 | 18.4 | . 21 충청북도 | 인구 | 136160 | 168670 | 204470 | 234813.0 | 294530.0 | . 22 충청남도 | 비율 | 11.2 | 13.3 | 14.9 | 16.4 | 19.5 | . 23 충청남도 | 인구 | 215059 | 261800 | 308556 | 341214.0 | 412504.0 | . 24 전라북도 | 비율 | 10.3 | 12.9 | 15.2 | 17.8 | 21.8 | . 25 전라북도 | 인구 | 205807 | 243721 | 284373 | 333524.0 | 391178.0 | . 26 전라남도 | 비율 | 11.9 | 15.6 | 18.3 | 20.5 | 23.9 | . 27 전라남도 | 인구 | 254370 | 306439 | 350900 | 391837.0 | 440014.0 | . 28 경상북도 | 비율 | 10.7 | 13.4 | 15.6 | 17.7 | 22.2 | . 29 경상북도 | 인구 | 300614 | 360068 | 418858 | 479634.0 | 585088.0 | . 30 경상남도 | 비율 | 8.4 | 10.2 | 11.8 | 13.8 | 17.9 | . 31 경상남도 | 인구 | 261303 | 323898 | 388648 | 464019.0 | 594154.0 | . 32 제주특별자치도 | 비율 | 8.0 | 10.0 | 12.2 | 13.8 | 16.0 | . 33 제주특별자치도 | 인구 | 43334 | 55795 | 69641 | 85893.0 | 108118.0 | . - 시각화를 위해서 비율만 선택하도록 하자. . df.iloc[1:].set_index((&#39;행정구역별&#39;,&#39;행정구역별&#39;)).stack().reset_index(). query(&#39;level_1==&quot;비율&quot;&#39;) . (행정구역별, 행정구역별) level_1 2000 2005 2010 2015 2021. 06 . 0 서울특별시 | 비율 | 5.4 | 7.2 | 9.7 | 12.6 | 16.4 | . 2 부산광역시 | 비율 | 6.0 | 8.3 | 11.3 | 14.6 | 19.8 | . 4 대구광역시 | 비율 | 5.9 | 7.8 | 10.0 | 12.7 | 17.0 | . 6 인천광역시 | 비율 | 5.4 | 6.9 | 8.6 | 10.7 | 14.4 | . 8 광주광역시 | 비율 | 5.6 | 7.1 | 9.0 | 11.3 | 14.5 | . 10 대전광역시 | 비율 | 5.5 | 6.9 | 8.7 | 10.9 | 14.8 | . 12 울산광역시 | 비율 | 4.0 | 5.3 | 6.8 | 8.8 | 13.1 | . 14 세종특별자치시 | 비율 | - | - | - | 10.6 | 10.0 | . 16 경기도 | 비율 | 5.7 | 7.1 | 8.7 | 10.5 | 13.5 | . 18 강원도 | 비율 | 9.3 | 12.1 | 14.8 | 16.9 | 21.2 | . 20 충청북도 | 비율 | 9.1 | 11.3 | 13.2 | 14.8 | 18.4 | . 22 충청남도 | 비율 | 11.2 | 13.3 | 14.9 | 16.4 | 19.5 | . 24 전라북도 | 비율 | 10.3 | 12.9 | 15.2 | 17.8 | 21.8 | . 26 전라남도 | 비율 | 11.9 | 15.6 | 18.3 | 20.5 | 23.9 | . 28 경상북도 | 비율 | 10.7 | 13.4 | 15.6 | 17.7 | 22.2 | . 30 경상남도 | 비율 | 8.4 | 10.2 | 11.8 | 13.8 | 17.9 | . 32 제주특별자치도 | 비율 | 8.0 | 10.0 | 12.2 | 13.8 | 16.0 | . df.iloc[1:].set_index((&#39;행정구역별&#39;,&#39;행정구역별&#39;)).stack().reset_index(). query(&#39;level_1==&quot;비율&quot;&#39;).set_index((&#39;행정구역별&#39;,&#39;행정구역별&#39;)) . level_1 2000 2005 2010 2015 2021. 06 . (행정구역별, 행정구역별) . 서울특별시 비율 | 5.4 | 7.2 | 9.7 | 12.6 | 16.4 | . 부산광역시 비율 | 6.0 | 8.3 | 11.3 | 14.6 | 19.8 | . 대구광역시 비율 | 5.9 | 7.8 | 10.0 | 12.7 | 17.0 | . 인천광역시 비율 | 5.4 | 6.9 | 8.6 | 10.7 | 14.4 | . 광주광역시 비율 | 5.6 | 7.1 | 9.0 | 11.3 | 14.5 | . 대전광역시 비율 | 5.5 | 6.9 | 8.7 | 10.9 | 14.8 | . 울산광역시 비율 | 4.0 | 5.3 | 6.8 | 8.8 | 13.1 | . 세종특별자치시 비율 | - | - | - | 10.6 | 10.0 | . 경기도 비율 | 5.7 | 7.1 | 8.7 | 10.5 | 13.5 | . 강원도 비율 | 9.3 | 12.1 | 14.8 | 16.9 | 21.2 | . 충청북도 비율 | 9.1 | 11.3 | 13.2 | 14.8 | 18.4 | . 충청남도 비율 | 11.2 | 13.3 | 14.9 | 16.4 | 19.5 | . 전라북도 비율 | 10.3 | 12.9 | 15.2 | 17.8 | 21.8 | . 전라남도 비율 | 11.9 | 15.6 | 18.3 | 20.5 | 23.9 | . 경상북도 비율 | 10.7 | 13.4 | 15.6 | 17.7 | 22.2 | . 경상남도 비율 | 8.4 | 10.2 | 11.8 | 13.8 | 17.9 | . 제주특별자치도 비율 | 8.0 | 10.0 | 12.2 | 13.8 | 16.0 | . df_=df.iloc[1:].set_index((&#39;행정구역별&#39;,&#39;행정구역별&#39;)).stack().reset_index(). query(&#39;level_1==&quot;비율&quot;&#39;).set_index((&#39;행정구역별&#39;,&#39;행정구역별&#39;)).iloc[:,1:].T df_ # matplotlib로 그리려면 .T해줘야 함 # for wide form . (행정구역별, 행정구역별) 서울특별시 부산광역시 대구광역시 인천광역시 광주광역시 대전광역시 울산광역시 세종특별자치시 경기도 강원도 충청북도 충청남도 전라북도 전라남도 경상북도 경상남도 제주특별자치도 . 2000 5.4 | 6.0 | 5.9 | 5.4 | 5.6 | 5.5 | 4.0 | - | 5.7 | 9.3 | 9.1 | 11.2 | 10.3 | 11.9 | 10.7 | 8.4 | 8.0 | . 2005 7.2 | 8.3 | 7.8 | 6.9 | 7.1 | 6.9 | 5.3 | - | 7.1 | 12.1 | 11.3 | 13.3 | 12.9 | 15.6 | 13.4 | 10.2 | 10.0 | . 2010 9.7 | 11.3 | 10.0 | 8.6 | 9.0 | 8.7 | 6.8 | - | 8.7 | 14.8 | 13.2 | 14.9 | 15.2 | 18.3 | 15.6 | 11.8 | 12.2 | . 2015 12.6 | 14.6 | 12.7 | 10.7 | 11.3 | 10.9 | 8.8 | 10.6 | 10.5 | 16.9 | 14.8 | 16.4 | 17.8 | 20.5 | 17.7 | 13.8 | 13.8 | . 2021. 06 16.4 | 19.8 | 17.0 | 14.4 | 14.5 | 14.8 | 13.1 | 10.0 | 13.5 | 21.2 | 18.4 | 19.5 | 21.8 | 23.9 | 22.2 | 17.9 | 16.0 | . df_.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Index: 5 entries, 2000 to 2021. 06 Data columns (total 17 columns): # Column Non-Null Count Dtype -- -- 0 서울특별시 5 non-null object 1 부산광역시 5 non-null object 2 대구광역시 5 non-null object 3 인천광역시 5 non-null object 4 광주광역시 5 non-null object 5 대전광역시 5 non-null object 6 울산광역시 5 non-null object 7 세종특별자치시 5 non-null object 8 경기도 5 non-null object 9 강원도 5 non-null object 10 충청북도 5 non-null object 11 충청남도 5 non-null object 12 전라북도 5 non-null object 13 전라남도 5 non-null object 14 경상북도 5 non-null object 15 경상남도 5 non-null object 16 제주특별자치도 5 non-null object dtypes: object(17) memory usage: 720.0+ bytes . - 세종시의 - 가 문제가 될듯 $ to$ 자료형도 이상함 . - 데이터프레임의 모든 원소에 변환을 수행해야 한다. (applymap) . 문자형을 숫자형으로 바꾸라 | 그런데 문자가 - 라면 None으로 바꿔라 | . df_2=df.iloc[1:].set_index((&#39;행정구역별&#39;,&#39;행정구역별&#39;)).stack().reset_index(). query(&#39;level_1==&quot;비율&quot;&#39;).set_index((&#39;행정구역별&#39;,&#39;행정구역별&#39;)).iloc[:,1:].T. applymap(lambda x: float(x) if x!=&#39;-&#39; else None) df_2 . (행정구역별, 행정구역별) 서울특별시 부산광역시 대구광역시 인천광역시 광주광역시 대전광역시 울산광역시 세종특별자치시 경기도 강원도 충청북도 충청남도 전라북도 전라남도 경상북도 경상남도 제주특별자치도 . 2000 5.4 | 6.0 | 5.9 | 5.4 | 5.6 | 5.5 | 4.0 | NaN | 5.7 | 9.3 | 9.1 | 11.2 | 10.3 | 11.9 | 10.7 | 8.4 | 8.0 | . 2005 7.2 | 8.3 | 7.8 | 6.9 | 7.1 | 6.9 | 5.3 | NaN | 7.1 | 12.1 | 11.3 | 13.3 | 12.9 | 15.6 | 13.4 | 10.2 | 10.0 | . 2010 9.7 | 11.3 | 10.0 | 8.6 | 9.0 | 8.7 | 6.8 | NaN | 8.7 | 14.8 | 13.2 | 14.9 | 15.2 | 18.3 | 15.6 | 11.8 | 12.2 | . 2015 12.6 | 14.6 | 12.7 | 10.7 | 11.3 | 10.9 | 8.8 | 10.6 | 10.5 | 16.9 | 14.8 | 16.4 | 17.8 | 20.5 | 17.7 | 13.8 | 13.8 | . 2021. 06 16.4 | 19.8 | 17.0 | 14.4 | 14.5 | 14.8 | 13.1 | 10.0 | 13.5 | 21.2 | 18.4 | 19.5 | 21.8 | 23.9 | 22.2 | 17.9 | 16.0 | . df_2.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Index: 5 entries, 2000 to 2021. 06 Data columns (total 17 columns): # Column Non-Null Count Dtype -- -- 0 서울특별시 5 non-null float64 1 부산광역시 5 non-null float64 2 대구광역시 5 non-null float64 3 인천광역시 5 non-null float64 4 광주광역시 5 non-null float64 5 대전광역시 5 non-null float64 6 울산광역시 5 non-null float64 7 세종특별자치시 2 non-null float64 8 경기도 5 non-null float64 9 강원도 5 non-null float64 10 충청북도 5 non-null float64 11 충청남도 5 non-null float64 12 전라북도 5 non-null float64 13 전라남도 5 non-null float64 14 경상북도 5 non-null float64 15 경상남도 5 non-null float64 16 제주특별자치도 5 non-null float64 dtypes: float64(17) memory usage: 720.0+ bytes . 전에 존재했던 세종특별자치시의 3개의 - 값은 NaN값으로 들어갔고 자료형도 float형태로 바뀐 것을 알 수 있음 | . - 이제 그리자 . import warnings warnings.filterwarnings(&#39;ignore&#39;) df.iloc[1:].set_index((&#39;행정구역별&#39;,&#39;행정구역별&#39;)).stack().reset_index(). query(&#39;level_1==&quot;비율&quot;&#39;).set_index((&#39;행정구역별&#39;,&#39;행정구역별&#39;)).iloc[:,1:].T. applymap(lambda x: float(x) if x!=&#39;-&#39; else None). plot.area(figsize=(10,10)) . &lt;AxesSubplot:&gt; . &#50696;&#51228;2 (plotly) . - plotly 그리기 위해서우선 타이디한 자료를 만들자. . df . 행정구역별 2021. 06 2015 2010 2005 2000 . 행정구역별 비율 인구 비율 인구 비율 인구 비율 인구 비율 인구 . 0 전국 | 16.7 | 8652198 | 13.1 | 6775101 | 10.9 | 5506352 | 8.9 | 4324524 | 7.0 | 3355614 | . 1 서울특별시 | 16.4 | 1568769 | 12.6 | 1262436 | 9.7 | 1002770 | 7.2 | 731349 | 5.4 | 558566 | . 2 부산광역시 | 19.8 | 666644 | 14.6 | 514630 | 11.3 | 401784 | 8.3 | 302784 | 6.0 | 229075 | . 3 대구광역시 | 17.0 | 408235 | 12.7 | 316122 | 10.0 | 252084 | 7.8 | 195419 | 5.9 | 149045 | . 4 인천광역시 | 14.4 | 422658 | 10.7 | 312905 | 8.6 | 237805 | 6.9 | 178602 | 5.4 | 138316 | . 5 광주광역시 | 14.5 | 208879 | 11.3 | 166389 | 9.0 | 130457 | 7.1 | 99389 | 5.6 | 77325 | . 6 대전광역시 | 14.8 | 215997 | 10.9 | 165528 | 8.7 | 130245 | 6.9 | 99811 | 5.5 | 75769 | . 7 울산광역시 | 13.1 | 147811 | 8.8 | 103205 | 6.8 | 76800 | 5.3 | 57797 | 4.0 | 42119 | . 8 세종특별자치시 | 10.0 | 36194 | 10.6 | 22399 | - | - | - | - | - | - | . 9 경기도 | 13.5 | 1825846 | 10.5 | 1318882 | 8.7 | 1022456 | 7.1 | 755511 | 5.7 | 524807 | . 10 강원도 | 21.2 | 325579 | 16.9 | 261671 | 14.8 | 226505 | 12.1 | 183471 | 9.3 | 143945 | . 11 충청북도 | 18.4 | 294530 | 14.8 | 234813 | 13.2 | 204470 | 11.3 | 168670 | 9.1 | 136160 | . 12 충청남도 | 19.5 | 412504 | 16.4 | 341214 | 14.9 | 308556 | 13.3 | 261800 | 11.2 | 215059 | . 13 전라북도 | 21.8 | 391178 | 17.8 | 333524 | 15.2 | 284373 | 12.9 | 243721 | 10.3 | 205807 | . 14 전라남도 | 23.9 | 440014 | 20.5 | 391837 | 18.3 | 350900 | 15.6 | 306439 | 11.9 | 254370 | . 15 경상북도 | 22.2 | 585088 | 17.7 | 479634 | 15.6 | 418858 | 13.4 | 360068 | 10.7 | 300614 | . 16 경상남도 | 17.9 | 594154 | 13.8 | 464019 | 11.8 | 388648 | 10.2 | 323898 | 8.4 | 261303 | . 17 제주특별자치도 | 16.0 | 108118 | 13.8 | 85893 | 12.2 | 69641 | 10.0 | 55795 | 8.0 | 43334 | . df.iloc[1:].set_index((&#39;행정구역별&#39;,&#39;행정구역별&#39;)).stack() . 2000 2005 2010 2015 2021. 06 . (행정구역별, 행정구역별) . 서울특별시 비율 5.4 | 7.2 | 9.7 | 12.6 | 16.4 | . 인구 558566 | 731349 | 1002770 | 1262436.0 | 1568769.0 | . 부산광역시 비율 6.0 | 8.3 | 11.3 | 14.6 | 19.8 | . 인구 229075 | 302784 | 401784 | 514630.0 | 666644.0 | . 대구광역시 비율 5.9 | 7.8 | 10.0 | 12.7 | 17.0 | . 인구 149045 | 195419 | 252084 | 316122.0 | 408235.0 | . 인천광역시 비율 5.4 | 6.9 | 8.6 | 10.7 | 14.4 | . 인구 138316 | 178602 | 237805 | 312905.0 | 422658.0 | . 광주광역시 비율 5.6 | 7.1 | 9.0 | 11.3 | 14.5 | . 인구 77325 | 99389 | 130457 | 166389.0 | 208879.0 | . 대전광역시 비율 5.5 | 6.9 | 8.7 | 10.9 | 14.8 | . 인구 75769 | 99811 | 130245 | 165528.0 | 215997.0 | . 울산광역시 비율 4.0 | 5.3 | 6.8 | 8.8 | 13.1 | . 인구 42119 | 57797 | 76800 | 103205.0 | 147811.0 | . 세종특별자치시 비율 - | - | - | 10.6 | 10.0 | . 인구 - | - | - | 22399.0 | 36194.0 | . 경기도 비율 5.7 | 7.1 | 8.7 | 10.5 | 13.5 | . 인구 524807 | 755511 | 1022456 | 1318882.0 | 1825846.0 | . 강원도 비율 9.3 | 12.1 | 14.8 | 16.9 | 21.2 | . 인구 143945 | 183471 | 226505 | 261671.0 | 325579.0 | . 충청북도 비율 9.1 | 11.3 | 13.2 | 14.8 | 18.4 | . 인구 136160 | 168670 | 204470 | 234813.0 | 294530.0 | . 충청남도 비율 11.2 | 13.3 | 14.9 | 16.4 | 19.5 | . 인구 215059 | 261800 | 308556 | 341214.0 | 412504.0 | . 전라북도 비율 10.3 | 12.9 | 15.2 | 17.8 | 21.8 | . 인구 205807 | 243721 | 284373 | 333524.0 | 391178.0 | . 전라남도 비율 11.9 | 15.6 | 18.3 | 20.5 | 23.9 | . 인구 254370 | 306439 | 350900 | 391837.0 | 440014.0 | . 경상북도 비율 10.7 | 13.4 | 15.6 | 17.7 | 22.2 | . 인구 300614 | 360068 | 418858 | 479634.0 | 585088.0 | . 경상남도 비율 8.4 | 10.2 | 11.8 | 13.8 | 17.9 | . 인구 261303 | 323898 | 388648 | 464019.0 | 594154.0 | . 제주특별자치도 비율 8.0 | 10.0 | 12.2 | 13.8 | 16.0 | . 인구 43334 | 55795 | 69641 | 85893.0 | 108118.0 | . df.iloc[1:].set_index((&#39;행정구역별&#39;,&#39;행정구역별&#39;)).stack().applymap(lambda x: float(x) if x!=&#39;-&#39; else None). stack() . (행정구역별, 행정구역별) 서울특별시 비율 2000 5.4 2005 7.2 2010 9.7 2015 12.6 2021. 06 16.4 ... 제주특별자치도 인구 2000 43334.0 2005 55795.0 2010 69641.0 2015 85893.0 2021. 06 108118.0 Length: 164, dtype: float64 . df.iloc[1:].set_index((&#39;행정구역별&#39;,&#39;행정구역별&#39;)).stack().applymap(lambda x: float(x) if x!=&#39;-&#39; else None). stack().reset_index() . (행정구역별, 행정구역별) level_1 level_2 0 . 0 서울특별시 | 비율 | 2000 | 5.4 | . 1 서울특별시 | 비율 | 2005 | 7.2 | . 2 서울특별시 | 비율 | 2010 | 9.7 | . 3 서울특별시 | 비율 | 2015 | 12.6 | . 4 서울특별시 | 비율 | 2021. 06 | 16.4 | . ... ... | ... | ... | ... | . 159 제주특별자치도 | 인구 | 2000 | 43334.0 | . 160 제주특별자치도 | 인구 | 2005 | 55795.0 | . 161 제주특별자치도 | 인구 | 2010 | 69641.0 | . 162 제주특별자치도 | 인구 | 2015 | 85893.0 | . 163 제주특별자치도 | 인구 | 2021. 06 | 108118.0 | . 164 rows × 4 columns . _df = _ . _df.columns = pd.Index([&#39;city&#39;,&#39;type&#39;,&#39;year&#39;,&#39;value&#39;]) . _df . city type year value . 0 서울특별시 | 비율 | 2000 | 5.4 | . 1 서울특별시 | 비율 | 2005 | 7.2 | . 2 서울특별시 | 비율 | 2010 | 9.7 | . 3 서울특별시 | 비율 | 2015 | 12.6 | . 4 서울특별시 | 비율 | 2021. 06 | 16.4 | . ... ... | ... | ... | ... | . 159 제주특별자치도 | 인구 | 2000 | 43334.0 | . 160 제주특별자치도 | 인구 | 2005 | 55795.0 | . 161 제주특별자치도 | 인구 | 2010 | 69641.0 | . 162 제주특별자치도 | 인구 | 2015 | 85893.0 | . 163 제주특별자치도 | 인구 | 2021. 06 | 108118.0 | . 164 rows × 4 columns . - 이제 그려보자. . # show(fig) . 즉 와이드 폼(.T 활용)은 plot이용해서 그릴 때, 타이디한 롱폼은 backend를 plotly로 그릴 때 . T 활용해서 타이디 데이터 만들 수도 있음 .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/15/intro2.html",
            "relUrl": "/2022/01/15/intro2.html",
            "date": " • Jan 15, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "2022/01/14/FRI",
            "content": "from pandas_datareader import data as pdr import numpy as np import pandas as pd import warnings from IPython.display import HTML def show(fig): return HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;,include_mathjax=False, config=dict({&#39;scrollZoom&#39;:False}))) . line - (matploblib) . symbols = [&#39;AMZN&#39;,&#39;AAPL&#39;,&#39;GOOG&#39;,&#39;MSFT&#39;,&#39;NFLX&#39;,&#39;NVDA&#39;,&#39;TSLA&#39;] start = &#39;2020-01-01&#39; end = &#39;2020-11-28&#39; df = pdr.get_data_yahoo(symbols,start,end)[&#39;Adj Close&#39;] . df.index . DatetimeIndex([&#39;2019-12-31&#39;, &#39;2020-01-02&#39;, &#39;2020-01-03&#39;, &#39;2020-01-06&#39;, &#39;2020-01-07&#39;, &#39;2020-01-08&#39;, &#39;2020-01-09&#39;, &#39;2020-01-10&#39;, &#39;2020-01-13&#39;, &#39;2020-01-14&#39;, ... &#39;2020-11-13&#39;, &#39;2020-11-16&#39;, &#39;2020-11-17&#39;, &#39;2020-11-18&#39;, &#39;2020-11-19&#39;, &#39;2020-11-20&#39;, &#39;2020-11-23&#39;, &#39;2020-11-24&#39;, &#39;2020-11-25&#39;, &#39;2020-11-27&#39;], dtype=&#39;datetime64[ns]&#39;, name=&#39;Date&#39;, length=231, freq=None) . df.columns . Index([&#39;AMZN&#39;, &#39;AAPL&#39;, &#39;GOOG&#39;, &#39;MSFT&#39;, &#39;NFLX&#39;, &#39;NVDA&#39;, &#39;TSLA&#39;], dtype=&#39;object&#39;, name=&#39;Symbols&#39;) . df # 지금 인덱스 역할을 Date가 하고 있음 . Symbols AMZN AAPL GOOG MSFT NFLX NVDA TSLA . Date . 2019-12-31 1847.839966 | 72.337982 | 1337.020020 | 154.749741 | 323.570007 | 58.676846 | 83.666000 | . 2020-01-02 1898.010010 | 73.988480 | 1367.369995 | 157.615112 | 329.809998 | 59.826443 | 86.052002 | . 2020-01-03 1874.969971 | 73.269150 | 1360.660034 | 155.652542 | 325.899994 | 58.868862 | 88.601997 | . 2020-01-06 1902.880005 | 73.852982 | 1394.209961 | 156.054855 | 335.829987 | 59.115734 | 90.307999 | . 2020-01-07 1906.859985 | 73.505646 | 1393.339966 | 154.632004 | 330.750000 | 59.831432 | 93.811996 | . ... ... | ... | ... | ... | ... | ... | ... | . 2020-11-20 3099.399902 | 116.621048 | 1742.189941 | 208.641113 | 488.239990 | 130.724670 | 489.609985 | . 2020-11-23 3098.389893 | 113.152443 | 1734.859985 | 208.363434 | 476.619995 | 131.246567 | 521.849976 | . 2020-11-24 3118.060059 | 114.464348 | 1768.880005 | 212.082260 | 482.880005 | 129.426178 | 555.380005 | . 2020-11-25 3185.070068 | 115.319084 | 1771.430054 | 212.092194 | 485.000000 | 132.192963 | 574.000000 | . 2020-11-27 3195.340088 | 115.875648 | 1793.189941 | 213.440872 | 491.359985 | 132.457642 | 585.760010 | . 231 rows × 7 columns . Symbols는 그냥 회사 이름들 범주알려주는 지표?느낌 인듯 | . df.reset_index() # Date가 column으로 들어갔음 . Symbols Date AMZN AAPL GOOG MSFT NFLX NVDA TSLA . 0 2019-12-31 | 1847.839966 | 72.337982 | 1337.020020 | 154.749741 | 323.570007 | 58.676846 | 83.666000 | . 1 2020-01-02 | 1898.010010 | 73.988480 | 1367.369995 | 157.615112 | 329.809998 | 59.826443 | 86.052002 | . 2 2020-01-03 | 1874.969971 | 73.269150 | 1360.660034 | 155.652542 | 325.899994 | 58.868862 | 88.601997 | . 3 2020-01-06 | 1902.880005 | 73.852982 | 1394.209961 | 156.054855 | 335.829987 | 59.115734 | 90.307999 | . 4 2020-01-07 | 1906.859985 | 73.505646 | 1393.339966 | 154.632004 | 330.750000 | 59.831432 | 93.811996 | . ... ... | ... | ... | ... | ... | ... | ... | ... | . 226 2020-11-20 | 3099.399902 | 116.621048 | 1742.189941 | 208.641113 | 488.239990 | 130.724670 | 489.609985 | . 227 2020-11-23 | 3098.389893 | 113.152443 | 1734.859985 | 208.363434 | 476.619995 | 131.246567 | 521.849976 | . 228 2020-11-24 | 3118.060059 | 114.464348 | 1768.880005 | 212.082260 | 482.880005 | 129.426178 | 555.380005 | . 229 2020-11-25 | 3185.070068 | 115.319084 | 1771.430054 | 212.092194 | 485.000000 | 132.192963 | 574.000000 | . 230 2020-11-27 | 3195.340088 | 115.875648 | 1793.189941 | 213.440872 | 491.359985 | 132.457642 | 585.760010 | . 231 rows × 8 columns . df.reset_index().plot.line(x=&#39;Date&#39;,y=&#39;AMZN&#39;) . &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt; . df.reset_index().plot.line(x=&#39;Date&#39;,y=[&#39;AMZN&#39;,&#39;GOOG&#39;]) . &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt; . df.reset_index().plot.line(x=&#39;Date&#39;) . &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt; . df.reset_index().plot.line(x=&#39;Date&#39;,figsize=(10,10)) . &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt; . 서브플랏 . df.reset_index().plot.line(x=&#39;Date&#39;,figsize=(10,10),subplots=True) . array([&lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;], dtype=object) . df.reset_index().plot.line(x=&#39;Date&#39;,figsize=(10,10),subplots=True,layout=(4,2)) . array([[&lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;], [&lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;], [&lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;], [&lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;]], dtype=object) . - 폰트조정 . df.reset_index().plot.line(x=&#39;Date&#39;,figsize=(10,10),subplots=True,layout=(4,2),fontsize=20) . array([[&lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;], [&lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;], [&lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;], [&lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;]], dtype=object) . - 투명도 조정 . df.reset_index().plot.line(x=&#39;Date&#39;,figsize=(10,10),subplots=True,layout=(4,2),alpha=0.3) . array([[&lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;], [&lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;], [&lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;], [&lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;]], dtype=object) . - 레전드 삭제 . df.reset_index().plot.line(x=&#39;Date&#39;,figsize=(10,10),subplots=True,layout=(4,2),legend=False) . array([[&lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;], [&lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;], [&lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;], [&lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt;]], dtype=object) . bar, barh . &#50696;&#51228;1 (matplotlib) . df = pd.read_csv(&#39;https://raw.githubusercontent.com/kalilurrahman/datasets/main/mobilephonemktshare2020.csv&#39;) df . Date Samsung Apple Huawei Xiaomi Oppo Mobicel Motorola LG Others Realme Google Nokia Lenovo OnePlus Sony Asus . 0 2019-10 | 31.49 | 22.09 | 10.02 | 7.79 | 4.10 | 3.15 | 2.41 | 2.40 | 9.51 | 0.54 | 2.35 | 0.95 | 0.96 | 0.70 | 0.84 | 0.74 | . 1 2019-11 | 31.36 | 22.90 | 10.18 | 8.16 | 4.42 | 3.41 | 2.40 | 2.40 | 9.10 | 0.78 | 0.66 | 0.97 | 0.97 | 0.73 | 0.83 | 0.75 | . 2 2019-12 | 31.37 | 24.79 | 9.95 | 7.73 | 4.23 | 3.19 | 2.50 | 2.54 | 8.13 | 0.84 | 0.75 | 0.90 | 0.87 | 0.74 | 0.77 | 0.70 | . 3 2020-01 | 31.29 | 24.76 | 10.61 | 8.10 | 4.25 | 3.02 | 2.42 | 2.40 | 7.55 | 0.88 | 0.69 | 0.88 | 0.86 | 0.79 | 0.80 | 0.69 | . 4 2020-02 | 30.91 | 25.89 | 10.98 | 7.80 | 4.31 | 2.89 | 2.36 | 2.34 | 7.06 | 0.89 | 0.70 | 0.81 | 0.77 | 0.78 | 0.80 | 0.69 | . 5 2020-03 | 30.80 | 27.03 | 10.70 | 7.70 | 4.30 | 2.87 | 2.35 | 2.28 | 6.63 | 0.93 | 0.73 | 0.72 | 0.74 | 0.78 | 0.76 | 0.66 | . 6 2020-04 | 30.41 | 28.79 | 10.28 | 7.60 | 4.20 | 2.75 | 2.51 | 2.28 | 5.84 | 0.90 | 0.75 | 0.69 | 0.71 | 0.80 | 0.76 | 0.70 | . 7 2020-05 | 30.18 | 26.72 | 10.39 | 8.36 | 4.70 | 3.12 | 2.46 | 2.19 | 6.31 | 1.04 | 0.70 | 0.73 | 0.77 | 0.81 | 0.78 | 0.76 | . 8 2020-06 | 31.06 | 25.26 | 10.69 | 8.55 | 4.65 | 3.18 | 2.57 | 2.11 | 6.39 | 1.04 | 0.68 | 0.74 | 0.75 | 0.77 | 0.78 | 0.75 | . 9 2020-07 | 30.95 | 24.82 | 10.75 | 8.94 | 4.69 | 3.46 | 2.45 | 2.03 | 6.41 | 1.13 | 0.65 | 0.76 | 0.74 | 0.76 | 0.75 | 0.72 | . 10 2020-08 | 31.04 | 25.15 | 10.73 | 8.90 | 4.69 | 3.38 | 2.39 | 1.96 | 6.31 | 1.18 | 0.63 | 0.74 | 0.72 | 0.75 | 0.73 | 0.70 | . 11 2020-09 | 30.57 | 24.98 | 10.58 | 9.49 | 4.94 | 3.50 | 2.27 | 1.88 | 6.12 | 1.45 | 0.63 | 0.74 | 0.67 | 0.81 | 0.69 | 0.67 | . 12 2020-10 | 30.25 | 26.53 | 10.44 | 9.67 | 4.83 | 2.54 | 2.21 | 1.79 | 6.04 | 1.55 | 0.63 | 0.69 | 0.65 | 0.85 | 0.67 | 0.64 | . df.plot.bar(x=&#39;Date&#39;,y=[&#39;Samsung&#39;,&#39;Apple&#39;],figsize=(10,5)) . &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt; . df.plot.bar(x=&#39;Date&#39;,y=[&#39;Samsung&#39;,&#39;Apple&#39;],figsize=(10,5),width=0.8) . &lt;AxesSubplot:xlabel=&#39;Date&#39;&gt; . df.plot.barh(x=&#39;Date&#39;,y=[&#39;Samsung&#39;,&#39;Apple&#39;],figsize=(5,10)) . &lt;AxesSubplot:ylabel=&#39;Date&#39;&gt; . df.plot.bar(x=&#39;Date&#39;,figsize=(15,10),subplots=True,layout=(4,4),legend=False) . array([[&lt;AxesSubplot:title={&#39;center&#39;:&#39;Samsung&#39;}, xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;Apple&#39;}, xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;Huawei&#39;}, xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;Xiaomi&#39;}, xlabel=&#39;Date&#39;&gt;], [&lt;AxesSubplot:title={&#39;center&#39;:&#39;Oppo&#39;}, xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;Mobicel&#39;}, xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;Motorola&#39;}, xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;LG&#39;}, xlabel=&#39;Date&#39;&gt;], [&lt;AxesSubplot:title={&#39;center&#39;:&#39;Others&#39;}, xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;Realme&#39;}, xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;Google&#39;}, xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;Nokia&#39;}, xlabel=&#39;Date&#39;&gt;], [&lt;AxesSubplot:title={&#39;center&#39;:&#39;Lenovo&#39;}, xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;OnePlus&#39;}, xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;Sony&#39;}, xlabel=&#39;Date&#39;&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;Asus&#39;}, xlabel=&#39;Date&#39;&gt;]], dtype=object) . . df.melt(id_vars=&#39;Date&#39;) $ to$ wideform이였던 dateframe를 longform으로 바꾸면서 타이디한 데이터 . 이제 plotly를 벡엔드로 활용해보자 . . df . Date Samsung Apple Huawei Xiaomi Oppo Mobicel Motorola LG Others Realme Google Nokia Lenovo OnePlus Sony Asus . 0 2019-10 | 31.49 | 22.09 | 10.02 | 7.79 | 4.10 | 3.15 | 2.41 | 2.40 | 9.51 | 0.54 | 2.35 | 0.95 | 0.96 | 0.70 | 0.84 | 0.74 | . 1 2019-11 | 31.36 | 22.90 | 10.18 | 8.16 | 4.42 | 3.41 | 2.40 | 2.40 | 9.10 | 0.78 | 0.66 | 0.97 | 0.97 | 0.73 | 0.83 | 0.75 | . 2 2019-12 | 31.37 | 24.79 | 9.95 | 7.73 | 4.23 | 3.19 | 2.50 | 2.54 | 8.13 | 0.84 | 0.75 | 0.90 | 0.87 | 0.74 | 0.77 | 0.70 | . 3 2020-01 | 31.29 | 24.76 | 10.61 | 8.10 | 4.25 | 3.02 | 2.42 | 2.40 | 7.55 | 0.88 | 0.69 | 0.88 | 0.86 | 0.79 | 0.80 | 0.69 | . 4 2020-02 | 30.91 | 25.89 | 10.98 | 7.80 | 4.31 | 2.89 | 2.36 | 2.34 | 7.06 | 0.89 | 0.70 | 0.81 | 0.77 | 0.78 | 0.80 | 0.69 | . 5 2020-03 | 30.80 | 27.03 | 10.70 | 7.70 | 4.30 | 2.87 | 2.35 | 2.28 | 6.63 | 0.93 | 0.73 | 0.72 | 0.74 | 0.78 | 0.76 | 0.66 | . 6 2020-04 | 30.41 | 28.79 | 10.28 | 7.60 | 4.20 | 2.75 | 2.51 | 2.28 | 5.84 | 0.90 | 0.75 | 0.69 | 0.71 | 0.80 | 0.76 | 0.70 | . 7 2020-05 | 30.18 | 26.72 | 10.39 | 8.36 | 4.70 | 3.12 | 2.46 | 2.19 | 6.31 | 1.04 | 0.70 | 0.73 | 0.77 | 0.81 | 0.78 | 0.76 | . 8 2020-06 | 31.06 | 25.26 | 10.69 | 8.55 | 4.65 | 3.18 | 2.57 | 2.11 | 6.39 | 1.04 | 0.68 | 0.74 | 0.75 | 0.77 | 0.78 | 0.75 | . 9 2020-07 | 30.95 | 24.82 | 10.75 | 8.94 | 4.69 | 3.46 | 2.45 | 2.03 | 6.41 | 1.13 | 0.65 | 0.76 | 0.74 | 0.76 | 0.75 | 0.72 | . 10 2020-08 | 31.04 | 25.15 | 10.73 | 8.90 | 4.69 | 3.38 | 2.39 | 1.96 | 6.31 | 1.18 | 0.63 | 0.74 | 0.72 | 0.75 | 0.73 | 0.70 | . 11 2020-09 | 30.57 | 24.98 | 10.58 | 9.49 | 4.94 | 3.50 | 2.27 | 1.88 | 6.12 | 1.45 | 0.63 | 0.74 | 0.67 | 0.81 | 0.69 | 0.67 | . 12 2020-10 | 30.25 | 26.53 | 10.44 | 9.67 | 4.83 | 2.54 | 2.21 | 1.79 | 6.04 | 1.55 | 0.63 | 0.69 | 0.65 | 0.85 | 0.67 | 0.64 | . df.melt(id_vars=&#39;Date&#39;) . Date variable value . 0 2019-10 | Samsung | 31.49 | . 1 2019-11 | Samsung | 31.36 | . 2 2019-12 | Samsung | 31.37 | . 3 2020-01 | Samsung | 31.29 | . 4 2020-02 | Samsung | 30.91 | . ... ... | ... | ... | . 203 2020-06 | Asus | 0.75 | . 204 2020-07 | Asus | 0.72 | . 205 2020-08 | Asus | 0.70 | . 206 2020-09 | Asus | 0.67 | . 207 2020-10 | Asus | 0.64 | . 208 rows × 3 columns . df.melt(id_vars=&#39;Date&#39;).groupby(&#39;variable&#39;).agg(np.mean) . value . variable . Apple 25.362308 | . Asus 0.705385 | . Google 0.811538 | . Huawei 10.484615 | . LG 2.200000 | . Lenovo 0.783077 | . Mobicel 3.112308 | . Motorola 2.407692 | . Nokia 0.793846 | . OnePlus 0.774615 | . Oppo 4.485385 | . Others 7.030769 | . Realme 1.011538 | . Samsung 30.898462 | . Sony 0.766154 | . Xiaomi 8.368462 | . df.melt(id_vars=&#39;Date&#39;).groupby(&#39;variable&#39;).agg(np.mean). plot.bar(legend=False) . &lt;AxesSubplot:xlabel=&#39;variable&#39;&gt; . df.melt(id_vars=&#39;Date&#39;).groupby(&#39;variable&#39;).agg(np.mean).sort_values(&#39;value&#39;,ascending=False). plot.bar(legend=False) . &lt;AxesSubplot:xlabel=&#39;variable&#39;&gt; . &#50696;&#51228;1 (plotly) . df.plot.bar(backend=&#39;plotly&#39;) . error 발생 $ to$ wideform은 plotly를 벡엔드로 활용 X . plotly는 이 블로그에서 지원하지 않으므로 주석처리 하겠음 | . # plot.bar(backend=&#39;plotly&#39;) . 위의 그림은 제조사의 평균 점유율을 날짜 별로 그린 것이고 아래 그림은 날짜별로 각 제조사의 점유율을 그린 것이기 때문에 각 날짜별로 제조사를 구분하기 위해서 색깔로 제조사를 구분해줄 필요가 있다 . # plot.bar(x=&#39;Date&#39;,y=&#39;value&#39;,color=&#39;variable&#39;,backend=&#39;plotly&#39;,width=500,height=600) . # plot.bar(x=&#39;Date&#39;,y=&#39;value&#39;,color=&#39;variable&#39;,backend=&#39;plotly&#39;,barmode=&#39;group&#39;) . # plot.bar(x=&#39;Date&#39;,y=&#39;value&#39;,color=&#39;variable&#39;,backend=&#39;plotly&#39;,barmode=&#39;group&#39;,text=&#39;value&#39;) . # plot.bar(x=&#39;Date&#39;,y=&#39;value&#39;,color=&#39;variable&#39;,backend=&#39;plotly&#39;,facet_col=&#39;variable&#39;) . # plot.bar(y=&#39;Date&#39;,x=&#39;value&#39;,color=&#39;variable&#39;,backend=&#39;plotly&#39;,facet_row=&#39;variable&#39;,height=700) .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/14/intro2.html",
            "relUrl": "/2022/01/14/intro2.html",
            "date": " • Jan 14, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "2022/01/13/THU",
            "content": "import pandas as pd df2016=pd.read_csv(&quot;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/stocks_2016.csv&quot;) df2017=pd.read_csv(&quot;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/stocks_2017.csv&quot;) df2018=pd.read_csv(&quot;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/stocks_2018.csv&quot;) . pd.concat([df2016,df2017,df2018]) # default는 아래로 쌓음 . Symbol Shares Low High . 0 AAPL | 80 | 95 | 110 | . 1 TSLA | 50 | 80 | 130 | . 2 WMT | 40 | 55 | 70 | . 0 AAPL | 50 | 120 | 140 | . 1 GE | 100 | 30 | 40 | . 2 IBM | 87 | 75 | 95 | . 3 SLB | 20 | 55 | 85 | . 4 TXN | 500 | 15 | 23 | . 5 TSLA | 100 | 100 | 300 | . 0 AAPL | 40 | 135 | 170 | . 1 AMZN | 8 | 900 | 1125 | . 2 TSLA | 50 | 220 | 400 | . pd.concat([df2016,df2017,df2018]).reset_index() # 구 인덱스는 아직 존재함 . index Symbol Shares Low High . 0 0 | AAPL | 80 | 95 | 110 | . 1 1 | TSLA | 50 | 80 | 130 | . 2 2 | WMT | 40 | 55 | 70 | . 3 0 | AAPL | 50 | 120 | 140 | . 4 1 | GE | 100 | 30 | 40 | . 5 2 | IBM | 87 | 75 | 95 | . 6 3 | SLB | 20 | 55 | 85 | . 7 4 | TXN | 500 | 15 | 23 | . 8 5 | TSLA | 100 | 100 | 300 | . 9 0 | AAPL | 40 | 135 | 170 | . 10 1 | AMZN | 8 | 900 | 1125 | . 11 2 | TSLA | 50 | 220 | 400 | . pd.concat([df2016,df2017,df2018]).reset_index(drop=True) . Symbol Shares Low High . 0 AAPL | 80 | 95 | 110 | . 1 TSLA | 50 | 80 | 130 | . 2 WMT | 40 | 55 | 70 | . 3 AAPL | 50 | 120 | 140 | . 4 GE | 100 | 30 | 40 | . 5 IBM | 87 | 75 | 95 | . 6 SLB | 20 | 55 | 85 | . 7 TXN | 500 | 15 | 23 | . 8 TSLA | 100 | 100 | 300 | . 9 AAPL | 40 | 135 | 170 | . 10 AMZN | 8 | 900 | 1125 | . 11 TSLA | 50 | 220 | 400 | . &#53945;&#51221; &#44396;&#44036;&#47564; &#48977;&#50500;&#49436; concat&#54616;&#44592; . pd.concat([df2016,df2017.iloc[:,1:]]) # df2017에서 선택되지 못한 자료인 0열은 자동으로 NaN처리 . Symbol Shares Low High . 0 AAPL | 80 | 95 | 110 | . 1 TSLA | 50 | 80 | 130 | . 2 WMT | 40 | 55 | 70 | . 0 NaN | 50 | 120 | 140 | . 1 NaN | 100 | 30 | 40 | . 2 NaN | 87 | 75 | 95 | . 3 NaN | 20 | 55 | 85 | . 4 NaN | 500 | 15 | 23 | . 5 NaN | 100 | 100 | 300 | . pd.concat([df2016,df2017,df2018],axis=&#39;columns&#39;) ## axis=&#39;columns&#39; axis=1로 가능/ 1대신에 0쓰면 rbind, 또는 그냥 aixs=0 안 써도 자동으로 rbind 처리 . Symbol Shares Low High Symbol Shares Low High Symbol Shares Low High . 0 AAPL | 80.0 | 95.0 | 110.0 | AAPL | 50 | 120 | 140 | AAPL | 40.0 | 135.0 | 170.0 | . 1 TSLA | 50.0 | 80.0 | 130.0 | GE | 100 | 30 | 40 | AMZN | 8.0 | 900.0 | 1125.0 | . 2 WMT | 40.0 | 55.0 | 70.0 | IBM | 87 | 75 | 95 | TSLA | 50.0 | 220.0 | 400.0 | . 3 NaN | NaN | NaN | NaN | SLB | 20 | 55 | 85 | NaN | NaN | NaN | NaN | . 4 NaN | NaN | NaN | NaN | TXN | 500 | 15 | 23 | NaN | NaN | NaN | NaN | . 5 NaN | NaN | NaN | NaN | TSLA | 100 | 100 | 300 | NaN | NaN | NaN | NaN | . df=pd.concat([df2016,df2017,df2018],keys=[2016,2017,2018]) df . Symbol Shares Low High . 2016 0 AAPL | 80 | 95 | 110 | . 1 TSLA | 50 | 80 | 130 | . 2 WMT | 40 | 55 | 70 | . 2017 0 AAPL | 50 | 120 | 140 | . 1 GE | 100 | 30 | 40 | . 2 IBM | 87 | 75 | 95 | . 3 SLB | 20 | 55 | 85 | . 4 TXN | 500 | 15 | 23 | . 5 TSLA | 100 | 100 | 300 | . 2018 0 AAPL | 40 | 135 | 170 | . 1 AMZN | 8 | 900 | 1125 | . 2 TSLA | 50 | 220 | 400 | . df.index . MultiIndex([(2016, 0), (2016, 1), (2016, 2), (2017, 0), (2017, 1), (2017, 2), (2017, 3), (2017, 4), (2017, 5), (2018, 0), (2018, 1), (2018, 2)], ) . $MuiliIndex$가 됐음을 알 수 있다. | . pd.concat({2016:df2016,2017:df2017,2018:df2018}) . Symbol Shares Low High . 2016 0 AAPL | 80 | 95 | 110 | . 1 TSLA | 50 | 80 | 130 | . 2 WMT | 40 | 55 | 70 | . 2017 0 AAPL | 50 | 120 | 140 | . 1 GE | 100 | 30 | 40 | . 2 IBM | 87 | 75 | 95 | . 3 SLB | 20 | 55 | 85 | . 4 TXN | 500 | 15 | 23 | . 5 TSLA | 100 | 100 | 300 | . 2018 0 AAPL | 40 | 135 | 170 | . 1 AMZN | 8 | 900 | 1125 | . 2 TSLA | 50 | 220 | 400 | . pd.concat(dict(zip([2016,2017,2018],[df2016,df2017,df2018]))) . Symbol Shares Low High . 2016 0 AAPL | 80 | 95 | 110 | . 1 TSLA | 50 | 80 | 130 | . 2 WMT | 40 | 55 | 70 | . 2017 0 AAPL | 50 | 120 | 140 | . 1 GE | 100 | 30 | 40 | . 2 IBM | 87 | 75 | 95 | . 3 SLB | 20 | 55 | 85 | . 4 TXN | 500 | 15 | 23 | . 5 TSLA | 100 | 100 | 300 | . 2018 0 AAPL | 40 | 135 | 170 | . 1 AMZN | 8 | 900 | 1125 | . 2 TSLA | 50 | 220 | 400 | . pd.concat([df2016,df2017,df2018],keys=[2016,2017]) . Symbol Shares Low High . 2016 0 AAPL | 80 | 95 | 110 | . 1 TSLA | 50 | 80 | 130 | . 2 WMT | 40 | 55 | 70 | . 2017 0 AAPL | 50 | 120 | 140 | . 1 GE | 100 | 30 | 40 | . 2 IBM | 87 | 75 | 95 | . 3 SLB | 20 | 55 | 85 | . 4 TXN | 500 | 15 | 23 | . 5 TSLA | 100 | 100 | 300 | . pd.concat([df2016,df2017,df2018],keys=[2016,2018]) #이렇게 해도 이름만 2018이지 데이터는 df2017로 불러오게 된다 . Symbol Shares Low High . 2016 0 AAPL | 80 | 95 | 110 | . 1 TSLA | 50 | 80 | 130 | . 2 WMT | 40 | 55 | 70 | . 2018 0 AAPL | 50 | 120 | 140 | . 1 GE | 100 | 30 | 40 | . 2 IBM | 87 | 75 | 95 | . 3 SLB | 20 | 55 | 85 | . 4 TXN | 500 | 15 | 23 | . 5 TSLA | 100 | 100 | 300 | . pd.concat([df2016,df2017,df2018],keys=[&#39;a&#39;,&#39;S&#39;,&#39;C&#39;,2019]) #2019는 그냥 아무처리도 못함 . Symbol Shares Low High . a 0 AAPL | 80 | 95 | 110 | . 1 TSLA | 50 | 80 | 130 | . 2 WMT | 40 | 55 | 70 | . S 0 AAPL | 50 | 120 | 140 | . 1 GE | 100 | 30 | 40 | . 2 IBM | 87 | 75 | 95 | . 3 SLB | 20 | 55 | 85 | . 4 TXN | 500 | 15 | 23 | . 5 TSLA | 100 | 100 | 300 | . C 0 AAPL | 40 | 135 | 170 | . 1 AMZN | 8 | 900 | 1125 | . 2 TSLA | 50 | 220 | 400 | . pd.concat([...],keys=[...],axis=&#39;columns&#39;) . df=pd.concat([df2016,df2017,df2018],axis=1,keys=[2016,2017,2018]) df . 2016 2017 2018 . Symbol Shares Low High Symbol Shares Low High Symbol Shares Low High . 0 AAPL | 80.0 | 95.0 | 110.0 | AAPL | 50 | 120 | 140 | AAPL | 40.0 | 135.0 | 170.0 | . 1 TSLA | 50.0 | 80.0 | 130.0 | GE | 100 | 30 | 40 | AMZN | 8.0 | 900.0 | 1125.0 | . 2 WMT | 40.0 | 55.0 | 70.0 | IBM | 87 | 75 | 95 | TSLA | 50.0 | 220.0 | 400.0 | . 3 NaN | NaN | NaN | NaN | SLB | 20 | 55 | 85 | NaN | NaN | NaN | NaN | . 4 NaN | NaN | NaN | NaN | TXN | 500 | 15 | 23 | NaN | NaN | NaN | NaN | . 5 NaN | NaN | NaN | NaN | TSLA | 100 | 100 | 300 | NaN | NaN | NaN | NaN | . df.columns . MultiIndex([(2016, &#39;Symbol&#39;), (2016, &#39;Shares&#39;), (2016, &#39;Low&#39;), (2016, &#39;High&#39;), (2017, &#39;Symbol&#39;), (2017, &#39;Shares&#39;), (2017, &#39;Low&#39;), (2017, &#39;High&#39;), (2018, &#39;Symbol&#39;), (2018, &#39;Shares&#39;), (2018, &#39;Low&#39;), (2018, &#39;High&#39;)], ) . column도 MultiIndex로 들어갔음 | . pd.concat({2016:df2016,2017:df2017,2018:df2018},axis=1) . 2016 2017 2018 . Symbol Shares Low High Symbol Shares Low High Symbol Shares Low High . 0 AAPL | 80.0 | 95.0 | 110.0 | AAPL | 50 | 120 | 140 | AAPL | 40.0 | 135.0 | 170.0 | . 1 TSLA | 50.0 | 80.0 | 130.0 | GE | 100 | 30 | 40 | AMZN | 8.0 | 900.0 | 1125.0 | . 2 WMT | 40.0 | 55.0 | 70.0 | IBM | 87 | 75 | 95 | TSLA | 50.0 | 220.0 | 400.0 | . 3 NaN | NaN | NaN | NaN | SLB | 20 | 55 | 85 | NaN | NaN | NaN | NaN | . 4 NaN | NaN | NaN | NaN | TXN | 500 | 15 | 23 | NaN | NaN | NaN | NaN | . 5 NaN | NaN | NaN | NaN | TSLA | 100 | 100 | 300 | NaN | NaN | NaN | NaN | . pd.concat(dict(zip([2016,2017,2018],[df2016,df2017,df2018])),axis=1) . 2016 2017 2018 . Symbol Shares Low High Symbol Shares Low High Symbol Shares Low High . 0 AAPL | 80.0 | 95.0 | 110.0 | AAPL | 50 | 120 | 140 | AAPL | 40.0 | 135.0 | 170.0 | . 1 TSLA | 50.0 | 80.0 | 130.0 | GE | 100 | 30 | 40 | AMZN | 8.0 | 900.0 | 1125.0 | . 2 WMT | 40.0 | 55.0 | 70.0 | IBM | 87 | 75 | 95 | TSLA | 50.0 | 220.0 | 400.0 | . 3 NaN | NaN | NaN | NaN | SLB | 20 | 55 | 85 | NaN | NaN | NaN | NaN | . 4 NaN | NaN | NaN | NaN | TXN | 500 | 15 | 23 | NaN | NaN | NaN | NaN | . 5 NaN | NaN | NaN | NaN | TSLA | 100 | 100 | 300 | NaN | NaN | NaN | NaN | . &#53440;&#51060;&#46356; &#45936;&#51060;&#53552; . df=pd.concat(dict(zip([2016,2017,2018],[df2016,df2017,df2018]))) df.stack().reset_index().drop([&#39;level_1&#39;],axis=1).rename(columns={&#39;level_0&#39;:&#39;year&#39;,&#39;level_2&#39;:&#39;category&#39;,0:&#39;value&#39;}) . year category value . 0 2016 | Symbol | AAPL | . 1 2016 | Shares | 80 | . 2 2016 | Low | 95 | . 3 2016 | High | 110 | . 4 2016 | Symbol | TSLA | . 5 2016 | Shares | 50 | . 6 2016 | Low | 80 | . 7 2016 | High | 130 | . 8 2016 | Symbol | WMT | . 9 2016 | Shares | 40 | . 10 2016 | Low | 55 | . 11 2016 | High | 70 | . 12 2017 | Symbol | AAPL | . 13 2017 | Shares | 50 | . 14 2017 | Low | 120 | . 15 2017 | High | 140 | . 16 2017 | Symbol | GE | . 17 2017 | Shares | 100 | . 18 2017 | Low | 30 | . 19 2017 | High | 40 | . 20 2017 | Symbol | IBM | . 21 2017 | Shares | 87 | . 22 2017 | Low | 75 | . 23 2017 | High | 95 | . 24 2017 | Symbol | SLB | . 25 2017 | Shares | 20 | . 26 2017 | Low | 55 | . 27 2017 | High | 85 | . 28 2017 | Symbol | TXN | . 29 2017 | Shares | 500 | . 30 2017 | Low | 15 | . 31 2017 | High | 23 | . 32 2017 | Symbol | TSLA | . 33 2017 | Shares | 100 | . 34 2017 | Low | 100 | . 35 2017 | High | 300 | . 36 2018 | Symbol | AAPL | . 37 2018 | Shares | 40 | . 38 2018 | Low | 135 | . 39 2018 | High | 170 | . 40 2018 | Symbol | AMZN | . 41 2018 | Shares | 8 | . 42 2018 | Low | 900 | . 43 2018 | High | 1125 | . 44 2018 | Symbol | TSLA | . 45 2018 | Shares | 50 | . 46 2018 | Low | 220 | . 47 2018 | High | 400 | .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/13/intro.html",
            "relUrl": "/2022/01/13/intro.html",
            "date": " • Jan 13, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "2022/01/12/WED",
            "content": "tidy data . import pandas as pd import numpy as np from plotnine import * import matplotlib.pyplot as plt . url = &#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/state_fruit.csv&#39; df=pd.read_csv(url) df . Unnamed: 0 Apple Orange Banana . 0 Texas | 12 | 10 | 40 | . 1 Arizona | 9 | 7 | 12 | . 2 Florida | 0 | 14 | 190 | . df=pd.read_csv(url,index_col=0) df . Apple Orange Banana . Texas 12 | 10 | 40 | . Arizona 9 | 7 | 12 | . Florida 0 | 14 | 190 | . df.stack() # 인덱스 기준으로 각 열 값 정리 . Texas Apple 12 Orange 10 Banana 40 Arizona Apple 9 Orange 7 Banana 12 Florida Apple 0 Orange 14 Banana 190 dtype: int64 . df.stack().reset_index().rename(columns={&#39;level_0&#39;:&#39;group1&#39;,&#39;level_1&#39;:&#39;group2&#39;,0:&#39;X&#39;}) . group1 group2 X . 0 Texas | Apple | 12 | . 1 Texas | Orange | 10 | . 2 Texas | Banana | 40 | . 3 Arizona | Apple | 9 | . 4 Arizona | Orange | 7 | . 5 Arizona | Banana | 12 | . 6 Florida | Apple | 0 | . 7 Florida | Orange | 14 | . 8 Florida | Banana | 190 | . df2=pd.read_csv(url) df2.rename(columns={&#39;Unnamed: 0&#39;:&#39;group1&#39;}) . group1 Apple Orange Banana . 0 Texas | 12 | 10 | 40 | . 1 Arizona | 9 | 7 | 12 | . 2 Florida | 0 | 14 | 190 | . df2.rename(columns={&#39;Unnamed: 0&#39;:&#39;group1&#39;}).melt(id_vars=&#39;group1&#39;) . group1 variable value . 0 Texas | Apple | 12 | . 1 Arizona | Apple | 9 | . 2 Florida | Apple | 0 | . 3 Texas | Orange | 10 | . 4 Arizona | Orange | 7 | . 5 Florida | Orange | 14 | . 6 Texas | Banana | 40 | . 7 Arizona | Banana | 12 | . 8 Florida | Banana | 190 | . df2.rename(columns={&#39;Unnamed: 0&#39;:&#39;group1&#39;}).melt(id_vars=&#39;group1&#39;) .rename(columns={&#39;variable&#39;:&#39;group2&#39;,&#39;value&#39;:&#39;X&#39;}) . group1 group2 X . 0 Texas | Apple | 12 | . 1 Arizona | Apple | 9 | . 2 Florida | Apple | 0 | . 3 Texas | Orange | 10 | . 4 Arizona | Orange | 7 | . 5 Florida | Orange | 14 | . 6 Texas | Banana | 40 | . 7 Arizona | Banana | 12 | . 8 Florida | Banana | 190 | . df=pd.read_csv(url,index_col=0) df . Apple Orange Banana . Texas 12 | 10 | 40 | . Arizona 9 | 7 | 12 | . Florida 0 | 14 | 190 | . df.reset_index() . index Apple Orange Banana . 0 Texas | 12 | 10 | 40 | . 1 Arizona | 9 | 7 | 12 | . 2 Florida | 0 | 14 | 190 | . df.reset_index().melt(id_vars=&#39;index&#39;) .rename(columns={&#39;index&#39;:&#39;group1&#39;,&#39;variable&#39;:&#39;group2&#39;,&#39;value&#39;:&#39;X&#39;}) . group1 group2 X . 0 Texas | Apple | 12 | . 1 Arizona | Apple | 9 | . 2 Florida | Apple | 0 | . 3 Texas | Orange | 10 | . 4 Arizona | Orange | 7 | . 5 Florida | Orange | 14 | . 6 Texas | Banana | 40 | . 7 Arizona | Banana | 12 | . 8 Florida | Banana | 190 | . df2=pd.read_csv(url) df2 . Unnamed: 0 Apple Orange Banana . 0 Texas | 12 | 10 | 40 | . 1 Arizona | 9 | 7 | 12 | . 2 Florida | 0 | 14 | 190 | . df2.set_index(&#39;Unnamed: 0&#39;) . Apple Orange Banana . Unnamed: 0 . Texas 12 | 10 | 40 | . Arizona 9 | 7 | 12 | . Florida 0 | 14 | 190 | . df2.set_index(&#39;Unnamed: 0&#39;).stack() . Unnamed: 0 Texas Apple 12 Orange 10 Banana 40 Arizona Apple 9 Orange 7 Banana 12 Florida Apple 0 Orange 14 Banana 190 dtype: int64 . df2.set_index(&#39;Unnamed: 0&#39;).stack().reset_index() .rename(columns={&#39;Unnamed: 0&#39;:&#39;group1&#39;,&#39;level_1&#39;:&#39;group2&#39;,0:&#39;X&#39;}) . group1 group2 X . 0 Texas | Apple | 12 | . 1 Texas | Orange | 10 | . 2 Texas | Banana | 40 | . 3 Arizona | Apple | 9 | . 4 Arizona | Orange | 7 | . 5 Arizona | Banana | 12 | . 6 Florida | Apple | 0 | . 7 Florida | Orange | 14 | . 8 Florida | Banana | 190 | . Barplot + &#54644;&#46308;&#47532;&#50948;&#52980;&#51032; &#44536;&#47000;&#54532;&#47112;&#51060;&#50612; . g=[&#39;A&#39;]*100+[&#39;B&#39;]*200 # df에 넣어줄 땐 list y=list(np.random.randn(100)*2+2)+list(np.random.randn(200)+3) # df에 넣어줄 땐 list df=pd.DataFrame({&#39;g&#39;:g,&#39;y&#39;:y}) df . g y . 0 A | 1.052926 | . 1 A | 0.918170 | . 2 A | 4.508794 | . 3 A | 3.343357 | . 4 A | 5.346823 | . ... ... | ... | . 295 B | 4.618109 | . 296 B | 3.721053 | . 297 B | 3.649687 | . 298 B | 0.368584 | . 299 B | 2.664331 | . 300 rows × 2 columns . ggplot(df)+geom_bar(aes(x=&#39;g&#39;,fill=&#39;g&#39;)) # 디폴트로 Y축은 A와 B의 개수 카운트로 수행 -&gt; 100,200개 . &lt;ggplot: (144141037442)&gt; . df.groupby(by=&#39;g&#39;).count() . y . g . A 100 | . B 200 | . df.groupby(by=&#39;g&#39;).count().reset_index() . g y . 0 A | 100 | . 1 B | 200 | . fig=ggplot(df.groupby(by=&#39;g&#39;).count().reset_index()) fig+geom_bar(aes(x=&#39;g&#39;,y=&#39;y&#39;,fill=&#39;g&#39;),stat=&#39;identity&#39;) # stat=&#39;identity&#39; (값을 그대로 사용하라는 파라미터) . &lt;ggplot: (144140819628)&gt; . ggplot(df)+geom_bar(aes(x=&#39;g&#39;,fill=&#39;g&#39;),stat=&#39;count&#39;) # stat=&#39;count&#39; =&gt; 굳이 작성을 안 해줘도 동일한 결과를 얻을 수 있음, 디폴트로 count가 실행되기 때문 . &lt;ggplot: (144140709386)&gt; . . td=df.groupby(by=&#39;g&#39;).count().reset_index() td . g y . 0 A | 100 | . 1 B | 200 | . plt.bar(td.g,td.y) . &lt;BarContainer object of 2 artists&gt; . td.plot(kind=&#39;bar&#39;,x=&#39;g&#39;,y=&#39;y&#39;) . &lt;AxesSubplot:xlabel=&#39;g&#39;&gt; . df.groupby(&#39;g&#39;).agg({&#39;y&#39;:[np.mean,np.median,np.std,lambda x: np.max(x)-np.min(x)]}) . y . mean median std &lt;lambda_0&gt; . g . A 2.057996 | 1.996399 | 2.070265 | 11.788106 | . B 2.912674 | 2.855547 | 0.987115 | 5.194664 | . df.groupby(&#39;g&#39;) .agg({&#39;y&#39;:[np.mean,np.median,np.std,lambda x: np.max(x)-np.min(x)]}) .rename(columns={&#39;&lt;lambda_0&gt;&#39;:&#39;range&#39;}).stack() # index기준으로 자료들을 stack한다고 생각하면 됨 . y . g . A mean 2.057996 | . median 1.996399 | . range 11.788106 | . std 2.070265 | . B mean 2.912674 | . median 2.855547 | . range 5.194664 | . std 0.987115 | . df.groupby(&#39;g&#39;) .agg({&#39;y&#39;:[np.mean,np.median,np.std,lambda x: np.max(x)-np.min(x)]}) .rename(columns={&#39;&lt;lambda_0&gt;&#39;:&#39;range&#39;}).stack().reset_index() . g level_1 y . 0 A | mean | 2.057996 | . 1 A | median | 1.996399 | . 2 A | range | 11.788106 | . 3 A | std | 2.070265 | . 4 B | mean | 2.912674 | . 5 B | median | 2.855547 | . 6 B | range | 5.194664 | . 7 B | std | 0.987115 | . td=df.groupby(&#39;g&#39;) .agg({&#39;y&#39;:[np.mean,np.median,np.std,lambda x: np.max(x)-np.min(x)]}) .rename(columns={&#39;&lt;lambda_0&gt;&#39;:&#39;range&#39;}).stack().reset_index() . td . g level_1 y . 0 A | mean | 2.057996 | . 1 A | median | 1.996399 | . 2 A | range | 11.788106 | . 3 A | std | 2.070265 | . 4 B | mean | 2.912674 | . 5 B | median | 2.855547 | . 6 B | range | 5.194664 | . 7 B | std | 0.987115 | . ggplot(td)+geom_bar(aes(x=&#39;level_1&#39;,y=&#39;y&#39;,fill=&#39;g&#39;),stat=&#39;identity&#39;) . &lt;ggplot: (144144674551)&gt; . ggplot(td)+geom_bar(aes(x=&#39;level_1&#39;,y=&#39;y&#39;,fill=&#39;g&#39;),stat=&#39;identity&#39;,position=&#39;dodge&#39;) . &lt;ggplot: (144144787038)&gt; . ggplot(td) +geom_bar(aes(x=&#39;level_1&#39;,y=&#39;y&#39;,fill=&#39;g&#39;),stat=&#39;identity&#39;,position=&#39;dodge&#39;) +coord_flip() . &lt;ggplot: (144144704871)&gt; . ggplot(td) +geom_bar(aes(x=&#39;level_1&#39;,y=&#39;y&#39;,fill=&#39;g&#39;),stat=&#39;identity&#39;,position=&#39;dodge&#39;) +coord_flip()+facet_wrap(&#39;level_1&#39;) . &lt;ggplot: (144144737437)&gt; . td . g level_1 y . 0 A | mean | 2.057996 | . 1 A | median | 1.996399 | . 2 A | range | 11.788106 | . 3 A | std | 2.070265 | . 4 B | mean | 2.912674 | . 5 B | median | 2.855547 | . 6 B | range | 5.194664 | . 7 B | std | 0.987115 | . ggplot(td) +geom_bar(aes(x=&#39;g&#39;,y=&#39;y&#39;,fill=&#39;g&#39;),stat=&#39;identity&#39;,position=&#39;dodge&#39;) +coord_flip() . &lt;ggplot: (144144676343)&gt; . ggplot(td) +geom_bar(aes(x=&#39;g&#39;,y=&#39;y&#39;,fill=&#39;g&#39;),stat=&#39;identity&#39;,position=&#39;dodge&#39;) +coord_flip()+facet_wrap(&#39;level_1&#39;) . &lt;ggplot: (144146538201)&gt; . facet_grid $ to$ (y~x) &#44852; . td . g level_1 y . 0 A | mean | 2.057996 | . 1 A | median | 1.996399 | . 2 A | range | 11.788106 | . 3 A | std | 2.070265 | . 4 B | mean | 2.912674 | . 5 B | median | 2.855547 | . 6 B | range | 5.194664 | . 7 B | std | 0.987115 | . ggplot(td)+facet_grid(&#39;level_1~g&#39;) +geom_bar(aes(x=&#39;g&#39;,y=&#39;y&#39;,fill=&#39;g&#39;),stat=&#39;identity&#39;)+coord_flip() . &lt;ggplot: (144146386439)&gt; . &#49900;&#49832;&#51032; &#50669;&#49444; . DEP=([&#39;A1&#39;]*2+[&#39;A2&#39;]*2+[&#39;B1&#39;]*2+[&#39;B2&#39;]*2)*2 GEN=[&#39;M&#39;]*8+[&#39;F&#39;]*8 STATE=[&#39;PASS&#39;,&#39;FAIL&#39;]*8 COUNT=[1,9,2,8,80,20,85,15,5,5,5,5,9,1,9,1] df=pd.DataFrame({&#39;DEP&#39;:DEP,&#39;STATE&#39;:STATE,&#39;GEN&#39;:GEN,&#39;COUNT&#39;:COUNT}) df . DEP STATE GEN COUNT . 0 A1 | PASS | M | 1 | . 1 A1 | FAIL | M | 9 | . 2 A2 | PASS | M | 2 | . 3 A2 | FAIL | M | 8 | . 4 B1 | PASS | M | 80 | . 5 B1 | FAIL | M | 20 | . 6 B2 | PASS | M | 85 | . 7 B2 | FAIL | M | 15 | . 8 A1 | PASS | F | 5 | . 9 A1 | FAIL | F | 5 | . 10 A2 | PASS | F | 5 | . 11 A2 | FAIL | F | 5 | . 12 B1 | PASS | F | 9 | . 13 B1 | FAIL | F | 1 | . 14 B2 | PASS | F | 9 | . 15 B2 | FAIL | F | 1 | . &#49884;&#44033;&#54868;1 : &#49457;&#48324; &#51204;&#52404;&#54633;&#44201;&#47456; . df.groupby([&#39;GEN&#39;,&#39;STATE&#39;]).agg({&#39;COUNT&#39;:np.sum}) . COUNT . GEN STATE . F FAIL 12 | . PASS 28 | . M FAIL 52 | . PASS 168 | . df.groupby([&#39;GEN&#39;,&#39;STATE&#39;]).agg({&#39;COUNT&#39;:np.sum}).index . MultiIndex([(&#39;F&#39;, &#39;FAIL&#39;), (&#39;F&#39;, &#39;PASS&#39;), (&#39;M&#39;, &#39;FAIL&#39;), (&#39;M&#39;, &#39;PASS&#39;)], names=[&#39;GEN&#39;, &#39;STATE&#39;]) . index가 tuple로 MultiIndex로 들어가있음 | . df.groupby([&#39;GEN&#39;,&#39;STATE&#39;]).agg({&#39;COUNT&#39;:np.sum}).reset_index() . GEN STATE COUNT . 0 F | FAIL | 12 | . 1 F | PASS | 28 | . 2 M | FAIL | 52 | . 3 M | PASS | 168 | . df.groupby([&#39;GEN&#39;]).agg({&#39;COUNT&#39;:np.sum}).reset_index().rename(columns={&#39;COUNT&#39;:&#39;SUM&#39;}) . GEN SUM . 0 F | 40 | . 1 M | 220 | . . _df1=df.groupby([&#39;GEN&#39;,&#39;STATE&#39;]).agg({&#39;COUNT&#39;:np.sum}).reset_index() _df2=df.groupby([&#39;GEN&#39;]).agg({&#39;COUNT&#39;:np.sum}).reset_index().rename(columns={&#39;COUNT&#39;:&#39;SUM&#39;}) . 방법 1 . def f(x): if x==&#39;F&#39;: return 40 if x==&#39;M&#39;: return 220 . _df1[&#39;SUM&#39;]=list(map(f,_df1.GEN)) _df1 . GEN STATE COUNT SUM . 0 F | FAIL | 12 | 40 | . 1 F | PASS | 28 | 40 | . 2 M | FAIL | 52 | 220 | . 3 M | PASS | 168 | 220 | . - 방법 2 . _df1=df.groupby([&#39;GEN&#39;,&#39;STATE&#39;]).agg({&#39;COUNT&#39;:np.sum}).reset_index() . _df1 . GEN STATE COUNT . 0 F | FAIL | 12 | . 1 F | PASS | 28 | . 2 M | FAIL | 52 | . 3 M | PASS | 168 | . _df2 . GEN SUM . 0 F | 40 | . 1 M | 220 | . def f(x): return lambda x: _df2.query(&#39;GEN == @x&#39;).SUM.item() . _df1[&#39;SUM&#39;]=list(map(f(_df1.GEN),_df1.GEN)) _df1 . GEN STATE COUNT SUM . 0 F | FAIL | 12 | 40 | . 1 F | PASS | 28 | 40 | . 2 M | FAIL | 52 | 220 | . 3 M | PASS | 168 | 220 | . - 방법 3 . _df1=df.groupby([&#39;GEN&#39;,&#39;STATE&#39;]).agg({&#39;COUNT&#39;:np.sum}).reset_index() . pd.merge(_df1,_df2) _df1.merge(_df2) _df2.merge(_df1) . . td=_df2.merge(_df1) . td . GEN SUM STATE COUNT . 0 F | 40 | FAIL | 12 | . 1 F | 40 | PASS | 28 | . 2 M | 220 | FAIL | 52 | . 3 M | 220 | PASS | 168 | . td[&#39;PROP&#39;]=td.COUNT/td.SUM td . GEN SUM STATE COUNT PROP . 0 F | 40 | FAIL | 12 | 0.300000 | . 1 F | 40 | PASS | 28 | 0.700000 | . 2 M | 220 | FAIL | 52 | 0.236364 | . 3 M | 220 | PASS | 168 | 0.763636 | . ggplot(td.query(&#39;STATE==&quot;PASS&quot;&#39;))+geom_bar(aes(x=&#39;GEN&#39;,y=&#39;PROP&#39;,fill=&#39;GEN&#39;),stat=&#39;identity&#39;) . &lt;ggplot: (144145134400)&gt; . &#49884;&#44033;&#54868;2: &#54617;&#44284;&#48324; &#49457;&#48324;&#50640; &#46384;&#47480; &#54633;&#44201;&#47456; . df . DEP STATE GEN COUNT . 0 A1 | PASS | M | 1 | . 1 A1 | FAIL | M | 9 | . 2 A2 | PASS | M | 2 | . 3 A2 | FAIL | M | 8 | . 4 B1 | PASS | M | 80 | . 5 B1 | FAIL | M | 20 | . 6 B2 | PASS | M | 85 | . 7 B2 | FAIL | M | 15 | . 8 A1 | PASS | F | 5 | . 9 A1 | FAIL | F | 5 | . 10 A2 | PASS | F | 5 | . 11 A2 | FAIL | F | 5 | . 12 B1 | PASS | F | 9 | . 13 B1 | FAIL | F | 1 | . 14 B2 | PASS | F | 9 | . 15 B2 | FAIL | F | 1 | . td=df.groupby([&#39;DEP&#39;,&#39;GEN&#39;]).agg({&#39;COUNT&#39;:sum}).reset_index() .rename(columns={&#39;COUNT&#39;:&#39;SUM&#39;}).merge(df) td . DEP GEN SUM STATE COUNT . 0 A1 | F | 10 | PASS | 5 | . 1 A1 | F | 10 | FAIL | 5 | . 2 A1 | M | 10 | PASS | 1 | . 3 A1 | M | 10 | FAIL | 9 | . 4 A2 | F | 10 | PASS | 5 | . 5 A2 | F | 10 | FAIL | 5 | . 6 A2 | M | 10 | PASS | 2 | . 7 A2 | M | 10 | FAIL | 8 | . 8 B1 | F | 10 | PASS | 9 | . 9 B1 | F | 10 | FAIL | 1 | . 10 B1 | M | 100 | PASS | 80 | . 11 B1 | M | 100 | FAIL | 20 | . 12 B2 | F | 10 | PASS | 9 | . 13 B2 | F | 10 | FAIL | 1 | . 14 B2 | M | 100 | PASS | 85 | . 15 B2 | M | 100 | FAIL | 15 | . td[&#39;PROP&#39;]=td.COUNT/td.SUM td . DEP GEN SUM STATE COUNT PROP . 0 A1 | F | 10 | PASS | 5 | 0.50 | . 1 A1 | F | 10 | FAIL | 5 | 0.50 | . 2 A1 | M | 10 | PASS | 1 | 0.10 | . 3 A1 | M | 10 | FAIL | 9 | 0.90 | . 4 A2 | F | 10 | PASS | 5 | 0.50 | . 5 A2 | F | 10 | FAIL | 5 | 0.50 | . 6 A2 | M | 10 | PASS | 2 | 0.20 | . 7 A2 | M | 10 | FAIL | 8 | 0.80 | . 8 B1 | F | 10 | PASS | 9 | 0.90 | . 9 B1 | F | 10 | FAIL | 1 | 0.10 | . 10 B1 | M | 100 | PASS | 80 | 0.80 | . 11 B1 | M | 100 | FAIL | 20 | 0.20 | . 12 B2 | F | 10 | PASS | 9 | 0.90 | . 13 B2 | F | 10 | FAIL | 1 | 0.10 | . 14 B2 | M | 100 | PASS | 85 | 0.85 | . 15 B2 | M | 100 | FAIL | 15 | 0.15 | . ggplot(td.query(&#39;STATE==&quot;PASS&quot;&#39;)) +geom_bar(aes(x=&#39;GEN&#39;,y=&#39;PROP&#39;,fill=&#39;GEN&#39;),stat=&#39;identity&#39;) +facet_wrap(&#39;DEP&#39;) . &lt;ggplot: (129899444131)&gt; .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/12/intro2.html",
            "relUrl": "/2022/01/12/intro2.html",
            "date": " • Jan 12, 2022"
        }
        
    
  
    
        ,"post8": {
            "title": "2022/01/11/TUE",
            "content": "import numpy as np import pandas as pd df=pd.read_csv(&#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/flights.csv&#39;) . groupby . df.head(2) . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 0 1 | 1 | 4 | WN | LAX | SLC | 1625 | 58.0 | 94.0 | 590 | 1905 | 65.0 | 0 | 0 | . 1 1 | 1 | 4 | UA | DEN | IAD | 823 | 7.0 | 154.0 | 1452 | 1333 | -13.0 | 0 | 0 | . grouped_df = df.groupby(by=&#39;AIRLINE&#39;) # 데이터프레임을 각 항공사 별로 나눔 . grouped_df.get_group(&#39;AA&#39;) # groupby로 나눈 표에서 AA만 얻을 때 . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 3 1 | 1 | 4 | AA | DFW | DCA | 1555 | 7.0 | 126.0 | 1192 | 1935 | -7.0 | 0 | 0 | . 6 1 | 1 | 4 | AA | DFW | MSY | 1250 | 84.0 | 64.0 | 447 | 1410 | 83.0 | 0 | 0 | . 8 1 | 1 | 4 | AA | ORD | STL | 1845 | -5.0 | 44.0 | 258 | 1950 | -5.0 | 0 | 0 | . 15 1 | 1 | 4 | AA | DEN | DFW | 1445 | -6.0 | 93.0 | 641 | 1745 | 4.0 | 0 | 0 | . 26 1 | 1 | 4 | AA | LAX | AUS | 1430 | 33.0 | 157.0 | 1242 | 1925 | 41.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58470 12 | 31 | 4 | AA | DFW | FAT | 1020 | -3.0 | 196.0 | 1313 | 1156 | -2.0 | 0 | 0 | . 58475 12 | 31 | 4 | AA | IAH | CLT | 710 | 1.0 | 113.0 | 912 | 1037 | -12.0 | 0 | 0 | . 58476 12 | 31 | 4 | AA | DFW | TPA | 1020 | -3.0 | 121.0 | 929 | 1340 | -6.0 | 0 | 0 | . 58479 12 | 31 | 4 | AA | DFW | ELP | 1200 | 3.0 | 94.0 | 551 | 1250 | 13.0 | 0 | 0 | . 58487 12 | 31 | 4 | AA | SFO | DFW | 515 | 5.0 | 166.0 | 1464 | 1045 | -19.0 | 0 | 0 | . 8900 rows × 14 columns . grouped_df.groups . 각 항공사별 data가 어떤 행에 들어가 있는지 dict형태로 들어가있음 | . for a in grouped_df.groups: print(a) # 각 표마다 위에 항공사 이름 표기 display(grouped_df.get_group(a)) # 항공사 별 df를 얻을 수 있음 . AA . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 3 1 | 1 | 4 | AA | DFW | DCA | 1555 | 7.0 | 126.0 | 1192 | 1935 | -7.0 | 0 | 0 | . 6 1 | 1 | 4 | AA | DFW | MSY | 1250 | 84.0 | 64.0 | 447 | 1410 | 83.0 | 0 | 0 | . 8 1 | 1 | 4 | AA | ORD | STL | 1845 | -5.0 | 44.0 | 258 | 1950 | -5.0 | 0 | 0 | . 15 1 | 1 | 4 | AA | DEN | DFW | 1445 | -6.0 | 93.0 | 641 | 1745 | 4.0 | 0 | 0 | . 26 1 | 1 | 4 | AA | LAX | AUS | 1430 | 33.0 | 157.0 | 1242 | 1925 | 41.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58470 12 | 31 | 4 | AA | DFW | FAT | 1020 | -3.0 | 196.0 | 1313 | 1156 | -2.0 | 0 | 0 | . 58475 12 | 31 | 4 | AA | IAH | CLT | 710 | 1.0 | 113.0 | 912 | 1037 | -12.0 | 0 | 0 | . 58476 12 | 31 | 4 | AA | DFW | TPA | 1020 | -3.0 | 121.0 | 929 | 1340 | -6.0 | 0 | 0 | . 58479 12 | 31 | 4 | AA | DFW | ELP | 1200 | 3.0 | 94.0 | 551 | 1250 | 13.0 | 0 | 0 | . 58487 12 | 31 | 4 | AA | SFO | DFW | 515 | 5.0 | 166.0 | 1464 | 1045 | -19.0 | 0 | 0 | . 8900 rows × 14 columns . AS . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 38 1 | 1 | 4 | AS | PHX | SEA | 1505 | -2.0 | 155.0 | 1107 | 1702 | -3.0 | 0 | 0 | . 198 1 | 2 | 5 | AS | LAX | SEA | 2110 | 5.0 | 145.0 | 954 | 2352 | 8.0 | 0 | 0 | . 241 1 | 2 | 5 | AS | LAS | PDX | 650 | -5.0 | 117.0 | 763 | 906 | -3.0 | 0 | 0 | . 277 1 | 2 | 5 | AS | ORD | ANC | 935 | -1.0 | 402.0 | 2846 | 1339 | -6.0 | 0 | 0 | . 397 1 | 3 | 6 | AS | LAS | SEA | 1300 | 48.0 | 137.0 | 867 | 1535 | 47.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58305 12 | 30 | 3 | AS | LAX | SEA | 1325 | -2.0 | 134.0 | 954 | 1608 | -7.0 | 0 | 0 | . 58355 12 | 31 | 4 | AS | PHX | SEA | 1200 | -5.0 | 145.0 | 1107 | 1407 | -24.0 | 0 | 0 | . 58404 12 | 31 | 4 | AS | SFO | SLC | 2110 | -2.0 | 80.0 | 599 | 2358 | -4.0 | 0 | 0 | . 58407 12 | 31 | 4 | AS | SFO | PDX | 645 | -2.0 | 81.0 | 550 | 832 | -3.0 | 0 | 0 | . 58428 12 | 31 | 4 | AS | LAX | SEA | 1420 | -8.0 | 127.0 | 954 | 1709 | -25.0 | 0 | 0 | . 768 rows × 14 columns . B6 . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 123 1 | 1 | 4 | B6 | LAS | BOS | 1230 | 0.0 | 246.0 | 2381 | 2026 | -27.0 | 0 | 0 | . 127 1 | 1 | 4 | B6 | LAS | BOS | 2359 | 68.0 | 247.0 | 2381 | 749 | 46.0 | 0 | 0 | . 239 1 | 2 | 5 | B6 | ORD | BOS | 540 | -8.0 | 96.0 | 867 | 856 | -22.0 | 0 | 0 | . 333 1 | 3 | 6 | B6 | LAX | FLL | 2237 | 32.0 | 270.0 | 2342 | 619 | 42.0 | 0 | 0 | . 548 1 | 4 | 7 | B6 | SFO | FLL | 2307 | -4.0 | 298.0 | 2583 | 724 | -1.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58262 12 | 30 | 3 | B6 | SFO | LGB | 1921 | -6.0 | 57.0 | 354 | 2038 | -14.0 | 0 | 0 | . 58301 12 | 30 | 3 | B6 | LAX | JFK | 630 | 4.0 | 285.0 | 2475 | 1445 | -6.0 | 0 | 0 | . 58425 12 | 31 | 4 | B6 | ORD | SJU | 700 | 239.0 | 250.0 | 2072 | 1335 | 239.0 | 0 | 0 | . 58477 12 | 31 | 4 | B6 | DFW | BOS | 1145 | 12.0 | 161.0 | 1562 | 1608 | -14.0 | 0 | 0 | . 58483 12 | 31 | 4 | B6 | PHX | BOS | 2236 | -12.0 | 231.0 | 2300 | 515 | -45.0 | 0 | 0 | . 543 rows × 14 columns . DL . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 53 1 | 1 | 4 | DL | LAS | MSP | 713 | -5.0 | 156.0 | 1299 | 1220 | -18.0 | 0 | 0 | . 57 1 | 1 | 4 | DL | MSP | RSW | 700 | -1.0 | 169.0 | 1416 | 1130 | -20.0 | 0 | 0 | . 77 1 | 1 | 4 | DL | LAX | ATL | 1130 | 24.0 | 217.0 | 1947 | 1840 | 16.0 | 0 | 0 | . 79 1 | 1 | 4 | DL | LAX | CMH | 2146 | -3.0 | 223.0 | 1995 | 459 | -13.0 | 0 | 0 | . 85 1 | 1 | 4 | DL | ATL | OKC | 2059 | -4.0 | 116.0 | 761 | 2227 | -12.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58440 12 | 31 | 4 | DL | ATL | CVG | 1611 | -4.0 | 61.0 | 373 | 1736 | -6.0 | 0 | 0 | . 58448 12 | 31 | 4 | DL | ATL | SRQ | 1610 | 0.0 | 61.0 | 444 | 1740 | -13.0 | 0 | 0 | . 58464 12 | 31 | 4 | DL | LAX | SFO | 700 | 108.0 | 54.0 | 337 | 825 | 105.0 | 0 | 0 | . 58467 12 | 31 | 4 | DL | ATL | IND | 1235 | -3.0 | 63.0 | 432 | 1407 | -13.0 | 0 | 0 | . 58485 12 | 31 | 4 | DL | ATL | CMH | 2206 | 2.0 | 64.0 | 447 | 2338 | -8.0 | 0 | 0 | . 10601 rows × 14 columns . EV . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 11 1 | 1 | 4 | EV | ORD | JAN | 1155 | 6.0 | 113.0 | 677 | 1403 | 5.0 | 0 | 0 | . 13 1 | 1 | 4 | EV | ORD | CMH | 1010 | -2.0 | 46.0 | 296 | 1228 | -9.0 | 0 | 0 | . 29 1 | 1 | 4 | EV | ORD | IND | 1025 | -6.0 | 29.0 | 177 | 1228 | -19.0 | 0 | 0 | . 40 1 | 1 | 4 | EV | IAH | CLE | 1038 | -3.0 | 126.0 | 1091 | 1425 | -18.0 | 0 | 0 | . 69 1 | 1 | 4 | EV | ATL | RAP | 1930 | -5.0 | 181.0 | 1230 | 2104 | -15.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58445 12 | 31 | 4 | EV | DFW | TXK | 850 | -5.0 | 30.0 | 181 | 948 | -17.0 | 0 | 0 | . 58452 12 | 31 | 4 | EV | DFW | SHV | 1650 | -4.0 | 32.0 | 190 | 1746 | -12.0 | 0 | 0 | . 58459 12 | 31 | 4 | EV | MSP | ORD | 1435 | 18.0 | 61.0 | 334 | 1609 | 3.0 | 0 | 0 | . 58463 12 | 31 | 4 | EV | ORD | MSN | 1220 | 18.0 | 32.0 | 108 | 1319 | 27.0 | 0 | 0 | . 58486 12 | 31 | 4 | EV | DFW | LFT | 850 | 21.0 | 52.0 | 351 | 1012 | 14.0 | 0 | 0 | . 5858 rows × 14 columns . F9 . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 7 1 | 1 | 4 | F9 | SFO | PHX | 1020 | -7.0 | 91.0 | 651 | 1315 | -6.0 | 0 | 0 | . 93 1 | 1 | 4 | F9 | ATL | DEN | 859 | 16.0 | 181.0 | 1199 | 1026 | 10.0 | 0 | 0 | . 209 1 | 2 | 5 | F9 | MSP | DEN | 1025 | -6.0 | 97.0 | 680 | 1134 | -13.0 | 0 | 0 | . 232 1 | 2 | 5 | F9 | DEN | PHX | 2040 | -7.0 | 83.0 | 602 | 2228 | -18.0 | 0 | 0 | . 247 1 | 2 | 5 | F9 | ORD | ATL | 730 | 10.0 | 86.0 | 606 | 1020 | 23.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58288 12 | 30 | 3 | F9 | DEN | ORD | 625 | -4.0 | 136.0 | 888 | 1000 | 14.0 | 0 | 0 | . 58331 12 | 30 | 3 | F9 | ORD | PHX | 825 | 18.0 | 207.0 | 1440 | 1127 | 14.0 | 0 | 0 | . 58447 12 | 31 | 4 | F9 | DEN | LAS | 1245 | 13.0 | 94.0 | 628 | 1340 | 13.0 | 0 | 0 | . 58449 12 | 31 | 4 | F9 | DEN | MCO | 645 | 11.0 | 169.0 | 1546 | 1224 | -11.0 | 0 | 0 | . 58488 12 | 31 | 4 | F9 | LAS | SFO | 1910 | 13.0 | 71.0 | 414 | 2050 | 4.0 | 0 | 0 | . 1317 rows × 14 columns . HA . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 582 1 | 4 | 7 | HA | LAX | OGG | 1115 | -11.0 | 310.0 | 2486 | 1500 | -27.0 | 0 | 0 | . 712 1 | 5 | 1 | HA | LAS | HNL | 900 | -5.0 | 357.0 | 2762 | 1315 | 5.0 | 0 | 0 | . 878 1 | 6 | 2 | HA | PHX | HNL | 800 | 1.0 | 374.0 | 2917 | 1140 | 3.0 | 0 | 0 | . 1053 1 | 7 | 3 | HA | LAX | HNL | 1705 | 0.0 | 332.0 | 2556 | 2055 | -2.0 | 0 | 0 | . 1269 1 | 8 | 4 | HA | LAX | HNL | 1000 | -1.0 | 335.0 | 2556 | 1350 | 0.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 55883 12 | 16 | 3 | HA | LAX | HNL | 835 | 1.0 | 314.0 | 2556 | 1235 | -18.0 | 0 | 0 | . 56174 12 | 18 | 5 | HA | LAX | HNL | 835 | -5.0 | 342.0 | 2556 | 1235 | -4.0 | 0 | 0 | . 56350 12 | 19 | 6 | HA | PHX | HNL | 800 | -5.0 | 363.0 | 2917 | 1155 | -34.0 | 0 | 0 | . 56816 12 | 21 | 1 | HA | LAX | LIH | 740 | 20.0 | 303.0 | 2615 | 1145 | -11.0 | 0 | 0 | . 58391 12 | 31 | 4 | HA | LAX | HNL | 1000 | 0.0 | 324.0 | 2556 | 1350 | -9.0 | 0 | 0 | . 112 rows × 14 columns . MQ . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 2 1 | 1 | 4 | MQ | DFW | VPS | 1305 | 36.0 | 85.0 | 641 | 1453 | 35.0 | 0 | 0 | . 10 1 | 1 | 4 | MQ | DFW | DRO | 1335 | 28.0 | 104.0 | 674 | 1438 | 28.0 | 0 | 0 | . 18 1 | 1 | 4 | MQ | ORD | DAY | 2220 | 19.0 | 37.0 | 240 | 23 | 20.0 | 0 | 0 | . 24 1 | 1 | 4 | MQ | DFW | BTR | 730 | NaN | NaN | 383 | 853 | NaN | 0 | 1 | . 50 1 | 1 | 4 | MQ | ORD | CID | 1135 | -7.0 | 37.0 | 196 | 1238 | -15.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58415 12 | 31 | 4 | MQ | ORD | FWA | 845 | -2.0 | 37.0 | 157 | 1045 | -4.0 | 0 | 0 | . 58426 12 | 31 | 4 | MQ | DFW | FAR | 1154 | 4.0 | 124.0 | 968 | 1437 | -13.0 | 0 | 0 | . 58468 12 | 31 | 4 | MQ | DFW | OKC | 1720 | -3.0 | 31.0 | 175 | 1819 | -10.0 | 0 | 0 | . 58474 12 | 31 | 4 | MQ | ORD | FNT | 829 | 4.0 | 40.0 | 223 | 1034 | -4.0 | 0 | 0 | . 58484 12 | 31 | 4 | MQ | ORD | DSM | 1333 | 1.0 | 57.0 | 299 | 1455 | -7.0 | 0 | 0 | . 3471 rows × 14 columns . NK . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 17 1 | 1 | 4 | NK | DEN | DTW | 1952 | 37.0 | 124.0 | 1123 | 31 | 54.0 | 0 | 0 | . 74 1 | 1 | 4 | NK | PHX | DFW | 159 | -1.0 | 103.0 | 868 | 502 | 1.0 | 0 | 0 | . 95 1 | 1 | 4 | NK | LAS | OAK | 1115 | 22.0 | 62.0 | 407 | 1246 | 10.0 | 0 | 0 | . 109 1 | 1 | 4 | NK | MSP | ORD | 616 | 2.0 | 49.0 | 334 | 745 | -19.0 | 0 | 0 | . 166 1 | 2 | 5 | NK | LAS | PDX | 1535 | -8.0 | 123.0 | 763 | 1754 | -4.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58160 12 | 29 | 2 | NK | MSP | MCO | 740 | 0.0 | 171.0 | 1310 | 1158 | 33.0 | 0 | 0 | . 58197 12 | 30 | 3 | NK | IAH | ORD | 755 | -8.0 | 136.0 | 925 | 1030 | -2.0 | 0 | 0 | . 58437 12 | 31 | 4 | NK | ORD | DFW | 1952 | 15.0 | 135.0 | 802 | 2225 | 23.0 | 0 | 0 | . 58461 12 | 31 | 4 | NK | ORD | LGA | 1801 | -5.0 | 84.0 | 733 | 2109 | -26.0 | 0 | 0 | . 58469 12 | 31 | 4 | NK | LAS | MSY | 1950 | 124.0 | 163.0 | 1500 | 112 | 101.0 | 0 | 0 | . 1516 rows × 14 columns . OO . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 12 1 | 1 | 4 | OO | ORD | MSP | 1510 | 2.0 | 65.0 | 334 | 1646 | 4.0 | 0 | 0 | . 16 1 | 1 | 4 | OO | DEN | SGU | 1105 | 21.0 | 66.0 | 517 | 1249 | 20.0 | 0 | 0 | . 22 1 | 1 | 4 | OO | LAS | LAX | 1544 | -4.0 | 39.0 | 236 | 1655 | -12.0 | 0 | 0 | . 25 1 | 1 | 4 | OO | ORD | SPI | 2110 | -4.0 | 31.0 | 174 | 2205 | 5.0 | 0 | 0 | . 27 1 | 1 | 4 | OO | IAH | JAC | 1104 | -1.0 | 161.0 | 1265 | 1316 | -1.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58451 12 | 31 | 4 | OO | ATL | FWA | 1905 | -3.0 | 72.0 | 508 | 2051 | -14.0 | 0 | 0 | . 58480 12 | 31 | 4 | OO | MSP | BIS | 1310 | -2.0 | 65.0 | 386 | 1449 | -9.0 | 0 | 0 | . 58482 12 | 31 | 4 | OO | DEN | CPR | 1850 | -2.0 | 38.0 | 230 | 1956 | 1.0 | 0 | 0 | . 58489 12 | 31 | 4 | OO | SFO | SBA | 1846 | -6.0 | 46.0 | 262 | 1956 | -5.0 | 0 | 0 | . 58491 12 | 31 | 4 | OO | SFO | BOI | 859 | 5.0 | 73.0 | 522 | 1146 | -1.0 | 0 | 0 | . 6588 rows × 14 columns . UA . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 1 1 | 1 | 4 | UA | DEN | IAD | 823 | 7.0 | 154.0 | 1452 | 1333 | -13.0 | 0 | 0 | . 5 1 | 1 | 4 | UA | IAH | SAN | 1450 | 1.0 | 178.0 | 1303 | 1620 | -14.0 | 0 | 0 | . 9 1 | 1 | 4 | UA | IAH | SJC | 925 | 3.0 | 215.0 | 1608 | 1136 | -14.0 | 0 | 0 | . 14 1 | 1 | 4 | UA | IAH | IND | 1426 | -1.0 | 102.0 | 844 | 1742 | -20.0 | 0 | 0 | . 21 1 | 1 | 4 | UA | ORD | CLE | 2102 | 48.0 | 47.0 | 315 | 2320 | 41.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58422 12 | 31 | 4 | UA | DEN | SAN | 1535 | 0.0 | 124.0 | 853 | 1704 | -13.0 | 0 | 0 | . 58432 12 | 31 | 4 | UA | ORD | SAN | 1915 | 7.0 | 238.0 | 1723 | 2143 | -3.0 | 0 | 0 | . 58457 12 | 31 | 4 | UA | ORD | LAX | 659 | -1.0 | 241.0 | 1744 | 946 | 0.0 | 0 | 0 | . 58460 12 | 31 | 4 | UA | SFO | PHL | 2235 | -6.0 | 265.0 | 2521 | 700 | -42.0 | 0 | 0 | . 58481 12 | 31 | 4 | UA | IAH | LAX | 1433 | 1.0 | 197.0 | 1379 | 1625 | -13.0 | 0 | 0 | . 7792 rows × 14 columns . US . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 31 1 | 1 | 4 | US | PHX | DEN | 1810 | 29.0 | 94.0 | 602 | 1954 | 49.0 | 0 | 0 | . 35 1 | 1 | 4 | US | ORD | PHL | 1600 | -2.0 | 80.0 | 678 | 1857 | -9.0 | 0 | 0 | . 49 1 | 1 | 4 | US | IAH | PHX | 1445 | -1.0 | 147.0 | 1009 | 1638 | -7.0 | 0 | 0 | . 96 1 | 1 | 4 | US | ATL | PHL | 1445 | -4.0 | 90.0 | 666 | 1644 | -11.0 | 0 | 0 | . 104 1 | 1 | 4 | US | MSP | PHX | 730 | -3.0 | 174.0 | 1276 | 1010 | -20.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 31514 6 | 30 | 2 | US | DEN | PHL | 705 | -4.0 | 188.0 | 1558 | 1240 | 1.0 | 0 | 0 | . 31523 6 | 30 | 2 | US | PHX | DEN | 1451 | 6.0 | 85.0 | 602 | 1738 | 7.0 | 0 | 0 | . 31535 6 | 30 | 2 | US | PHX | AUS | 840 | -3.0 | 116.0 | 872 | 1304 | -11.0 | 0 | 0 | . 31561 6 | 30 | 2 | US | ORD | PHX | 710 | -5.0 | 170.0 | 1440 | 901 | -50.0 | 0 | 0 | . 31582 6 | 30 | 2 | US | PHX | OGG | 800 | -4.0 | 356.0 | 2845 | 1127 | -13.0 | 0 | 0 | . 1615 rows × 14 columns . VX . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 56 1 | 1 | 4 | VX | LAS | SFO | 900 | 23.0 | 65.0 | 414 | 1035 | 11.0 | 0 | 0 | . 227 1 | 2 | 5 | VX | SFO | LAS | 1220 | -5.0 | 68.0 | 414 | 1350 | -5.0 | 0 | 0 | . 243 1 | 2 | 5 | VX | SFO | SEA | 700 | -4.0 | 104.0 | 679 | 905 | -1.0 | 0 | 0 | . 417 1 | 3 | 6 | VX | SFO | LAS | 900 | -2.0 | 62.0 | 414 | 1030 | -11.0 | 0 | 0 | . 432 1 | 3 | 6 | VX | SFO | SEA | 2035 | -2.0 | 106.0 | 679 | 2240 | -2.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58332 12 | 30 | 3 | VX | SFO | LAS | 1950 | -3.0 | 58.0 | 414 | 2120 | -4.0 | 0 | 0 | . 58383 12 | 31 | 4 | VX | SFO | PSP | 1630 | -7.0 | 65.0 | 421 | 1755 | -12.0 | 0 | 0 | . 58400 12 | 31 | 4 | VX | SFO | LAX | 1125 | -4.0 | 54.0 | 337 | 1245 | -10.0 | 0 | 0 | . 58471 12 | 31 | 4 | VX | SFO | LAX | 700 | 6.0 | 51.0 | 337 | 820 | 3.0 | 0 | 0 | . 58478 12 | 31 | 4 | VX | SFO | LAX | 1530 | 29.0 | 52.0 | 337 | 1650 | 22.0 | 0 | 0 | . 993 rows × 14 columns . WN . MONTH DAY WEEKDAY AIRLINE ORG_AIR DEST_AIR SCHED_DEP DEP_DELAY AIR_TIME DIST SCHED_ARR ARR_DELAY DIVERTED CANCELLED . 0 1 | 1 | 4 | WN | LAX | SLC | 1625 | 58.0 | 94.0 | 590 | 1905 | 65.0 | 0 | 0 | . 4 1 | 1 | 4 | WN | LAX | MCI | 1720 | 48.0 | 166.0 | 1363 | 2225 | 39.0 | 0 | 0 | . 19 1 | 1 | 4 | WN | PHX | LAX | 1640 | 51.0 | 58.0 | 370 | 1700 | 59.0 | 0 | 0 | . 20 1 | 1 | 4 | WN | ATL | BWI | 1115 | 1.0 | 76.0 | 577 | 1305 | -15.0 | 0 | 0 | . 23 1 | 1 | 4 | WN | ATL | HOU | 1555 | 30.0 | 113.0 | 696 | 1720 | 18.0 | 0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 58455 12 | 31 | 4 | WN | LAX | SMF | 1420 | -2.0 | 64.0 | 373 | 1540 | -7.0 | 0 | 0 | . 58458 12 | 31 | 4 | WN | LAS | SFO | 1825 | 25.0 | 67.0 | 414 | 1955 | 17.0 | 0 | 0 | . 58472 12 | 31 | 4 | WN | PHX | HOU | 845 | 5.0 | 119.0 | 1020 | 1210 | 7.0 | 0 | 0 | . 58473 12 | 31 | 4 | WN | DEN | PDX | 1205 | 4.0 | 130.0 | 991 | 1400 | -13.0 | 0 | 0 | . 58490 12 | 31 | 4 | WN | MSP | ATL | 525 | 39.0 | 124.0 | 907 | 855 | 34.0 | 0 | 0 | . 8418 rows × 14 columns . df.groupby(by=&#39;AIRLINE&#39;).agg({&#39;ARR_DELAY&#39;:np.mean}) df.groupby(by=&#39;AIRLINE&#39;)[&#39;ARR_DELAY&#39;].agg(np.mean) . 아래 셀과 동일하게 사용 가능 | . df.groupby(by=&#39;AIRLINE&#39;).agg({&#39;ARR_DELAY&#39;:&#39;mean&#39;}) . ARR_DELAY . AIRLINE . AA 5.542661 | . AS -0.833333 | . B6 8.692593 | . DL 0.339691 | . EV 7.034580 | . F9 13.630651 | . HA 4.972973 | . MQ 6.860591 | . NK 18.436070 | . OO 7.593463 | . UA 7.765755 | . US 1.681105 | . VX 5.348884 | . WN 6.397353 | . def f(x): return -np.mean(x) df.groupby(by=&#39;AIRLINE&#39;).agg({&#39;ARR_DELAY&#39;:f}) . ARR_DELAY . AIRLINE . AA -5.542661 | . AS 0.833333 | . B6 -8.692593 | . DL -0.339691 | . EV -7.034580 | . F9 -13.630651 | . HA -4.972973 | . MQ -6.860591 | . NK -18.436070 | . OO -7.593463 | . UA -7.765755 | . US -1.681105 | . VX -5.348884 | . WN -6.397353 | . df.groupby(by=&#39;AIRLINE&#39;).agg({&#39;ARR_DELAY&#39;:lambda x: -np.mean(x)}) . ARR_DELAY . AIRLINE . AA -5.542661 | . AS 0.833333 | . B6 -8.692593 | . DL -0.339691 | . EV -7.034580 | . F9 -13.630651 | . HA -4.972973 | . MQ -6.860591 | . NK -18.436070 | . OO -7.593463 | . UA -7.765755 | . US -1.681105 | . VX -5.348884 | . WN -6.397353 | . df.groupby(by=&#39;AIRLINE&#39;)[&#39;ARR_DELAY&#39;].agg(lambda x: -np.mean(x)) . AIRLINE AA -5.542661 AS 0.833333 B6 -8.692593 DL -0.339691 EV -7.034580 F9 -13.630651 HA -4.972973 MQ -6.860591 NK -18.436070 OO -7.593463 UA -7.765755 US -1.681105 VX -5.348884 WN -6.397353 Name: ARR_DELAY, dtype: float64 . def f(x,y): return np.mean(x)**y df.groupby(by=&#39;AIRLINE&#39;)[&#39;ARR_DELAY&#39;].agg(f,2) #2는 y값임 . AIRLINE AA 30.721086 AS 0.694444 B6 75.561166 DL 0.115390 EV 49.485310 F9 185.794656 HA 24.730460 MQ 47.067715 NK 339.888677 OO 57.660681 UA 60.306954 US 2.826113 VX 28.610564 WN 40.926120 Name: ARR_DELAY, dtype: float64 . df.groupby(by=&#39;AIRLINE&#39;).agg({&#39;ARR_DELAY&#39;: lambda x: f(x,2)}) . AIRLINE,WEEKDAY $ to$ {CANCELLED: sum} . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]).agg({&#39;CANCELLED&#39;:&#39;sum&#39;}) . CANCELLED . AIRLINE WEEKDAY . AA 1 41 | . 2 9 | . 3 16 | . 4 20 | . 5 18 | . ... ... ... | . WN 3 18 | . 4 10 | . 5 7 | . 6 10 | . 7 7 | . 98 rows × 1 columns . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]).agg({&#39;CANCELLED&#39;:np.sum}) df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;])[&#39;CANCELLED&#39;].agg(&#39;sum&#39;) df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;])[&#39;CANCELLED&#39;].agg(np.sum) df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;])[&#39;CANCELLED&#39;].sum() . 위 셀과 동일하게 적용 가능 | . AIRLINE,WEEKDAY $ to$ {CANCELLED: sum, mean} , {DIVERTED: sum, mean} . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]).agg({&#39;CANCELLED&#39;:[&#39;sum&#39;,&#39;mean&#39;],&#39;DIVERTED&#39;:[&#39;sum&#39;,&#39;mean&#39;]}) . CANCELLED DIVERTED . sum mean sum mean . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 6 | 0.004699 | . 2 9 | 0.007341 | 2 | 0.001631 | . 3 16 | 0.011949 | 2 | 0.001494 | . 4 20 | 0.015004 | 5 | 0.003751 | . 5 18 | 0.014151 | 1 | 0.000786 | . ... ... ... | ... | ... | ... | . WN 3 18 | 0.014118 | 2 | 0.001569 | . 4 10 | 0.007911 | 4 | 0.003165 | . 5 7 | 0.005828 | 0 | 0.000000 | . 6 10 | 0.010132 | 3 | 0.003040 | . 7 7 | 0.006066 | 3 | 0.002600 | . 98 rows × 4 columns . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]).agg({&#39;CANCELLED&#39;:[np.sum,np.mean],&#39;DIVERTED&#39;:[np.sum,np.mean]}) df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;])[[&#39;CANCELLED&#39;,&#39;DIVERTED&#39;]].agg([&#39;sum&#39;,&#39;mean&#39;]) df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;])[[&#39;CANCELLED&#39;,&#39;DIVERTED&#39;]].agg([np.sum,np.mean]) . 위 셀과 동일하게 적용 가능 | . AIRLINE,WEEKDAY $ to$ {CANCELLED: sum, mean, size} , {AIR_TIME: mean,var} . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]).agg({&#39;CANCELLED&#39;:[&#39;sum&#39;,&#39;mean&#39;,&#39;size&#39;],&#39;AIR_TIME&#39;:[&#39;mean&#39;,&#39;var&#39;]}) . CANCELLED AIR_TIME . sum mean size mean var . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 1277 | 147.610569 | 5393.806723 | . 2 9 | 0.007341 | 1226 | 143.851852 | 5359.890719 | . 3 16 | 0.011949 | 1339 | 144.514005 | 5378.854539 | . 4 20 | 0.015004 | 1333 | 141.124618 | 4791.524627 | . 5 18 | 0.014151 | 1272 | 145.430966 | 5884.592076 | . ... ... ... | ... | ... | ... | ... | . WN 3 18 | 0.014118 | 1275 | 104.219920 | 2901.873447 | . 4 10 | 0.007911 | 1264 | 107.200800 | 2966.568935 | . 5 7 | 0.005828 | 1201 | 107.893635 | 3268.717093 | . 6 10 | 0.010132 | 987 | 109.247433 | 3152.753719 | . 7 7 | 0.006066 | 1154 | 107.602273 | 3183.126889 | . 98 rows × 5 columns . df.groupby(by=[&#39;AIRLINE&#39;,&#39;WEEKDAY&#39;]) .agg({&#39;CANCELLED&#39;:[np.sum,np.mean,len],&#39;AIR_TIME&#39;:[np.mean,lambda x: np.std(x,ddof=1)**2]}) . CANCELLED AIR_TIME . sum mean len mean &lt;lambda_0&gt; . AIRLINE WEEKDAY . AA 1 41 | 0.032106 | 1277 | 147.610569 | 5393.806723 | . 2 9 | 0.007341 | 1226 | 143.851852 | 5359.890719 | . 3 16 | 0.011949 | 1339 | 144.514005 | 5378.854539 | . 4 20 | 0.015004 | 1333 | 141.124618 | 4791.524627 | . 5 18 | 0.014151 | 1272 | 145.430966 | 5884.592076 | . ... ... ... | ... | ... | ... | ... | . WN 3 18 | 0.014118 | 1275 | 104.219920 | 2901.873447 | . 4 10 | 0.007911 | 1264 | 107.200800 | 2966.568935 | . 5 7 | 0.005828 | 1201 | 107.893635 | 3268.717093 | . 6 10 | 0.010132 | 987 | 109.247433 | 3152.753719 | . 7 7 | 0.006066 | 1154 | 107.602273 | 3183.126889 | . 98 rows × 5 columns . &#44396;&#44036; &#45208;&#45572;&#44592; $ to$ pd.cut &#54876;&#50857; . df.DIST.hist() # DIST라는 열이 있음 . &lt;AxesSubplot:&gt; . bins=[-np.inf, 400, 600, 800, 1000, 1200, np.inf] . cuts, AIRLINE $ to$ {DIVERTED: sum} . cuts=pd.cut(df.DIST,bins=bins,labels=[&#39;Q1&#39;,&#39;Q2&#39;,&#39;Q3&#39;,&#39;Q4&#39;,&#39;Q5&#39;,&#39;Q6&#39;]) . cuts . 0 Q2 1 Q6 2 Q3 3 Q5 4 Q6 .. 58487 Q6 58488 Q2 58489 Q1 58490 Q4 58491 Q2 Name: DIST, Length: 58492, dtype: category Categories (6, object): [&#39;Q1&#39; &lt; &#39;Q2&#39; &lt; &#39;Q3&#39; &lt; &#39;Q4&#39; &lt; &#39;Q5&#39; &lt; &#39;Q6&#39;] . df.groupby(by=[cuts,&#39;AIRLINE&#39;]).agg({&#39;DIVERTED&#39;:sum}) . DIVERTED . DIST AIRLINE . Q1 AA 0 | . AS 0 | . B6 0 | . DL 1 | . EV 3 | . ... ... ... | . Q6 OO 4 | . UA 12 | . US 1 | . VX 1 | . WN 8 | . 84 rows × 1 columns . df.groupby(cuts).agg({&#39;DIVERTED&#39;:len}) . DIVERTED . DIST . Q1 15027 | . Q2 9130 | . Q3 8553 | . Q4 7542 | . Q5 3889 | . Q6 14351 | .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/11/intro2.html",
            "relUrl": "/2022/01/11/intro2.html",
            "date": " • Jan 11, 2022"
        }
        
    
  
    
        ,"post9": {
            "title": "2022/01/10/MON",
            "content": "query . import matplotlib.pyplot as plt from plotnine import * import numpy as np import pandas as pd np.random.seed(1) df=pd.DataFrame(np.random.normal(size=(15,4)),columns=list(&#39;ABCD&#39;)) . df.query(&#39;A&gt;0 &amp; B&lt;0&#39;) . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 11 0.050808 | -0.636996 | 0.190915 | 2.100255 | . df.query(&#39;A&gt;0 and B&lt;0&#39;) . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 11 0.050808 | -0.636996 | 0.190915 | 2.100255 | . lambda 사용할 때 &amp;로 묶을 땐 and와의 차이점이 있었는데 query에선 없는 것 같음 | . df.query(&#39;A&lt;B&lt;C&#39;) . A B C D . 9 -1.117310 | 0.234416 | 1.659802 | 0.742044 | . 13 -1.142518 | -0.349343 | -0.208894 | 0.586623 | . A&#50676; &#54217;&#44512; . df.A.mean() . -0.018839420539994597 . df[&#39;A&#39;].mean() . -0.018839420539994597 . df.query(&#39;A&gt;-0.018839420539994597&#39;) . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 11 0.050808 | -0.636996 | 0.190915 | 2.100255 | . 12 0.120159 | 0.617203 | 0.300170 | -0.352250 | . 14 0.838983 | 0.931102 | 0.285587 | 0.885141 | . meanA=df.A.mean() . df.query(&#39;A&gt; @meanA&#39;) #`@meanA` 대신 `@df.A.mean()` 가능 . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 6 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 11 0.050808 | -0.636996 | 0.190915 | 2.100255 | . 12 0.120159 | 0.617203 | 0.300170 | -0.352250 | . 14 0.838983 | 0.931102 | 0.285587 | 0.885141 | . df.query(&#39; A&gt; @meanA and A&lt;0.8&#39;) . A B C D . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 11 0.050808 | -0.636996 | 0.190915 | 2.100255 | . 12 0.120159 | 0.617203 | 0.300170 | -0.352250 | . df.query(&#39;index==0 or 3 &lt;= index &lt;=5 or 9&lt;=index &lt;=11&#39;) . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 3 -0.322417 | -0.384054 | 1.133769 | -1.099891 | . 4 -0.172428 | -0.877858 | 0.042214 | 0.582815 | . 5 -1.100619 | 1.144724 | 0.901591 | 0.502494 | . 9 -1.117310 | 0.234416 | 1.659802 | 0.742044 | . 10 -0.191836 | -0.887629 | -0.747158 | 1.692455 | . 11 0.050808 | -0.636996 | 0.190915 | 2.100255 | . df.query(&#39;index==0 or index ==[8,9,10]&#39;) . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 8 -0.687173 | -0.845206 | -0.671246 | -0.012665 | . 9 -1.117310 | 0.234416 | 1.659802 | 0.742044 | . 10 -0.191836 | -0.887629 | -0.747158 | 1.692455 | . i1= np.arange(3) # 0,1,2를 의미 . df.query(&#39;index in @i1 or index==5&#39;) . A B C D . 0 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 1 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 5 -1.100619 | 1.144724 | 0.901591 | 0.502494 | . &#45216;&#51676; &#51064;&#45937;&#49905; . df2=pd.DataFrame(np.random.normal(size=(10,4)), columns=list(&#39;ABCD&#39;), index=pd.date_range(&#39;20201226&#39;,periods=10)) . df2 . A B C D . 2020-12-26 -0.675108 | -2.937872 | -0.163313 | 1.148371 | . 2020-12-27 -0.634830 | -0.077837 | -0.198111 | -0.527920 | . 2020-12-28 0.490793 | 0.847149 | -0.508893 | -0.618730 | . 2020-12-29 1.172832 | -1.536797 | -1.061825 | 0.860925 | . 2020-12-30 1.645496 | -0.625553 | 0.412574 | -0.088867 | . 2020-12-31 0.189418 | -0.353450 | 0.392431 | 0.233936 | . 2021-01-01 0.905785 | -0.055679 | 0.727501 | 0.054261 | . 2021-01-02 -0.187347 | -1.205595 | 1.019300 | -1.465409 | . 2021-01-03 -1.638860 | 1.588163 | -1.024634 | -0.985670 | . 2021-01-04 -0.445074 | 0.209585 | -0.197880 | 0.551394 | . df2.query(&#39;&quot;2020-12-27&quot;&lt;= index &lt;= &quot;2021-01-03&quot;&#39;) . A B C D . 2020-12-27 -0.634830 | -0.077837 | -0.198111 | -0.527920 | . 2020-12-28 0.490793 | 0.847149 | -0.508893 | -0.618730 | . 2020-12-29 1.172832 | -1.536797 | -1.061825 | 0.860925 | . 2020-12-30 1.645496 | -0.625553 | 0.412574 | -0.088867 | . 2020-12-31 0.189418 | -0.353450 | 0.392431 | 0.233936 | . 2021-01-01 0.905785 | -0.055679 | 0.727501 | 0.054261 | . 2021-01-02 -0.187347 | -1.205595 | 1.019300 | -1.465409 | . 2021-01-03 -1.638860 | 1.588163 | -1.024634 | -0.985670 | . df2.query(&#39; &quot;2020-12-27&quot;&lt;= index &lt;= &quot;2021-01-03&quot; and A+B &lt; C&#39;) . A B C D . 2020-12-27 -0.634830 | -0.077837 | -0.198111 | -0.527920 | . 2020-12-31 0.189418 | -0.353450 | 0.392431 | 0.233936 | . 2021-01-02 -0.187347 | -1.205595 | 1.019300 | -1.465409 | . . fifa22=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/2021-10-25-FIFA22_official_data.csv&#39;) . fifa22.sort_values(by=&#39;Overall&#39;,ascending=False).head(2) . ID Name Age Photo Nationality Flag Overall Potential Club Club Logo ... SlidingTackle GKDiving GKHandling GKKicking GKPositioning GKReflexes Best Position Best Overall Rating Release Clause DefensiveAwareness . 29 158023 | L. Messi | 34 | https://cdn.sofifa.com/players/158/023/22_60.png | Argentina | https://cdn.sofifa.com/flags/ar.png | 93 | 93 | Paris Saint-Germain | https://cdn.sofifa.com/teams/73/30.png | ... | 24.0 | 6.0 | 11.0 | 15.0 | 14.0 | 8.0 | RW | 93.0 | €144.3M | 20.0 | . 33 188545 | R. Lewandowski | 32 | https://cdn.sofifa.com/players/188/545/22_60.png | Poland | https://cdn.sofifa.com/flags/pl.png | 92 | 92 | FC Bayern München | https://cdn.sofifa.com/teams/21/30.png | ... | 19.0 | 15.0 | 6.0 | 12.0 | 8.0 | 10.0 | ST | 92.0 | €197.2M | 35.0 | . 2 rows × 65 columns . fifa22.sort_values(by=&#39;Overall&#39;,ascending=False).reset_index() . index ID Name Age Photo Nationality Flag Overall Potential Club ... SlidingTackle GKDiving GKHandling GKKicking GKPositioning GKReflexes Best Position Best Overall Rating Release Clause DefensiveAwareness . 0 29 | 158023 | L. Messi | 34 | https://cdn.sofifa.com/players/158/023/22_60.png | Argentina | https://cdn.sofifa.com/flags/ar.png | 93 | 93 | Paris Saint-Germain | ... | 24.0 | 6.0 | 11.0 | 15.0 | 14.0 | 8.0 | RW | 93.0 | €144.3M | 20.0 | . 1 33 | 188545 | R. Lewandowski | 32 | https://cdn.sofifa.com/players/188/545/22_60.png | Poland | https://cdn.sofifa.com/flags/pl.png | 92 | 92 | FC Bayern München | ... | 19.0 | 15.0 | 6.0 | 12.0 | 8.0 | 10.0 | ST | 92.0 | €197.2M | 35.0 | . 2 14244 | 200389 | J. Oblak | 28 | https://cdn.sofifa.com/players/200/389/22_60.png | Slovenia | https://cdn.sofifa.com/flags/si.png | 91 | 93 | Atlético de Madrid | ... | 18.0 | 87.0 | 92.0 | 78.0 | 90.0 | 90.0 | GK | 91.0 | €238M | 27.0 | . 3 3 | 192985 | K. De Bruyne | 30 | https://cdn.sofifa.com/players/192/985/22_60.png | Belgium | https://cdn.sofifa.com/flags/be.png | 91 | 91 | Manchester City | ... | 53.0 | 15.0 | 13.0 | 5.0 | 10.0 | 13.0 | CM | 91.0 | €232.2M | 68.0 | . 4 64 | 190871 | Neymar Jr | 29 | https://cdn.sofifa.com/players/190/871/22_60.png | Brazil | https://cdn.sofifa.com/flags/br.png | 91 | 91 | Paris Saint-Germain | ... | 29.0 | 9.0 | 9.0 | 15.0 | 15.0 | 11.0 | LW | 91.0 | €238.7M | 35.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 16705 15593 | 235352 | 18 T. Käßemodel | 28 | https://cdn.sofifa.com/players/235/352/18_60.png | Germany | https://cdn.sofifa.com/flags/de.png | 46 | 46 | FC Erzgebirge Aue | ... | 38.0 | 10.0 | 12.0 | 6.0 | 13.0 | 6.0 | CM | 45.0 | €47K | NaN | . 16706 15685 | 219735 | 15 T. Fletcher | 19 | https://cdn.sofifa.com/players/219/735/15_60.png | England | https://cdn.sofifa.com/flags/gb-eng.png | 46 | 52 | Wycombe Wanderers | ... | 50.0 | 14.0 | 7.0 | 8.0 | 14.0 | 11.0 | CB | 46.0 | NaN | NaN | . 16707 16572 | 19334 | 10 I. Baraclough | 38 | https://cdn.sofifa.com/players/019/334/10_60.png | England | https://cdn.sofifa.com/flags/gb-eng.png | 44 | 65 | NaN | ... | NaN | 5.0 | 20.0 | 46.0 | 20.0 | 20.0 | CM | 46.0 | NaN | NaN | . 16708 15999 | 220806 | 16 E. Redman | 18 | https://cdn.sofifa.com/players/220/806/16_60.png | Wales | https://cdn.sofifa.com/flags/gb-wls.png | 44 | 57 | Newport County | ... | 38.0 | 13.0 | 7.0 | 16.0 | 9.0 | 7.0 | CB | 44.0 | NaN | NaN | . 16709 16709 | 178453 | 07 A. Censori | 17 | https://cdn.sofifa.com/players/178/453/07_60.png | Italy | https://cdn.sofifa.com/flags/it.png | 28 | 38 | Arezzo | ... | NaN | 7.0 | 1.0 | 36.0 | 6.0 | 9.0 | ST | 36.0 | NaN | NaN | . 16710 rows × 66 columns . fifa22=fifa22.sort_values(by=&#39;Overall&#39;,ascending=False).reset_index().rename(columns={&#39;index&#39;:&#39;index_old&#39;}) # Overall 기준 정렬 // ascending=False -&gt; 내림차순 (디폴트 = 오름차순) # reset_index().rename(columns={&#39;index&#39;:&#39;index_old&#39;}) -&gt; 인덱스 초기화하고 index -&gt; index_old . ggplot(fifa22)+geom_point(aes(x=&#39;Overall&#39;, y=&#39;Potential&#39;),alpha=0.1) . &lt;ggplot: (133762170218)&gt; . fifa22[&#39;Potential2&#39;] = fifa22[&#39;Potential&#39;] - fifa22[&#39;Overall&#39;] . ggplot(fifa22)+geom_point(aes(x=&#39;Overall&#39;, y=&#39;Potential2&#39;),alpha=0.1,position=&#39;jitter&#39;) . &lt;ggplot: (133762242536)&gt; . ggplot(fifa22.query(&#39;Potential2&gt;0.1&#39;))+geom_point(aes(x=&#39;Overall&#39;, y=&#39;Potential2&#39;),alpha=0.1,position=&#39;jitter&#39;) . &lt;ggplot: (133762827475)&gt; . &#44396;&#54925; &#45208;&#45600;&#49436; &#49884;&#44033;&#54868; . fifa22.Overall.hist() . &lt;AxesSubplot:&gt; . def f(x): if x&gt;72: y=&#39;Q1&#39; elif x&gt;68: y=&#39;Q2&#39; elif x&gt;63: y=&#39;Q3&#39; else: y=&#39;Q4&#39; return y . fifa22[&#39;Q&#39;]=list(map(f,fifa22.Overall)) . ggplot(fifa22.query(&#39;Potential2&gt;0.1&#39;)) +geom_boxplot(aes(x=&#39;Q&#39;,y=&#39;Potential2&#39;)) . &lt;ggplot: (133762235248)&gt; . fifa22.groupby(by=&#39;Q&#39;).mean() . index_old ID Age Overall Potential Special International Reputation Weak Foot Skill Moves Jersey Number ... StandingTackle SlidingTackle GKDiving GKHandling GKKicking GKPositioning GKReflexes Best Overall Rating DefensiveAwareness Potential2 . Q . Q1 4205.816376 | 201709.364799 | 28.326170 | 76.350653 | 78.255441 | 1844.926007 | 1.626496 | 3.176823 | 2.831066 | 17.057236 | ... | 55.358542 | 52.228876 | 16.784548 | 16.630305 | 16.624864 | 16.758705 | 16.976877 | 76.917573 | 55.146188 | 1.904788 | . Q2 6656.466321 | 213336.582220 | 27.405236 | 70.411781 | 73.040633 | 1722.092446 | 1.108536 | 3.048814 | 2.581947 | 18.576262 | ... | 51.731115 | 49.226441 | 15.478047 | 15.266703 | 15.244887 | 15.389692 | 15.560404 | 71.146441 | 51.307382 | 2.628852 | . Q3 9087.227636 | 222530.020074 | 25.744884 | 66.074449 | 70.642370 | 1624.772169 | 1.024557 | 2.983824 | 2.406743 | 19.722168 | ... | 48.641395 | 46.344720 | 15.147340 | 15.015786 | 14.956149 | 15.104658 | 15.248295 | 67.034886 | 47.517955 | 4.567920 | . Q4 12537.131020 | 240787.302644 | 21.998584 | 59.602691 | 69.572710 | 1458.843957 | 1.003069 | 2.856232 | 2.157932 | 25.944563 | ... | 42.165722 | 40.681238 | 15.555949 | 15.391879 | 15.237724 | 15.305241 | 15.611898 | 60.936969 | 39.979637 | 9.970019 | . 4 rows × 47 columns . fifa22.groupby(by=&#39;Q&#39;).mean().Overall # Q1,Q2,Q3,Q4의 Overall평균만, 현재 자료형은 float . Q Q1 76.350653 Q2 70.411781 Q3 66.074449 Q4 59.602691 Name: Overall, dtype: float64 . l_=fifa22.groupby(by=&#39;Q&#39;).mean().Overall . type(l_) . pandas.core.series.Series . l_은 pandas series형태 . l=fifa22.groupby(by=&#39;Q&#39;).mean().Overall.to_list() # to_list() 해당 자료를 list로 만들겠다 . l . [76.3506528835691, 70.4117807472048, 66.07444942506334, 59.60269121813031] . - 이제 박스플랏이 들어갈 x축의 위치를 저장할 컬럼을 추가하고 그 이름을 Qx 라고 하자. . def g(x): if x==&#39;Q1&#39;: y=l[0] elif x==&#39;Q2&#39;: y=l[1] elif x==&#39;Q3&#39;: y=l[2] else: y=l[3] return y . fifa22[&#39;Qx&#39;]=list(map(g,fifa22.Q)) . ggplot(fifa22.query(&#39;Potential2&gt;0.1&#39;)) +geom_point(aes(x=&#39;Overall&#39;, y=&#39;Potential2&#39;,color=&#39;Q&#39;),alpha=0.1,size=0.1,position=&#39;jitter&#39;) +geom_boxplot(aes(x=&#39;Qx&#39;, y=&#39;Potential2&#39;,color=&#39;Q&#39;)) # 박스플랏이 overall 평균에 위치可 . &lt;ggplot: (133763474110)&gt; . fifa22.query(&#39;Q==&quot;Q1&quot; and Potential2&gt;20&#39;) . index_old ID Name Age Photo Nationality Flag Overall Potential Club ... GKKicking GKPositioning GKReflexes Best Position Best Overall Rating Release Clause DefensiveAwareness Potential2 Q Qx . 0 rows × 69 columns .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/10/intro2.html",
            "relUrl": "/2022/01/10/intro2.html",
            "date": " • Jan 10, 2022"
        }
        
    
  
    
        ,"post10": {
            "title": "2022/01/09/SUN",
            "content": "import numpy as np import pandas as pd np.random.seed(1) dic= {&#39;X1&#39;:np.random.normal(0,1,5), &#39;X2&#39;:np.random.normal(0,1,5), &#39;X3&#39;:np.random.normal(0,1,5), &#39;X4&#39;:np.random.normal(0,1,5), &#39;X5&#39;:np.random.normal(0,1,5), &#39;X6&#39;:np.random.normal(0,1,5)} df1=pd.DataFrame(dic) # 딕셔너리도 데이터프레임으로 만들 수 있음 df1 . X1 X2 X3 X4 X5 X6 . 0 1.624345 | -2.301539 | 1.462108 | -1.099891 | -1.100619 | -0.683728 | . 1 -0.611756 | 1.744812 | -2.060141 | -0.172428 | 1.144724 | -0.122890 | . 2 -0.528172 | -0.761207 | -0.322417 | -0.877858 | 0.901591 | -0.935769 | . 3 -1.072969 | 0.319039 | -0.384054 | 0.042214 | 0.502494 | -0.267888 | . 4 0.865408 | -0.249370 | 1.133769 | 0.582815 | 0.900856 | 0.530355 | . 행 추출 | . # df1.iloc[[0]] # df1.iloc[[0],:] # df1.iloc[0,:] . # df1.loc[[0]] # df1.loc[[0],:] # df1.loc[0,:] . 대괄호 두개 처리 | . # df1.loc[[True,False,False,False,False]] # df1.iloc[[True,False,False,False,False],:] # df1.iloc[[True,False,False,False,False]] . 대괄호 두개 처리! | . # df1.loc[[0,2],:] # 1,3행 선택 . loc vs iloc . _df= pd.DataFrame({&#39;A&#39;:[1,2,3,4],&#39;B&#39;:[4,5,6,7]},index=list(&#39;abcd&#39;)) # 인덱스는 형태가 list! _df . A B . a 1 | 4 | . b 2 | 5 | . c 3 | 6 | . d 4 | 7 | . 연속 추출은 대괄호 생략 가능 | . # _df.loc[&#39;a&#39;:&#39;c&#39;,:] # _df.iloc[0:3,:] =&gt; 0,1,2행 # _df.iloc[[0,2],:] =&gt; 0,2행 . np.random.normal(size=(20,4)) . array([[-1.37311732, 0.31515939, 0.84616065, -0.85951594], [ 0.35054598, -1.31228341, -0.03869551, -1.61577235], [ 1.12141771, 0.40890054, -0.02461696, -0.77516162], [ 1.27375593, 1.96710175, -1.85798186, 1.23616403], [ 1.62765075, 0.3380117 , -1.19926803, 0.86334532], [-0.1809203 , -0.60392063, -1.23005814, 0.5505375 ], [ 0.79280687, -0.62353073, 0.52057634, -1.14434139], [ 0.80186103, 0.0465673 , -0.18656977, -0.10174587], [ 0.86888616, 0.75041164, 0.52946532, 0.13770121], [ 0.07782113, 0.61838026, 0.23249456, 0.68255141], [-0.31011677, -2.43483776, 1.0388246 , 2.18697965], [ 0.44136444, -0.10015523, -0.13644474, -0.11905419], [ 0.01740941, -1.12201873, -0.51709446, -0.99702683], [ 0.24879916, -0.29664115, 0.49521132, -0.17470316], [ 0.98633519, 0.2135339 , 2.19069973, -1.89636092], [-0.64691669, 0.90148689, 2.52832571, -0.24863478], [ 0.04366899, -0.22631424, 1.33145711, -0.28730786], [ 0.68006984, -0.3198016 , -1.27255876, 0.31354772], [ 0.50318481, 1.29322588, -0.11044703, -0.61736206], [ 0.5627611 , 0.24073709, 0.28066508, -0.0731127 ]]) . np.random.seed(1) _df= pd.DataFrame(np.random.normal(size=(20,4)), columns=list(&#39;ABCD&#39;), index=pd.date_range(&#39;20201225&#39;,periods=20)) _df . A B C D . 2020-12-25 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 2020-12-26 0.865408 | -2.301539 | 1.744812 | -0.761207 | . 2020-12-27 0.319039 | -0.249370 | 1.462108 | -2.060141 | . 2020-12-28 -0.322417 | -0.384054 | 1.133769 | -1.099891 | . 2020-12-29 -0.172428 | -0.877858 | 0.042214 | 0.582815 | . 2020-12-30 -1.100619 | 1.144724 | 0.901591 | 0.502494 | . 2020-12-31 0.900856 | -0.683728 | -0.122890 | -0.935769 | . 2021-01-01 -0.267888 | 0.530355 | -0.691661 | -0.396754 | . 2021-01-02 -0.687173 | -0.845206 | -0.671246 | -0.012665 | . 2021-01-03 -1.117310 | 0.234416 | 1.659802 | 0.742044 | . 2021-01-04 -0.191836 | -0.887629 | -0.747158 | 1.692455 | . 2021-01-05 0.050808 | -0.636996 | 0.190915 | 2.100255 | . 2021-01-06 0.120159 | 0.617203 | 0.300170 | -0.352250 | . 2021-01-07 -1.142518 | -0.349343 | -0.208894 | 0.586623 | . 2021-01-08 0.838983 | 0.931102 | 0.285587 | 0.885141 | . 2021-01-09 -0.754398 | 1.252868 | 0.512930 | -0.298093 | . 2021-01-10 0.488518 | -0.075572 | 1.131629 | 1.519817 | . 2021-01-11 2.185575 | -1.396496 | -1.444114 | -0.504466 | . 2021-01-12 0.160037 | 0.876169 | 0.315635 | -2.022201 | . 2021-01-13 -0.306204 | 0.827975 | 0.230095 | 0.762011 | . 연속 추출시 대괄호 생략 가능 | . . pd.Series(_df.index) # index 자리에 columns 입력하면 열의 번호 . 0 2020-12-25 1 2020-12-26 2 2020-12-27 3 2020-12-28 4 2020-12-29 5 2020-12-30 6 2020-12-31 7 2021-01-01 8 2021-01-02 9 2021-01-03 10 2021-01-04 11 2021-01-05 12 2021-01-06 13 2021-01-07 14 2021-01-08 15 2021-01-09 16 2021-01-10 17 2021-01-11 18 2021-01-12 19 2021-01-13 dtype: datetime64[ns] . _df.iloc[11:15] . A B C D . 2021-01-05 0.050808 | -0.636996 | 0.190915 | 2.100255 | . 2021-01-06 0.120159 | 0.617203 | 0.300170 | -0.352250 | . 2021-01-07 -1.142518 | -0.349343 | -0.208894 | 0.586623 | . 2021-01-08 0.838983 | 0.931102 | 0.285587 | 0.885141 | . &#53945;&#51221; &#51060;&#47492;&#51032; &#50676; &#52628;&#52636; . _df.A . 2020-12-25 1.624345 2020-12-26 0.865408 2020-12-27 0.319039 2020-12-28 -0.322417 2020-12-29 -0.172428 2020-12-30 -1.100619 2020-12-31 0.900856 2021-01-01 -0.267888 2021-01-02 -0.687173 2021-01-03 -1.117310 2021-01-04 -0.191836 2021-01-05 0.050808 2021-01-06 0.120159 2021-01-07 -1.142518 2021-01-08 0.838983 2021-01-09 -0.754398 2021-01-10 0.488518 2021-01-11 2.185575 2021-01-12 0.160037 2021-01-13 -0.306204 Freq: D, Name: A, dtype: float64 . _df[&#39;A&#39;] #행에선 x . 2020-12-25 1.624345 2020-12-26 0.865408 2020-12-27 0.319039 2020-12-28 -0.322417 2020-12-29 -0.172428 2020-12-30 -1.100619 2020-12-31 0.900856 2021-01-01 -0.267888 2021-01-02 -0.687173 2021-01-03 -1.117310 2021-01-04 -0.191836 2021-01-05 0.050808 2021-01-06 0.120159 2021-01-07 -1.142518 2021-01-08 0.838983 2021-01-09 -0.754398 2021-01-10 0.488518 2021-01-11 2.185575 2021-01-12 0.160037 2021-01-13 -0.306204 Freq: D, Name: A, dtype: float64 . _df.iloc[::5] # 5단위로 행 추출 . A B C D . 2020-12-25 1.624345 | -0.611756 | -0.528172 | -1.072969 | . 2020-12-30 -1.100619 | 1.144724 | 0.901591 | 0.502494 | . 2021-01-04 -0.191836 | -0.887629 | -0.747158 | 1.692455 | . 2021-01-09 -0.754398 | 1.252868 | 0.512930 | -0.298093 | . _df.iloc[:,::2] # 2단위로 열 추출 . A C . 2020-12-25 1.624345 | -0.528172 | . 2020-12-26 0.865408 | 1.744812 | . 2020-12-27 0.319039 | 1.462108 | . 2020-12-28 -0.322417 | 1.133769 | . 2020-12-29 -0.172428 | 0.042214 | . 2020-12-30 -1.100619 | 0.901591 | . 2020-12-31 0.900856 | -0.122890 | . 2021-01-01 -0.267888 | -0.691661 | . 2021-01-02 -0.687173 | -0.671246 | . 2021-01-03 -1.117310 | 1.659802 | . 2021-01-04 -0.191836 | -0.747158 | . 2021-01-05 0.050808 | 0.190915 | . 2021-01-06 0.120159 | 0.300170 | . 2021-01-07 -1.142518 | -0.208894 | . 2021-01-08 0.838983 | 0.285587 | . 2021-01-09 -0.754398 | 0.512930 | . 2021-01-10 0.488518 | 1.131629 | . 2021-01-11 2.185575 | -1.444114 | . 2021-01-12 0.160037 | 0.315635 | . 2021-01-13 -0.306204 | 0.230095 | . lambda + map . np.random.seed(1) df2= pd.DataFrame(np.random.normal(size=(10,4)),columns=list(&#39;ABCD&#39;)) . A&gt;0 : A&#50676;&#47564; &#48977;&#51652; &#50506;&#44256; A&gt;0&#51064; &#47784;&#46304; &#50676;&#51012; &#45796; &#48977;&#51020; . . . . . A&gt;0,C&lt;0 : A&gt;0,C&lt;0&#51064; &#47784;&#46304; &#54665; &#48977;&#51020; . . . 괄호 처리 주의(&amp;) | . . .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/09/intro2.html",
            "relUrl": "/2022/01/09/intro2.html",
            "date": " • Jan 9, 2022"
        }
        
    
  
    
        ,"post11": {
            "title": "2022/01/08/SAT",
            "content": "import pandas as pd import matplotlib.pyplot as plt import numpy as np np.random.seed(1) temp= np.array([-10.2, -5.2, 0.1, 10.1, 12.2, 14.7,25.4, 26.8, 28.9, 35.1, 32.2, 34.6]) ϵ1= np.random.normal(size=12,scale=5) icecream= 20 + temp * 2 + ϵ1 . np.random.seed(2) ϵ2= np.random.normal(size=12,scale=5) disease = 30+ temp* 0.5 + ϵ2 . plt.plot(temp,icecream,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x1c29099ffd0&gt;] . plt.plot(temp,disease,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x1c291128cd0&gt;] . plt.plot(icecream,disease,&#39;.&#39;) # 아이스크림 &amp; 소아마비 . [&lt;matplotlib.lines.Line2D at 0x1c2911a0940&gt;] . plt.plot(icecream[:6],disease[:6],&#39;.&#39;) # 비슷한 온도로 관찰 -&gt; 선형관계 약해짐 . [&lt;matplotlib.lines.Line2D at 0x1c29120c5e0&gt;] . . df=pd.read_csv(&#39;https://raw.githubusercontent.com/guebin/2021DV/master/_notebooks/extremum.csv&#39;) . df.columns . Index([&#39;지점번호&#39;, &#39;지점명&#39;, &#39;일시&#39;, &#39;평균기온(℃)&#39;, &#39;최고기온(℃)&#39;, &#39;최고기온시각&#39;, &#39;최저기온(℃)&#39;, &#39;최저기온시각일교차&#39;, &#39;Unnamed: 8&#39;], dtype=&#39;object&#39;) . pd.Series(df.columns) . 0 지점번호 1 지점명 2 일시 3 평균기온(℃) 4 최고기온(℃) 5 최고기온시각 6 최저기온(℃) 7 최저기온시각일교차 8 Unnamed: 8 dtype: object . temp=np.array(df.iloc[:,3]) # 평균기온 열 len(temp) #평균기온에 해당되는 행 656개 . 656 . np.random.seed(1) ϵ1=np.random.normal(size=656, scale=10) icecream=temp*2 + 30 + ϵ1 . np.random.seed(2) ϵ2=np.random.normal(size=656,scale=1) disease=temp*0.5 + 40 +ϵ2 . plt.plot(temp,icecream,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x1c292285490&gt;] . plt.plot(temp,disease,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x1c2922ec310&gt;] . plt.plot(icecream,disease,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x1c292342a30&gt;] . np.corrcoef(icecream,disease) #상관계수 -&gt; 인과관계 의미 x . array([[1. , 0.86298975], [0.86298975, 1. ]]) . plt.plot(icecream[temp&gt;25],disease[temp&gt;25], &#39;.&#39;) # 비슷한 온도구간 관찰 -&gt; 선형관계 약해짐 . [&lt;matplotlib.lines.Line2D at 0x1c29283bb80&gt;] . fig , ((ax1,ax2), (ax3,ax4)) = plt.subplots(2,2) ax1.plot(temp,icecream,&#39;.&#39;) ax2.plot(temp,disease,&#39;.&#39;) ax3.plot(icecream,disease,&#39;.&#39;) ax4.plot(icecream,disease,&#39;.&#39;) ax4.plot(icecream[temp&gt;25],disease[temp&gt;25],&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x1c292967430&gt;] . &#50728;&#46020;&#44396;&#44036; &#52852;&#53580;&#44256;&#47532;&#54868; . df1=pd.DataFrame({&#39;temp&#39;:temp, &#39;icecream&#39;:icecream, &#39;disease&#39;:disease}) . df1 . temp icecream disease . 0 -0.5 | 45.243454 | 39.333242 | . 1 1.4 | 26.682436 | 40.643733 | . 2 2.6 | 29.918282 | 39.163804 | . 3 2.0 | 23.270314 | 42.640271 | . 4 2.5 | 43.654076 | 39.456564 | . ... ... | ... | ... | . 651 19.9 | 78.839992 | 49.633906 | . 652 20.4 | 86.554679 | 48.920443 | . 653 18.3 | 78.666079 | 49.882650 | . 654 12.8 | 52.771364 | 46.613159 | . 655 6.7 | 40.736731 | 44.902513 | . 656 rows × 3 columns . df1.temp . 0 -0.5 1 1.4 2 2.6 3 2.0 4 2.5 ... 651 19.9 652 20.4 653 18.3 654 12.8 655 6.7 Name: temp, Length: 656, dtype: float64 . df1.temp.hist() # = plt.hist(df1.temp) . &lt;AxesSubplot:&gt; . def f(x): if x&lt;0: y=&#39;group0&#39; elif x&lt;10: y=&#39;group10&#39; elif x&lt;20: y=&#39;group20&#39; else: y=&#39;group30&#39; return y . df1[&#39;temp2&#39;]=list(map(f,df1.temp)) . df1 . temp icecream disease temp2 . 0 -0.5 | 45.243454 | 39.333242 | group0 | . 1 1.4 | 26.682436 | 40.643733 | group10 | . 2 2.6 | 29.918282 | 39.163804 | group10 | . 3 2.0 | 23.270314 | 42.640271 | group10 | . 4 2.5 | 43.654076 | 39.456564 | group10 | . ... ... | ... | ... | ... | . 651 19.9 | 78.839992 | 49.633906 | group20 | . 652 20.4 | 86.554679 | 48.920443 | group30 | . 653 18.3 | 78.666079 | 49.882650 | group20 | . 654 12.8 | 52.771364 | 46.613159 | group20 | . 655 6.7 | 40.736731 | 44.902513 | group10 | . 656 rows × 4 columns . from plotnine import * ggplot(df1)+geom_point(aes(x=&#39;icecream&#39;,y=&#39;disease&#39;,color=&#39;temp2&#39;)) . &lt;ggplot: (120959691903)&gt; . ggplot(df1)+geom_point(aes(x=&#39;icecream&#39;,y=&#39;disease&#39;,color=&#39;temp2&#39;)) +geom_smooth(aes(x=&#39;icecream&#39;,y=&#39;disease&#39;,colour=&#39;temp2&#39;),size=1,linetype=&#39;dashed&#39;) . C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine stats smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (120949679559)&gt; . ggplot(df1,aes(x=&#39;icecream&#39;,y=&#39;disease&#39;))+geom_point(aes(color=&#39;temp2&#39;)) +geom_smooth(aes(color=&#39;temp2&#39;),size=1,linetype=&#39;dashed&#39;) . C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine stats smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (120959836549)&gt; . 만약 아이스크림과 질병이 연관있는 경우라면 . np.random.seed(1) ϵ1=np.random.normal(size=656, scale=10) icecream=temp*2 + 30 + ϵ1 np.random.seed(2) ϵ2=np.random.normal(size=656,scale=1) disease= 30+ temp*0.0 + icecream*0.15 +ϵ2*2 # 식 자체 정의를 달리해야 함 . df2=pd.DataFrame({&#39;temp&#39;:temp,&#39;icecream&#39;:icecream,&#39;disease&#39;:disease}) df2[&#39;temp2&#39;]=list(map(f,df2.temp)) # map을 이용하여 기존df에 자료 추가해주려면 list로 !! . ggplot(df2)+geom_point(aes(x=&#39;icecream&#39;,y=&#39;disease&#39;,colour=&#39;temp2&#39;)) +geom_smooth(aes(x=&#39;icecream&#39;,y=&#39;disease&#39;,colour=&#39;temp2&#39;),size=2,linetype=&#39;dashed&#39;) . C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine stats smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (120959800808)&gt; . df1.corr() . temp icecream disease . temp 1.000000 | 0.884366 | 0.975609 | . icecream 0.884366 | 1.000000 | 0.862990 | . disease 0.975609 | 0.862990 | 1.000000 | . df2.corr() . temp icecream disease . temp 1.000000 | 0.884366 | 0.725505 | . icecream 0.884366 | 1.000000 | 0.830539 | . disease 0.725505 | 0.830539 | 1.000000 | . .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/08/intro2.html",
            "relUrl": "/2022/01/08/intro2.html",
            "date": " • Jan 8, 2022"
        }
        
    
  
    
        ,"post12": {
            "title": "2022/01/07/FRI",
            "content": "&#54644;&#46308;&#47532;&#50948;&#52980; &#44536;&#47000;&#54532;&#47112;&#51060;&#50612; . import pandas as pd . mpg=pd.read_csv(&quot;mpg.csv&quot;) . &#44592;&#48376;&#49328;&#51216;&#46020; (2&#52264;&#50896;) . from plotnine import * ggplot(mpg) + geom_point(aes(x = &quot;displ&quot;, y = &quot;hwy&quot;)) . &lt;ggplot: (117623195251)&gt; . $ to$ 엔진크기와 연료효율은 반비례 $ to$ 엔진크기가 클수록 연비 안 좋다 . fig=ggplot(mpg) . a1=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;) point1=geom_point(a1) . fig+point1 . &lt;ggplot: (117623102492)&gt; . &#49328;&#51216;&#46020;&#51025;&#50857; (3&#52264;&#50896;) + (&#51216;&#53356;&#44592;&#48320;&#44221;) . ggplot(mpg)+ geom_point(aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,size= &#39;class&#39;)) . C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine scales scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. . &lt;ggplot: (117623142138)&gt; . &#49328;&#51216;&#46020; + &#53804;&#47749;&#46020;&#48320;&#44221; . ggplot(data=mpg)+ geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,alpha= &#39;class&#39;)) # 여기서 data와 mapping은 생략 가능 . C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine scales scale_alpha.py:68: PlotnineWarning: Using alpha for a discrete variable is not advised. . &lt;ggplot: (117623137118)&gt; . 4&#52264;&#50896; (+&#51216; &#53356;&#44592;, + &#53804;&#47749;&#46020;) . ggplot(data=mpg)+ geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,size= &#39;class&#39;,alpha=&#39;class&#39;)) . C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine scales scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine scales scale_alpha.py:68: PlotnineWarning: Using alpha for a discrete variable is not advised. . &lt;ggplot: (117623141988)&gt; . 3&#52264;&#50896; &#49328;&#51216;&#46020; (+ &#54805;&#53468;) . ggplot(data=mpg)+ geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,shape=&#39;class&#39;)) . &lt;ggplot: (117624346444)&gt; . 3&#52264;&#50896; &#49328;&#51216;&#46020; (+&#49353;&#44628; ) . ggplot(data=mpg)+ geom_point(mapping=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,color=&#39;class&#39;)) . &lt;ggplot: (117624492963)&gt; . - 객체지향적으로? . a2=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,color=&#39;class&#39;) . a1 . {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;} . a2 . {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;} . point2=geom_point(a2) . fig+point2 . &lt;ggplot: (117624600333)&gt; . &#51648;&#50740;&#51012; &#45908; &#52628;&#44032; (&#51201;&#54633;&#49440;,&#52628;&#49464;&#49440;) . fig+point1 . &lt;ggplot: (117624629044)&gt; . sline1=geom_smooth(a1) . fig+point1+sline1 . C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine stats smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (117624849797)&gt; . fig+point2+sline1 . C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine stats smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (117624864687)&gt; . - 명령어로 한번에 그리기 . ggplot(mpg) +geom_point(aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,color=&#39;class&#39;)) +geom_smooth(aes(x=&#39;displ&#39;,y=&#39;hwy&#39;)) # aes(x=&#39;displ&#39;,y=&#39;hwy&#39;) 이건 생략해도 됨, 밑에서 설명할 것 . C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine stats smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (117625399411)&gt; . - 공통적인 맵핑규칙은 ggplot()쪽으로 빼기도 한다. (figure를 선언하는 곳에서 공통으로 선언함) . ggplot(mpg,aes(x=&#39;displ&#39;,y=&#39;hwy&#39;))+geom_point(aes(color=&#39;class&#39;))+geom_smooth() . C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine stats smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (117625531733)&gt; . &#49328;&#51216;&#46020;&#51025;&#50857;2 (4&#52264;&#50896;) . ggplot(mpg,aes(x=&#39;displ&#39;,y=&#39;hwy&#39;))+geom_point(aes(size=&#39;class&#39;,color=&#39;drv&#39;),alpha=0.2) . C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine scales scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. . &lt;ggplot: (117624905376)&gt; . 모든 $x$에 대하여 붉은색 점들이 대부분 초록선과 보라색 점들에 비하여 아래쪽에 위치하여 있음 $ to$ 4륜구동방식이 연비가 좋지 않음 | . - 객체지향적 . a1,a2 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}) . a3=a2.copy() . a1,a2,a3 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}) . a3[&#39;color&#39;]=&#39;drv&#39; a3[&#39;size&#39;]=&#39;class&#39; # 이건 새로 생성 . a1,a2,a3 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;drv&#39;, &#39;size&#39;: &#39;class&#39;}) . 아래와 같이 선언해도 괜찮음 a3=aes(x=&#39;displ&#39;,y=&#39;hwy&#39;,color=&#39;drv&#39;,size=&#39;class&#39;) . | . point3=geom_point(a3,alpha=0.2) . fig+point3 . C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine scales scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. . &lt;ggplot: (117624865663)&gt; . fig+point3+sline1 . C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine scales scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine stats smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (117623265160)&gt; . &#44033; &#44536;&#47353;&#48324;&#47196; &#49440;&#51012; &#46384;&#47196; &#44536;&#47540;&#49688;&#46020; &#51080;&#51012;&#44620;? . a1,a2,a3 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;drv&#39;, &#39;size&#39;: &#39;class&#39;}) . a4=a2.copy() . a4[&#39;color&#39;]=&#39;drv&#39; . a4 . {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;drv&#39;} . sline2=geom_smooth(a4) . fig+sline2+point3 . C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine scales scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine stats smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (117623085858)&gt; . - 선의 색깔을 동일하게 하고 선의 타입을 변경하여 그룹을 표시할수도 있지 않을까? . a1,a2,a3,a4 . ({&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;class&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;drv&#39;, &#39;size&#39;: &#39;class&#39;}, {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;color&#39;: &#39;drv&#39;}) . a5=a1.copy() . a5[&#39;linetype&#39;]=&#39;drv&#39; . a5 . {&#39;x&#39;: &#39;displ&#39;, &#39;y&#39;: &#39;hwy&#39;, &#39;linetype&#39;: &#39;drv&#39;} . sline3=geom_smooth(a5,size=1,color=&#39;gray&#39;) # size는 선의 굵기 . fig+point3+sline3 . C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine scales scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine stats smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (117626080434)&gt; . fig+point3+sline3+sline1 . C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine scales scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine stats smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (117626269175)&gt; . sline2=geom_smooth(a4,size=1,linetype=&#39;dashed&#39;) fig+point3+sline2+sline1 . C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine scales scale_size.py:48: PlotnineWarning: Using size for a discrete variable is not advised. C: Users ehfus Anaconda3 envs dv2021 lib site-packages plotnine stats smoothers.py:310: PlotnineWarning: Confidence intervals are not yet implementedfor lowess smoothings. . &lt;ggplot: (117626079883)&gt; . - 고차원의 변수를 표현할 수 있는 무기는 다양하다. . 산점도(포인트지옴): 점의크기, 점의형태, 점의색깔, 점의투명도 | 라인플랏(스무스지옴, 라인지옴): 선의형태, 선의색깔, 선의굵기 | . &#44208;&#47200; . : 그래프는 데이터 + 지옴 + 맵핑(변수와 에스테틱간의 맵핑) + 스탯(통계) + 포지션 + 축 + 패싯그리드 7개의 조합으로 그릴수 있다. . &#54032;&#45796;&#49828;&#50640;&#49436; column&#51012; &#49440;&#53469;&#54616;&#45716; &#48169;&#48277; . import numpy as np dic={&#39;X1&#39;:np.random.normal(0,1,5), &#39;X2&#39;:np.random.normal(0,1,5), &#39;X3&#39;:np.random.normal(0,1,5)} df=pd.DataFrame(dic) df . X1 X2 X3 . 0 -1.215979 | -1.395564 | 0.193139 | . 1 -0.311555 | 0.430770 | 0.044660 | . 2 -0.464150 | -0.188806 | -0.456508 | . 3 -0.476752 | 0.543144 | 1.066535 | . 4 -1.246602 | -0.812871 | 1.230598 | . df.X1 . 0 -1.215979 1 -0.311555 2 -0.464150 3 -0.476752 4 -1.246602 Name: X1, dtype: float64 . df[&#39;X1&#39;] . 0 -1.215979 1 -0.311555 2 -0.464150 3 -0.476752 4 -1.246602 Name: X1, dtype: float64 . df[[&#39;X1&#39;]] . X1 . 0 -1.215979 | . 1 -0.311555 | . 2 -0.464150 | . 3 -0.476752 | . 4 -1.246602 | . df[&#39;X1&#39;]는 series를 리턴하고 df[[&#39;X1&#39;]]는 dataframe을 리턴한다. | . df.loc[:,&#39;X1&#39;] . 0 -1.215979 1 -0.311555 2 -0.464150 3 -0.476752 4 -1.246602 Name: X1, dtype: float64 . - 방법5 . df.loc[:,[&#39;X1&#39;]] . X1 . 0 -1.215979 | . 1 -0.311555 | . 2 -0.464150 | . 3 -0.476752 | . 4 -1.246602 | . - 방법6 . df.loc[:,[True,False,False]] . X1 . 0 -1.215979 | . 1 -0.311555 | . 2 -0.464150 | . 3 -0.476752 | . 4 -1.246602 | . - 방법7 . df.iloc[:,0] . 0 -1.215979 1 -0.311555 2 -0.464150 3 -0.476752 4 -1.246602 Name: X1, dtype: float64 . - 방법8 . df.iloc[:,[0]] . X1 . 0 -1.215979 | . 1 -0.311555 | . 2 -0.464150 | . 3 -0.476752 | . 4 -1.246602 | . - 방법9 . df.iloc[:,[True,False,False]] . X1 . 0 -1.215979 | . 1 -0.311555 | . 2 -0.464150 | . 3 -0.476752 | . 4 -1.246602 | . &#52280;&#44256;&#49324;&#54637;: &#50676;&#51060;&#47492;&#51060; interger&#51068; &#44221;&#50864; . _df = pd.DataFrame(np.array([[1,2,3],[3,4,5],[5,6,7]])) _df . 0 1 2 . 0 1 | 2 | 3 | . 1 3 | 4 | 5 | . 2 5 | 6 | 7 | . - 아래가 모두 가능하다. . _df[0] . 0 1 1 3 2 5 Name: 0, dtype: int32 . _df[[0]] . 0 . 0 1 | . 1 3 | . 2 5 | . _df.loc[:,0] . 0 1 1 3 2 5 Name: 0, dtype: int32 . _df.loc[:,[0]] . 0 . 0 1 | . 1 3 | . 2 5 | . _df.iloc[:,0] . 0 1 1 3 2 5 Name: 0, dtype: int32 . _df.iloc[:,[0]] . 0 . 0 1 | . 1 3 | . 2 5 | . dic={&#39;X.1&#39;:np.random.normal(0,1,5), &#39;X.2&#39;:np.random.normal(0,1,5), &#39;X.3&#39;:np.random.normal(0,1,5)} _df=pd.DataFrame(dic) _df . X.1 X.2 X.3 . 0 -0.379475 | 0.328678 | -1.183929 | . 1 1.803752 | -2.116759 | 0.436055 | . 2 0.280973 | -0.187272 | -0.685104 | . 3 -0.065296 | 0.383366 | -0.498928 | . 4 0.687288 | -1.173613 | -0.944841 | . _df[&#39;X.1&#39;] . 0 -0.379475 1 1.803752 2 0.280973 3 -0.065296 4 0.687288 Name: X.1, dtype: float64 . # 이건 사용 불가 # df.~ 이 형태로 indexing할 땐 column명에 dot이 있거나 공백이 있으면 사용할 수 없다 . &#50696;&#51228;2: &#50668;&#47084;&#44060;&#51032; &#50676;&#51012; &#49440;&#53469; . dic={&#39;X1&#39;:np.random.normal(0,1,5), &#39;X2&#39;:np.random.normal(0,1,5), &#39;X3&#39;:np.random.normal(0,1,5), &#39;X4&#39;:np.random.normal(0,1,5)} df=pd.DataFrame(dic) df . X1 X2 X3 X4 . 0 1.132239 | 0.408603 | 1.545259 | 0.988863 | . 1 1.141026 | 0.062062 | 0.347106 | 0.915165 | . 2 0.833884 | 0.070472 | -1.086375 | -1.122671 | . 3 -0.269858 | 1.385849 | -0.786887 | -1.641488 | . 4 0.485986 | -0.644105 | -2.143558 | 0.987382 | . - 방법1 . df[[&#39;X1&#39;,&#39;X2&#39;,&#39;X3&#39;]] . X1 X2 X3 . 0 1.132239 | 0.408603 | 1.545259 | . 1 1.141026 | 0.062062 | 0.347106 | . 2 0.833884 | 0.070472 | -1.086375 | . 3 -0.269858 | 1.385849 | -0.786887 | . 4 0.485986 | -0.644105 | -2.143558 | . - 방법2 . df.loc[:,[&#39;X1&#39;,&#39;X2&#39;,&#39;X3&#39;]] . X1 X2 X3 . 0 1.132239 | 0.408603 | 1.545259 | . 1 1.141026 | 0.062062 | 0.347106 | . 2 0.833884 | 0.070472 | -1.086375 | . 3 -0.269858 | 1.385849 | -0.786887 | . 4 0.485986 | -0.644105 | -2.143558 | . - 방법3 . df.loc[:,&#39;X1&#39;:&#39;X3&#39;] . X1 X2 X3 . 0 1.132239 | 0.408603 | 1.545259 | . 1 1.141026 | 0.062062 | 0.347106 | . 2 0.833884 | 0.070472 | -1.086375 | . 3 -0.269858 | 1.385849 | -0.786887 | . 4 0.485986 | -0.644105 | -2.143558 | . - 방법4 . df.loc[:,[True,True,True,False]] . X1 X2 X3 . 0 1.132239 | 0.408603 | 1.545259 | . 1 1.141026 | 0.062062 | 0.347106 | . 2 0.833884 | 0.070472 | -1.086375 | . 3 -0.269858 | 1.385849 | -0.786887 | . 4 0.485986 | -0.644105 | -2.143558 | . - 방법5 . df.iloc[:,[0,1,2]] . X1 X2 X3 . 0 1.132239 | 0.408603 | 1.545259 | . 1 1.141026 | 0.062062 | 0.347106 | . 2 0.833884 | 0.070472 | -1.086375 | . 3 -0.269858 | 1.385849 | -0.786887 | . 4 0.485986 | -0.644105 | -2.143558 | . - 방법6 . df.iloc[:,:3] . X1 X2 X3 . 0 1.132239 | 0.408603 | 1.545259 | . 1 1.141026 | 0.062062 | 0.347106 | . 2 0.833884 | 0.070472 | -1.086375 | . 3 -0.269858 | 1.385849 | -0.786887 | . 4 0.485986 | -0.644105 | -2.143558 | . df.iloc[:,0:3] . X1 X2 X3 . 0 1.132239 | 0.408603 | 1.545259 | . 1 1.141026 | 0.062062 | 0.347106 | . 2 0.833884 | 0.070472 | -1.086375 | . 3 -0.269858 | 1.385849 | -0.786887 | . 4 0.485986 | -0.644105 | -2.143558 | . df.iloc[:,range(3)] . X1 X2 X3 . 0 1.132239 | 0.408603 | 1.545259 | . 1 1.141026 | 0.062062 | 0.347106 | . 2 0.833884 | 0.070472 | -1.086375 | . 3 -0.269858 | 1.385849 | -0.786887 | . 4 0.485986 | -0.644105 | -2.143558 | . - 방법7 . df.iloc[:,[True,True,True,False]] . X1 X2 X3 . 0 1.132239 | 0.408603 | 1.545259 | . 1 1.141026 | 0.062062 | 0.347106 | . 2 0.833884 | 0.070472 | -1.086375 | . 3 -0.269858 | 1.385849 | -0.786887 | . 4 0.485986 | -0.644105 | -2.143558 | . loc&#50640;&#49436; &#49836;&#46972;&#51060;&#49905;&#51008; &#47560;&#51648;&#47561;&#48320;&#49688;&#47484; &#54252;&#54632;, iloc&#50640;&#49436;&#45716; &#54252;&#54632;&#54616;&#51648; &#50506;&#51020; . df.iloc[:,0:3] ## 0,1,2,3중 3은 포함되지 않는다. . X1 X2 X3 . 0 1.132239 | 0.408603 | 1.545259 | . 1 1.141026 | 0.062062 | 0.347106 | . 2 0.833884 | 0.070472 | -1.086375 | . 3 -0.269858 | 1.385849 | -0.786887 | . 4 0.485986 | -0.644105 | -2.143558 | . df.loc[:,&#39;X1&#39;:&#39;X3&#39;] ## &#39;X3&#39;도 포함된다. . X1 X2 X3 . 0 1.132239 | 0.408603 | 1.545259 | . 1 1.141026 | 0.062062 | 0.347106 | . 2 0.833884 | 0.070472 | -1.086375 | . 3 -0.269858 | 1.385849 | -0.786887 | . 4 0.485986 | -0.644105 | -2.143558 | . - 그래서 column의 이름이 integer일 경우는 종종 매우 헷갈리는 일이 일어남 . _df = pd.DataFrame(np.array([[1,2,3,4],[3,4,5,6],[5,6,7,8]])) _df . 0 1 2 3 . 0 1 | 2 | 3 | 4 | . 1 3 | 4 | 5 | 6 | . 2 5 | 6 | 7 | 8 | . _df.loc[:,0:2] . 0 1 2 . 0 1 | 2 | 3 | . 1 3 | 4 | 5 | . 2 5 | 6 | 7 | . _df.iloc[:,0:2] . 0 1 . 0 1 | 2 | . 1 3 | 4 | . 2 5 | 6 | . &#50696;&#51228;3: movie data - &#53945;&#51221;&#51312;&#44148;&#50640; &#47582;&#45716; &#50676;&#51012; &#49440;&#53469; . df=pd.read_csv(&#39;https://raw.githubusercontent.com/PacktPublishing/Pandas-Cookbook/master/data/movie.csv&#39;) . - 열의 이름을 출력하여 보자. . df.columns . Index([&#39;color&#39;, &#39;director_name&#39;, &#39;num_critic_for_reviews&#39;, &#39;duration&#39;, &#39;director_facebook_likes&#39;, &#39;actor_3_facebook_likes&#39;, &#39;actor_2_name&#39;, &#39;actor_1_facebook_likes&#39;, &#39;gross&#39;, &#39;genres&#39;, &#39;actor_1_name&#39;, &#39;movie_title&#39;, &#39;num_voted_users&#39;, &#39;cast_total_facebook_likes&#39;, &#39;actor_3_name&#39;, &#39;facenumber_in_poster&#39;, &#39;plot_keywords&#39;, &#39;movie_imdb_link&#39;, &#39;num_user_for_reviews&#39;, &#39;language&#39;, &#39;country&#39;, &#39;content_rating&#39;, &#39;budget&#39;, &#39;title_year&#39;, &#39;actor_2_facebook_likes&#39;, &#39;imdb_score&#39;, &#39;aspect_ratio&#39;, &#39;movie_facebook_likes&#39;], dtype=&#39;object&#39;) . pd.Series(df.columns) . 0 color 1 director_name 2 num_critic_for_reviews 3 duration 4 director_facebook_likes 5 actor_3_facebook_likes 6 actor_2_name 7 actor_1_facebook_likes 8 gross 9 genres 10 actor_1_name 11 movie_title 12 num_voted_users 13 cast_total_facebook_likes 14 actor_3_name 15 facenumber_in_poster 16 plot_keywords 17 movie_imdb_link 18 num_user_for_reviews 19 language 20 country 21 content_rating 22 budget 23 title_year 24 actor_2_facebook_likes 25 imdb_score 26 aspect_ratio 27 movie_facebook_likes dtype: object . list(range(13))+[26] . [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 26] . df.iloc[:,list(range(13))+[26]] . color director_name num_critic_for_reviews duration director_facebook_likes actor_3_facebook_likes actor_2_name actor_1_facebook_likes gross genres actor_1_name movie_title num_voted_users aspect_ratio . 0 Color | James Cameron | 723.0 | 178.0 | 0.0 | 855.0 | Joel David Moore | 1000.0 | 760505847.0 | Action|Adventure|Fantasy|Sci-Fi | CCH Pounder | Avatar | 886204 | 1.78 | . 1 Color | Gore Verbinski | 302.0 | 169.0 | 563.0 | 1000.0 | Orlando Bloom | 40000.0 | 309404152.0 | Action|Adventure|Fantasy | Johnny Depp | Pirates of the Caribbean: At World&#39;s End | 471220 | 2.35 | . 2 Color | Sam Mendes | 602.0 | 148.0 | 0.0 | 161.0 | Rory Kinnear | 11000.0 | 200074175.0 | Action|Adventure|Thriller | Christoph Waltz | Spectre | 275868 | 2.35 | . 3 Color | Christopher Nolan | 813.0 | 164.0 | 22000.0 | 23000.0 | Christian Bale | 27000.0 | 448130642.0 | Action|Thriller | Tom Hardy | The Dark Knight Rises | 1144337 | 2.35 | . 4 NaN | Doug Walker | NaN | NaN | 131.0 | NaN | Rob Walker | 131.0 | NaN | Documentary | Doug Walker | Star Wars: Episode VII - The Force Awakens | 8 | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 Color | Scott Smith | 1.0 | 87.0 | 2.0 | 318.0 | Daphne Zuniga | 637.0 | NaN | Comedy|Drama | Eric Mabius | Signed Sealed Delivered | 629 | NaN | . 4912 Color | NaN | 43.0 | 43.0 | NaN | 319.0 | Valorie Curry | 841.0 | NaN | Crime|Drama|Mystery|Thriller | Natalie Zea | The Following | 73839 | 16.00 | . 4913 Color | Benjamin Roberds | 13.0 | 76.0 | 0.0 | 0.0 | Maxwell Moody | 0.0 | NaN | Drama|Horror|Thriller | Eva Boehnke | A Plague So Pleasant | 38 | NaN | . 4914 Color | Daniel Hsia | 14.0 | 100.0 | 0.0 | 489.0 | Daniel Henney | 946.0 | 10443.0 | Comedy|Drama|Romance | Alan Ruck | Shanghai Calling | 1255 | 2.35 | . 4915 Color | Jon Gunn | 43.0 | 90.0 | 16.0 | 16.0 | Brian Herzlinger | 86.0 | 85222.0 | Documentary | John August | My Date with Drew | 4285 | 1.85 | . 4916 rows × 14 columns . - 다시열의 이름들을 확인 . df.columns . Index([&#39;color&#39;, &#39;director_name&#39;, &#39;num_critic_for_reviews&#39;, &#39;duration&#39;, &#39;director_facebook_likes&#39;, &#39;actor_3_facebook_likes&#39;, &#39;actor_2_name&#39;, &#39;actor_1_facebook_likes&#39;, &#39;gross&#39;, &#39;genres&#39;, &#39;actor_1_name&#39;, &#39;movie_title&#39;, &#39;num_voted_users&#39;, &#39;cast_total_facebook_likes&#39;, &#39;actor_3_name&#39;, &#39;facenumber_in_poster&#39;, &#39;plot_keywords&#39;, &#39;movie_imdb_link&#39;, &#39;num_user_for_reviews&#39;, &#39;language&#39;, &#39;country&#39;, &#39;content_rating&#39;, &#39;budget&#39;, &#39;title_year&#39;, &#39;actor_2_facebook_likes&#39;, &#39;imdb_score&#39;, &#39;aspect_ratio&#39;, &#39;movie_facebook_likes&#39;], dtype=&#39;object&#39;) . actor&#46972;&#45716; &#45800;&#50612;&#44032; &#54252;&#54632;&#46108; &#48320;&#49688;&#46308;&#47564; &#48977;&#44256;&#49910;&#45796;. . list(map(lambda x : &#39;actor&#39; in x, df.columns)) . [False, False, False, False, False, True, True, True, False, False, True, False, False, False, True, False, False, False, False, False, False, False, False, False, True, False, False, False] . df.iloc[:,list(map(lambda x : &#39;actor&#39; in x, df.columns))] . actor_3_facebook_likes actor_2_name actor_1_facebook_likes actor_1_name actor_3_name actor_2_facebook_likes . 0 855.0 | Joel David Moore | 1000.0 | CCH Pounder | Wes Studi | 936.0 | . 1 1000.0 | Orlando Bloom | 40000.0 | Johnny Depp | Jack Davenport | 5000.0 | . 2 161.0 | Rory Kinnear | 11000.0 | Christoph Waltz | Stephanie Sigman | 393.0 | . 3 23000.0 | Christian Bale | 27000.0 | Tom Hardy | Joseph Gordon-Levitt | 23000.0 | . 4 NaN | Rob Walker | 131.0 | Doug Walker | NaN | 12.0 | . ... ... | ... | ... | ... | ... | ... | . 4911 318.0 | Daphne Zuniga | 637.0 | Eric Mabius | Crystal Lowe | 470.0 | . 4912 319.0 | Valorie Curry | 841.0 | Natalie Zea | Sam Underwood | 593.0 | . 4913 0.0 | Maxwell Moody | 0.0 | Eva Boehnke | David Chandler | 0.0 | . 4914 489.0 | Daniel Henney | 946.0 | Alan Ruck | Eliza Coupe | 719.0 | . 4915 16.0 | Brian Herzlinger | 86.0 | John August | Jon Gunn | 23.0 | . 4916 rows × 6 columns . df.loc[:,list(map(lambda x : &#39;actor&#39; in x, df.columns))] . actor_3_facebook_likes actor_2_name actor_1_facebook_likes actor_1_name actor_3_name actor_2_facebook_likes . 0 855.0 | Joel David Moore | 1000.0 | CCH Pounder | Wes Studi | 936.0 | . 1 1000.0 | Orlando Bloom | 40000.0 | Johnny Depp | Jack Davenport | 5000.0 | . 2 161.0 | Rory Kinnear | 11000.0 | Christoph Waltz | Stephanie Sigman | 393.0 | . 3 23000.0 | Christian Bale | 27000.0 | Tom Hardy | Joseph Gordon-Levitt | 23000.0 | . 4 NaN | Rob Walker | 131.0 | Doug Walker | NaN | 12.0 | . ... ... | ... | ... | ... | ... | ... | . 4911 318.0 | Daphne Zuniga | 637.0 | Eric Mabius | Crystal Lowe | 470.0 | . 4912 319.0 | Valorie Curry | 841.0 | Natalie Zea | Sam Underwood | 593.0 | . 4913 0.0 | Maxwell Moody | 0.0 | Eva Boehnke | David Chandler | 0.0 | . 4914 489.0 | Daniel Henney | 946.0 | Alan Ruck | Eliza Coupe | 719.0 | . 4915 16.0 | Brian Herzlinger | 86.0 | John August | Jon Gunn | 23.0 | . 4916 rows × 6 columns . loc으로 해도 되고 iloc으로 해도 된다. . - 방법3 . list로 안 만들어도 됨 . df.iloc[:,map(lambda x : &#39;actor&#39; in x, df.columns)] . actor_3_facebook_likes actor_2_name actor_1_facebook_likes actor_1_name actor_3_name actor_2_facebook_likes . 0 855.0 | Joel David Moore | 1000.0 | CCH Pounder | Wes Studi | 936.0 | . 1 1000.0 | Orlando Bloom | 40000.0 | Johnny Depp | Jack Davenport | 5000.0 | . 2 161.0 | Rory Kinnear | 11000.0 | Christoph Waltz | Stephanie Sigman | 393.0 | . 3 23000.0 | Christian Bale | 27000.0 | Tom Hardy | Joseph Gordon-Levitt | 23000.0 | . 4 NaN | Rob Walker | 131.0 | Doug Walker | NaN | 12.0 | . ... ... | ... | ... | ... | ... | ... | . 4911 318.0 | Daphne Zuniga | 637.0 | Eric Mabius | Crystal Lowe | 470.0 | . 4912 319.0 | Valorie Curry | 841.0 | Natalie Zea | Sam Underwood | 593.0 | . 4913 0.0 | Maxwell Moody | 0.0 | Eva Boehnke | David Chandler | 0.0 | . 4914 489.0 | Daniel Henney | 946.0 | Alan Ruck | Eliza Coupe | 719.0 | . 4915 16.0 | Brian Herzlinger | 86.0 | John August | Jon Gunn | 23.0 | . 4916 rows × 6 columns . - 방법4 . df.loc[:,map(lambda x : &#39;face&#39; in x, df.columns)] . director_facebook_likes actor_3_facebook_likes actor_1_facebook_likes cast_total_facebook_likes facenumber_in_poster actor_2_facebook_likes movie_facebook_likes . 0 0.0 | 855.0 | 1000.0 | 4834 | 0.0 | 936.0 | 33000 | . 1 563.0 | 1000.0 | 40000.0 | 48350 | 0.0 | 5000.0 | 0 | . 2 0.0 | 161.0 | 11000.0 | 11700 | 1.0 | 393.0 | 85000 | . 3 22000.0 | 23000.0 | 27000.0 | 106759 | 0.0 | 23000.0 | 164000 | . 4 131.0 | NaN | 131.0 | 143 | 0.0 | 12.0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | . 4911 2.0 | 318.0 | 637.0 | 2283 | 2.0 | 470.0 | 84 | . 4912 NaN | 319.0 | 841.0 | 1753 | 1.0 | 593.0 | 32000 | . 4913 0.0 | 0.0 | 0.0 | 0 | 0.0 | 0.0 | 16 | . 4914 0.0 | 489.0 | 946.0 | 2386 | 5.0 | 719.0 | 660 | . 4915 16.0 | 16.0 | 86.0 | 163 | 0.0 | 23.0 | 456 | . 4916 rows × 7 columns . &#48320;&#49688;&#51060;&#47492;&#51060; s&#47196; &#45149;&#45208;&#45716; &#48320;&#49688;&#46308;&#47564; &#48977;&#44256;&#49910;&#45796;. . df.iloc[:,map(lambda x: &#39;s&#39; == x[-1],df.columns )] . num_critic_for_reviews director_facebook_likes actor_3_facebook_likes actor_1_facebook_likes gross genres num_voted_users cast_total_facebook_likes plot_keywords num_user_for_reviews actor_2_facebook_likes movie_facebook_likes . 0 723.0 | 0.0 | 855.0 | 1000.0 | 760505847.0 | Action|Adventure|Fantasy|Sci-Fi | 886204 | 4834 | avatar|future|marine|native|paraplegic | 3054.0 | 936.0 | 33000 | . 1 302.0 | 563.0 | 1000.0 | 40000.0 | 309404152.0 | Action|Adventure|Fantasy | 471220 | 48350 | goddess|marriage ceremony|marriage proposal|pi... | 1238.0 | 5000.0 | 0 | . 2 602.0 | 0.0 | 161.0 | 11000.0 | 200074175.0 | Action|Adventure|Thriller | 275868 | 11700 | bomb|espionage|sequel|spy|terrorist | 994.0 | 393.0 | 85000 | . 3 813.0 | 22000.0 | 23000.0 | 27000.0 | 448130642.0 | Action|Thriller | 1144337 | 106759 | deception|imprisonment|lawlessness|police offi... | 2701.0 | 23000.0 | 164000 | . 4 NaN | 131.0 | NaN | 131.0 | NaN | Documentary | 8 | 143 | NaN | NaN | 12.0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 1.0 | 2.0 | 318.0 | 637.0 | NaN | Comedy|Drama | 629 | 2283 | fraud|postal worker|prison|theft|trial | 6.0 | 470.0 | 84 | . 4912 43.0 | NaN | 319.0 | 841.0 | NaN | Crime|Drama|Mystery|Thriller | 73839 | 1753 | cult|fbi|hideout|prison escape|serial killer | 359.0 | 593.0 | 32000 | . 4913 13.0 | 0.0 | 0.0 | 0.0 | NaN | Drama|Horror|Thriller | 38 | 0 | NaN | 3.0 | 0.0 | 16 | . 4914 14.0 | 0.0 | 489.0 | 946.0 | 10443.0 | Comedy|Drama|Romance | 1255 | 2386 | NaN | 9.0 | 719.0 | 660 | . 4915 43.0 | 16.0 | 16.0 | 86.0 | 85222.0 | Documentary | 4285 | 163 | actress name in title|crush|date|four word tit... | 84.0 | 23.0 | 456 | . 4916 rows × 12 columns . df.loc[:,map(lambda x: &#39;s&#39; == x[-1],df.columns )] . num_critic_for_reviews director_facebook_likes actor_3_facebook_likes actor_1_facebook_likes gross genres num_voted_users cast_total_facebook_likes plot_keywords num_user_for_reviews actor_2_facebook_likes movie_facebook_likes . 0 723.0 | 0.0 | 855.0 | 1000.0 | 760505847.0 | Action|Adventure|Fantasy|Sci-Fi | 886204 | 4834 | avatar|future|marine|native|paraplegic | 3054.0 | 936.0 | 33000 | . 1 302.0 | 563.0 | 1000.0 | 40000.0 | 309404152.0 | Action|Adventure|Fantasy | 471220 | 48350 | goddess|marriage ceremony|marriage proposal|pi... | 1238.0 | 5000.0 | 0 | . 2 602.0 | 0.0 | 161.0 | 11000.0 | 200074175.0 | Action|Adventure|Thriller | 275868 | 11700 | bomb|espionage|sequel|spy|terrorist | 994.0 | 393.0 | 85000 | . 3 813.0 | 22000.0 | 23000.0 | 27000.0 | 448130642.0 | Action|Thriller | 1144337 | 106759 | deception|imprisonment|lawlessness|police offi... | 2701.0 | 23000.0 | 164000 | . 4 NaN | 131.0 | NaN | 131.0 | NaN | Documentary | 8 | 143 | NaN | NaN | 12.0 | 0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 4911 1.0 | 2.0 | 318.0 | 637.0 | NaN | Comedy|Drama | 629 | 2283 | fraud|postal worker|prison|theft|trial | 6.0 | 470.0 | 84 | . 4912 43.0 | NaN | 319.0 | 841.0 | NaN | Crime|Drama|Mystery|Thriller | 73839 | 1753 | cult|fbi|hideout|prison escape|serial killer | 359.0 | 593.0 | 32000 | . 4913 13.0 | 0.0 | 0.0 | 0.0 | NaN | Drama|Horror|Thriller | 38 | 0 | NaN | 3.0 | 0.0 | 16 | . 4914 14.0 | 0.0 | 489.0 | 946.0 | 10443.0 | Comedy|Drama|Romance | 1255 | 2386 | NaN | 9.0 | 719.0 | 660 | . 4915 43.0 | 16.0 | 16.0 | 86.0 | 85222.0 | Documentary | 4285 | 163 | actress name in title|crush|date|four word tit... | 84.0 | 23.0 | 456 | . 4916 rows × 12 columns . &#48320;&#49688;&#51060;&#47492;&#51060; c &#54841;&#51008; d&#47196; &#49884;&#51089;&#54616;&#45716; &#48320;&#49688;&#46308;&#47564; &#48977;&#44256;&#49910;&#45796;. . df.iloc[:,map(lambda x: &#39;c&#39; == x[0] or &#39;d&#39; == x[0] ,df.columns )] . color director_name duration director_facebook_likes cast_total_facebook_likes country content_rating . 0 Color | James Cameron | 178.0 | 0.0 | 4834 | USA | PG-13 | . 1 Color | Gore Verbinski | 169.0 | 563.0 | 48350 | USA | PG-13 | . 2 Color | Sam Mendes | 148.0 | 0.0 | 11700 | UK | PG-13 | . 3 Color | Christopher Nolan | 164.0 | 22000.0 | 106759 | USA | PG-13 | . 4 NaN | Doug Walker | NaN | 131.0 | 143 | NaN | NaN | . ... ... | ... | ... | ... | ... | ... | ... | . 4911 Color | Scott Smith | 87.0 | 2.0 | 2283 | Canada | NaN | . 4912 Color | NaN | 43.0 | NaN | 1753 | USA | TV-14 | . 4913 Color | Benjamin Roberds | 76.0 | 0.0 | 0 | USA | NaN | . 4914 Color | Daniel Hsia | 100.0 | 0.0 | 2386 | USA | PG-13 | . 4915 Color | Jon Gunn | 90.0 | 16.0 | 163 | USA | PG | . 4916 rows × 7 columns .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/07/intro2.html",
            "relUrl": "/2022/01/07/intro2.html",
            "date": " • Jan 7, 2022"
        }
        
    
  
    
        ,"post13": {
            "title": "2022/01/06/THU",
            "content": "- 예제1: 한줄 띄우기 . &#39;나는 n곽도성&#39; . &#39;나는 n곽도성&#39; . print(&#39;나는 n최규빈&#39;) . 나는 최규빈 . – 예제2: 탭 . print(&#39;나는 t곽도성&#39;) . 나는 곽도성 . - 예제3: 이스케이프 . 나는 n최규빈 자체를 출력하고 싶다 . print(&#39;나는 n최규빈&#39;) . 나는 n최규빈 . print(&#39; &#39;) . . print(&#39;나는 &#39;최규빈 &#39;&#39;) . 나는&#39;최규빈&#39; . print(&quot;나는&#39;최규빈&#39;&quot;) . 나는&#39;최규빈&#39; . &#47928;&#51088;&#50676; &#47700;&#49548;&#46300; . - 예제1 . S = &#39;spammy&#39; S.replace(&#39;mm&#39;,&#39;xx&#39;) . &#39;spaxxy&#39; . – 예제2 . S = &#39;xxxxSPAMxxxxSPAMxxxx&#39; . S.replace(&#39;SPAM&#39;,&#39;EGGS&#39;) . &#39;xxxxEGGSxxxxEGGSxxxx&#39; . S.replace(&#39;SPAM&#39;,&#39;EGGS&#39;,1) # 1번만 바꿔라 . &#39;xxxxEGGSxxxxSPAMxxxx&#39; . – 예제1 . S = &#39;xxxxSPAMxxxxSPAMxxxx&#39; . where=S.find(&#39;A&#39;) . where . 6 . a=S.find(&#39;SPAM&#39;) . SPAM자체를 찾진 않음 . a . 4 . S[a] . &#39;S&#39; . S[:a]+&#39;EGGS&#39;+S[(where+4):] . &#39;xxxxEGGSxxSPAMxxxx&#39; . – 예제1 . S=&#39;spammy&#39; . S[3:5] . &#39;mm&#39; . . mm을 xx로 바꾸고 싶은데 문자열은 불변리스트라서 바꿀 수 없다. | . then 문자열을 잠시 가변객체인 리스트로 바꾼뒤 리스트에서 자유롭게 편집하고 그 다음에 다시 문자열로 만들자. | . L=list(S) . L . [&#39;s&#39;, &#39;p&#39;, &#39;a&#39;, &#39;m&#39;, &#39;m&#39;, &#39;y&#39;] . L[3:5] . [&#39;m&#39;, &#39;m&#39;] . L[3:5]=[&#39;x&#39;,&#39;x&#39;] . L . [&#39;s&#39;, &#39;p&#39;, &#39;a&#39;, &#39;x&#39;, &#39;x&#39;, &#39;y&#39;] . . &#39;-&#39;.join([&#39;a&#39;,&#39;b&#39;,&#39;c&#39;]) . &#39;a-b-c&#39; . . S=&#39;&#39;.join(L) . S . &#39;spaxxy&#39; . – 예제1 . s=&#39;bob,hacker,40&#39; . s . &#39;bob,hacker,40&#39; . a=s.split(&#39;,&#39;) a . [&#39;bob&#39;, &#39;hacker&#39;, &#39;40&#39;] . type(a) . list . list형태임 . – 예제2 . s= &#39;aaa bbb ccc&#39; . 구분되어 있는 게 스페이스이기 때문에 . 스페이스 기준으로 나눠서 원소만들고 list안에 넣어준다 = split . s.split(&#39; &#39;) . [&#39;aaa&#39;, &#39;bbb&#39;, &#39;ccc&#39;] . s.split() . [&#39;aaa&#39;, &#39;bbb&#39;, &#39;ccc&#39;] . s: 스트링 . (스트링을 받아서 넣어줌) . &#39;age: %s&#39; % &#39;35&#39; . &#39;age: 35&#39; . &#39;age: %s&#39; % &#39;e&#39; . &#39;age: e&#39; . &#39;age: %a&#39; % &#39;e&#39; . &#34;age: &#39;e&#39;&#34; . d: 정수 . &#39;age: %d&#39; % 39.254 . &#39;age: 39&#39; . f: 플롯 . &#39;age: %f&#39; % 39 . &#39;age: 39.000000&#39; . - 예제2 . &#39;addr: %s to %s&#39; % (&#39;seoul&#39;,&#39;jeonju&#39;) . &#39;addr: seoul to jeonju&#39; . 꼭 tuple(괄호가 포함된 상태)로 묶어주어야 함 . . 이렇게 사용하면 안 됨 . &#39;addr: %s to %s&#39; % [&#39;seoul&#39;,&#39;jeonju&#39;] . &#39;addr: %s to %s&#39; % &#39;seoul&#39;,&#39;jeonju&#39; . . s = &#39;addr: %s to %s&#39; s % (&#39;seoul&#39;,&#39;jeonju&#39;) . &#39;addr: seoul to jeonju&#39; . &#46357;&#49492;&#45320;&#47532; &#44592;&#48152; &#54252;&#47588;&#54021; . - 예제1 . &#39;여기 %(food1)s 1개, %(food2)s 1개 주문이요&#39; % {&#39;food1&#39;:&#39;짜장면&#39;,&#39;food2&#39;:&#39;짬뽕&#39;} . &#39;여기 짜장면 1개, 짬뽕 1개 주문이요&#39; . &#39;여기 %(food1)s 1개, %(food2)s 1개 주문이요, 아.. 아니다. %(food1)s은 취소하고 그냥 %(food2)s 두개 주세요&#39; % {&#39;food1&#39;:&#39;짜장면&#39;,&#39;food2&#39;:&#39;짬뽕&#39;} . &#39;여기 짜장면 1개, 짬뽕 1개 주문이요, 아.. 아니다. 짜장면은 취소하고 그냥 짬뽕 두개 주세요&#39; . - 예제2 . mail=&#39;%(studentname)s 학생 안녕하세요 n저는 통계학과 xxx 교수 입니다. n전공설계과목 지침에 따라 %(studentname)s학생과 2회 상담을 실시해야 합니다. n저는 %(day)s에 시간이 괜찮은데 %(studentname)s 학생도 그날 시간이 괜찮을까요? n&#39; . print(mail % {&#39;studentname&#39;:&#39;곽도성&#39;, &#39;day&#39;:&#39;5월31일&#39;}) . 곽도성 학생 안녕하세요 저는 통계학과 xxx 교수 입니다. 전공설계과목 지침에 따라 곽도성학생과 2회 상담을 실시해야 합니다. 저는 5월31일에 시간이 괜찮은데 곽도성 학생도 그날 시간이 괜찮을까요? . - 예제3 . import pandas as pd df=pd.DataFrame({&#39;studentname&#39;:[&#39;As&#39;,&#39;Bs&#39;],&#39;day&#39;:[&#39;5월31일&#39;,&#39;6월3일&#39;]}) df . studentname day . 0 As | 5월31일 | . 1 Bs | 6월3일 | . df.loc[:,[&#39;day&#39;]] . day . 0 5월31일 | . 1 6월3일 | . df.iloc[[0]] . studentname day . 0 As | 5월31일 | . dict(df.iloc[1]) . {&#39;studentname&#39;: &#39;Bs&#39;, &#39;day&#39;: &#39;6월3일&#39;} . dict(df.iloc[[1]]) . {&#39;studentname&#39;: 1 Bs Name: studentname, dtype: object, &#39;day&#39;: 1 6월3일 Name: day, dtype: object} . for i in [0,1]: print(mail % dict(df.iloc[i])) . As 학생 안녕하세요 저는 통계학과 xxx 교수 입니다. 전공설계과목 지침에 따라 As학생과 2회 상담을 실시해야 합니다. 저는 5월31일에 시간이 괜찮은데 As 학생도 그날 시간이 괜찮을까요? Bs 학생 안녕하세요 저는 통계학과 xxx 교수 입니다. 전공설계과목 지침에 따라 Bs학생과 2회 상담을 실시해야 합니다. 저는 6월3일에 시간이 괜찮은데 Bs 학생도 그날 시간이 괜찮을까요? . &#47700;&#49436;&#46300; . mail=&#39;{studentname} 학생 안녕하세요 n저는 통계학과 최규빈 교수 입니다. n전공설계과목 지침에 따라 {studentname}학생과 2회 상담을 실시해야 합니다. n저는 {day}에 시간이 괜찮은데 {studentname} 학생도 그날 시간이 괜찮을까요? n&#39; . mail.format(studentname=&#39;박혜원&#39;,day=&#39;6월2일&#39;) . &#39;박혜원 학생 안녕하세요 n저는 통계학과 최규빈 교수 입니다. n전공설계과목 지침에 따라 박혜원학생과 2회 상담을 실시해야 합니다. n저는 6월2일에 시간이 괜찮은데 박혜원 학생도 그날 시간이 괜찮을까요? n&#39; . print(mail.format(studentname=&#39;박혜원&#39;,day=&#39;6월2일&#39;)) . 박혜원 학생 안녕하세요 저는 통계학과 최규빈 교수 입니다. 전공설계과목 지침에 따라 박혜원학생과 2회 상담을 실시해야 합니다. 저는 6월2일에 시간이 괜찮은데 박혜원 학생도 그날 시간이 괜찮을까요? . – 예제2 . &#39;이름:{},나이:{},성별:{}&#39;.format(&#39;곽도성&#39;,&#39;23&#39;,&#39;남&#39;) . &#39;이름:곽도성,나이:23,성별:남&#39; . df=pd.DataFrame({&#39;a&#39;:[1,2,3],&#39;b&#39;:[1,2,3]}) . df . a b . 0 1 | 1 | . 1 2 | 2 | . 2 3 | 3 | . df.a . 0 1 1 2 2 3 Name: a, dtype: int64 . df[&#39;a&#39;] . 0 1 1 2 2 3 Name: a, dtype: int64 . df[[&#39;a&#39;]] . a . 0 1 | . 1 2 | . 2 3 | . df.iloc[0] . a 1 b 1 Name: 0, dtype: int64 . df.loc[2] . a 3 b 3 Name: 2, dtype: int64 . df.iloc[:,0] . 0 1 1 2 2 3 Name: a, dtype: int64 . df.iloc[:,1] . 0 1 1 2 2 3 Name: b, dtype: int64 .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/06/intro3.html",
            "relUrl": "/2022/01/06/intro3.html",
            "date": " • Jan 6, 2022"
        }
        
    
  
    
        ,"post14": {
            "title": "2022/01/06/THU",
            "content": "lambda . - 예제1: 사용방법 . lambda x=1,y=2,z=3 : x+y+z . &lt;function __main__.&lt;lambda&gt;(x=1, y=2, z=3)&gt; . (lambda x=1,y=2,z=3 : x+y+z)() . 6 . a() . 6 . a(1,1,1) . 3 . f = lambda x,y,z : x+y+z # lambda 입력:출력 . f(2,3,4) . 9 . - 예제2: 디폴트입력값 . x= (lambda a=&#39;fee&#39;,b=&#39;fie&#39;,c=&#39;foe&#39;: a+b+c) . x() . &#39;feefiefoe&#39; . x(&#39;wee&#39;,&#39;려치&#39;) . &#39;wee려치foe&#39; . &#50696;&#51228;3: &#46988;&#45796;&#46308;&#51032; &#47532;&#49828;&#53944;&#44032;&#45733; . l=[lambda x: x**2, lambda x: x**3, lambda x: x**4] . iter_l=iter(l) . iter_l.__next__() . &lt;function __main__.&lt;lambda&gt;(x)&gt; . 즉 l자체가 iterable object . for a in l: print(a(2)) . 4 8 16 . - 예제4: 람다들의 딕셔너리 가능 . dct={&#39;f1&#39;: (lambda x: x+1), &#39;f2&#39;: (lambda x: x+22), &#39;f3&#39;: (lambda x: x+333)} . dct[&#39;f1&#39;](1), dct[&#39;f2&#39;](1), dct[&#39;f3&#39;](1) . (2, 23, 334) . - 예제5: 조건부 출력 . (예비학습) 문자열의 대소비교 . &#39;a&#39; &lt; &#39;b&#39; . True . &#39;c&#39; &lt; &#39;b&#39; . False . (예제시작) . lower = lambda x,y : x if x&lt;y else y . lower(&#39;a&#39;,&#39;b&#39;) . &#39;a&#39; . lower(&#39;c&#39;,&#39;b&#39;) . &#39;b&#39; . - 예제6 : lambda expression 을 return으로 반환가능 . def action(x): return (lambda y: x+y) . act = action(99) ## act는 99+y를 수행하는 함수 act2 = action(98) ## act2는 98+y를 수행하는 함수 . print(act(2)) print(act2(2)) # 윗 줄 아랫 줄에 대입된 2는 y자리에 대입된 것이다. . 101 100 . - 예제7: 예제6의 발전 . action = lambda x: lambda y: x+y act= action(99) act2=action(98) print(act(2)) print(act2(2)) . 101 100 . map . - 예제1: 사용방법 . def inc(x): return x+1 . list(map(inc,[1,2,3,4])) . [2, 3, 4, 5] . - 예제1의 변형(람다사용) . list(map(lambda x: x+1,[1,2,3,4])) . [2, 3, 4, 5] . - 예제2: map과 리스트컴프리헨션 비교 . f= lambda x: x+2 . f(2) . 4 . 이럴 땐 f의 입력으로 int도 가능 . f = lambda x: (&#39;1&#39; in x ) . # 내 생각엔 &#39;1&#39; in x 라는 함수 자체에서 x의 입력으로 받을 수 있는 것들이 int형은 안 되는 것 같음 . f(&#39;a&#39;) . False . f(&#39;X1&#39;),f(&#39;X2&#39;),f(&#39;Y1&#39;),f(&#39;Y2&#39;) . (True, False, True, False) . map . list(map(f,[&#39;X1&#39;,&#39;X2&#39;,&#39;Y3&#39;,&#39;Y4&#39;])) . [True, False, False, False] . (&#47532;&#49828;&#53944;&#52980;&#54532;&#47532;&#54760;&#49496;&#44284; &#48708;&#44368;)(&#51473;&#50836;) . [f(x) for x in [&#39;X1&#39;,&#39;X2&#39;,&#39;Y3&#39;,&#39;Y4&#39;]] . [True, False, False, False] . - 예제3: 두개의 입력을 받는 함수(pow) map, 리스트컴프리헨션 비교 . (함수소개) . pow(2,4) . 16 . (map) . list(map(pow,[2,2,2,3,3,3],[0,1,2,0,1,2])) . [1, 2, 4, 1, 3, 9] . (리스트컴프리헨션과 비교) . [pow(x,y) for x,y in zip([2,2,2,3,3,3],[0,1,2,0,1,2])] . [1, 2, 4, 1, 3, 9] . - 예제4: map은 (하나의 함수,다양한 입력)인 경우 사용가능 . 아래 셀은 함수가 세개라서 사용 불가능 . l=[lambda x: x+1, lambda x: x+2, lambda x: x+3 ] . . 리스트컴프리헨션은 (다양한함수,다양한입력)이 가능함 . [l[i](x) for i,x in zip([0,1,2],[100,200,300])] . [101, 202, 303] . - 종합: 리스트컴프리헨션과 비교하면 (1) 반복인덱스를 쓰지 않는 장점이 있는 반면 (2) 좀 더 제약적으로 사용할 수밖에 없다는 단점이 있음 . &#50528;&#46300;&#50892;&#46300; &#53552;&#54532;&#54000; . - 터프티의 이론중 백미: 엄격한 미니멀리즘 . 최소한의 잉크로 많은 정보를 전달할 수 있다면 그것이 바로 좋은 그래프이다. | 작은 지면 내에서 잉크를 최대한 적게 써서 짧은 시간 안에 많은 영감을 주어야 한다. | . - 데이터-잉크비: 데이터를 표현하는데 들아가는 잉크의 양 / 그래픽을 인쇄하는데 들어가는 잉크의 총량 . - 차트정크 (나이젤홈즈의 그래프) =&gt; 상당히 좋지 않은 차트를 의미함 . . - 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽 . . - 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽 . . - 별로인 그래프 (왼쪽) / 우수한 그래프 오른쪽 . . &#52272;&#49828;&#48120;&#45208;&#46300;&#51032; &#46020;&#54364; (&#51064;&#47448;&#50669;&#49324;&#49345; &#44032;&#51109; &#54988;&#47469;&#54620; &#49884;&#44033;&#54868;) . . 군대의 크기, 2차원 평면상의 위치, 군대의 이동방향, 모스코바에서 퇴각하는 동안의 여러날짜, 온도 $ to$ 6차원의 변수 | . - 왜 우수한 그래프일까? . 자료를 파악하는 기법은 최근까지도 산점도, 막대그래프, 라인플랏에 의존 | 이러한 플랏의 단점은 고차원의 자료를 분석하기 어렵다는 것임 | 미나드는 여러그램을 그리는 방법 대신에 한 그림에서 패널을 늘리는 방법을 선택함. | . &#50696;&#51228; . import pandas as pd x=[44,48,49,58,62,68,69,70,76,79] ## 몸무게 y=[159,160,162,165,167,162,165,175,165,172] ## 키 g= &#39;f&#39;,&#39;f&#39;,&#39;f&#39;,&#39;f&#39;,&#39;m&#39;,&#39;f&#39;,&#39;m&#39;,&#39;m&#39;,&#39;m&#39;,&#39;m&#39; df=pd.DataFrame({&#39;w&#39;:x,&#39;h&#39;:y,&#39;g&#39;:g}) . df . w h g . 0 44 | 159 | f | . 1 48 | 160 | f | . 2 49 | 162 | f | . 3 58 | 165 | f | . 4 62 | 167 | m | . 5 68 | 162 | f | . 6 69 | 165 | m | . 7 70 | 175 | m | . 8 76 | 165 | m | . 9 79 | 172 | m | . - 미나드의 접근방법 . import seaborn as sns sns.scatterplot(data=df,x=&#39;w&#39;,y=&#39;h&#39;,hue=&#39;g&#39;) . &lt;AxesSubplot:xlabel=&#39;w&#39;, ylabel=&#39;h&#39;&gt; . 아래 셀은 지양하자 . figs = sns.FacetGrid(df,col=&#39;g&#39;) figs.map(sns.scatterplot,&#39;w&#39;,&#39;h&#39;) . &lt;seaborn.axisgrid.FacetGrid at 0x1ea09b30220&gt; . - 생각보다 데이터가 정리된 형태에 따라서 시각화에 대한 사고방식이 달라진다. 아래와 같은 자료를 받았다고 하자. . df . w h g . 0 44 | 159 | f | . 1 48 | 160 | f | . 2 49 | 162 | f | . 3 58 | 165 | f | . 4 62 | 167 | m | . 5 68 | 162 | f | . 6 69 | 165 | m | . 7 70 | 175 | m | . 8 76 | 165 | m | . 9 79 | 172 | m | . df1=df.query(&quot;g ==&#39;f&#39;&quot;)[[&#39;w&#39;,&#39;h&#39;]] ## 여성.csv df2=df.query(&quot;g ==&#39;m&#39;&quot;)[[&#39;w&#39;,&#39;h&#39;]] ## 남성.csv . df1 . w h . 0 44 | 159 | . 1 48 | 160 | . 2 49 | 162 | . 3 58 | 165 | . 5 68 | 162 | . df2 . w h . 4 62 | 167 | . 6 69 | 165 | . 7 70 | 175 | . 8 76 | 165 | . 9 79 | 172 | . - 데이터프레임을 바꿀 생각을 하는게 쉽지 않다. . (방법1) . df1[&#39;g&#39;]= &#39;f&#39; . df1 . w h g . 0 44 | 159 | f | . 1 48 | 160 | f | . 2 49 | 162 | f | . 3 58 | 165 | f | . 5 68 | 162 | f | . df2[&#39;g&#39;]= &#39;m&#39; . df2 . w h g . 4 62 | 167 | m | . 6 69 | 165 | m | . 7 70 | 175 | m | . 8 76 | 165 | m | . 9 79 | 172 | m | . pd.concat([df1,df2]) . w h g . 0 44 | 159 | f | . 1 48 | 160 | f | . 2 49 | 162 | f | . 3 58 | 165 | f | . 5 68 | 162 | f | . 4 62 | 167 | m | . 6 69 | 165 | m | . 7 70 | 175 | m | . 8 76 | 165 | m | . 9 79 | 172 | m | . (방법2) . df1=df.query(&quot;g ==&#39;f&#39;&quot;)[[&#39;w&#39;,&#39;h&#39;]] ## 여성.csv df2=df.query(&quot;g ==&#39;m&#39;&quot;)[[&#39;w&#39;,&#39;h&#39;]] ## 남성.csv . df_=pd.concat([df1,df2],keys=[&#39;f&#39;,&#39;m&#39;]) df_ . w h . f 0 44 | 159 | . 1 48 | 160 | . 2 49 | 162 | . 3 58 | 165 | . 5 68 | 162 | . m 4 62 | 167 | . 6 69 | 165 | . 7 70 | 175 | . 8 76 | 165 | . 9 79 | 172 | . . df_.index . MultiIndex([(&#39;f&#39;, 0), (&#39;f&#39;, 1), (&#39;f&#39;, 2), (&#39;f&#39;, 3), (&#39;f&#39;, 5), (&#39;m&#39;, 4), (&#39;m&#39;, 6), (&#39;m&#39;, 7), (&#39;m&#39;, 8), (&#39;m&#39;, 9)], ) . 지금은 index가 튜플형태임 . df_.loc[(&#39;f&#39;,3)] . w 58 h 165 Name: (f, 3), dtype: int64 . . pd.concat([df1,df2],keys=[&#39;f&#39;,&#39;m&#39;]).reset_index() . level_0 level_1 w h . 0 f | 0 | 44 | 159 | . 1 f | 1 | 48 | 160 | . 2 f | 2 | 49 | 162 | . 3 f | 3 | 58 | 165 | . 4 f | 5 | 68 | 162 | . 5 m | 4 | 62 | 167 | . 6 m | 6 | 69 | 165 | . 7 m | 7 | 70 | 175 | . 8 m | 8 | 76 | 165 | . 9 m | 9 | 79 | 172 | . pd.concat([df1,df2],keys=[&#39;f&#39;,&#39;m&#39;]).reset_index().iloc[:,[0,2,3]] . level_0 w h . 0 f | 44 | 159 | . 1 f | 48 | 160 | . 2 f | 49 | 162 | . 3 f | 58 | 165 | . 4 f | 68 | 162 | . 5 m | 62 | 167 | . 6 m | 69 | 165 | . 7 m | 70 | 175 | . 8 m | 76 | 165 | . 9 m | 79 | 172 | . pd.concat([df1,df2],keys=[&#39;f&#39;,&#39;m&#39;]).reset_index().iloc[:,[0,2,3]].rename(columns={&#39;level_0&#39;:&#39;g&#39;}) . g w h . 0 f | 44 | 159 | . 1 f | 48 | 160 | . 2 f | 49 | 162 | . 3 f | 58 | 165 | . 4 f | 68 | 162 | . 5 m | 62 | 167 | . 6 m | 69 | 165 | . 7 m | 70 | 175 | . 8 m | 76 | 165 | . 9 m | 79 | 172 | . (방법3) . df_1=df.query(&quot;g==&#39;f&#39;&quot;) df_2=df.query(&quot;g==&#39;m&#39;&quot;) pd.concat([df_1,df_2]) . w h g . 0 44 | 159 | f | . 1 48 | 160 | f | . 2 49 | 162 | f | . 3 58 | 165 | f | . 5 68 | 162 | f | . 4 62 | 167 | m | . 6 69 | 165 | m | . 7 70 | 175 | m | . 8 76 | 165 | m | . 9 79 | 172 | m | .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/06/intro2.html",
            "relUrl": "/2022/01/06/intro2.html",
            "date": " • Jan 6, 2022"
        }
        
    
  
    
        ,"post15": {
            "title": "2022/01/05/WED",
            "content": "- 예제1 . a=11 if a&lt;5: print(&#39;a=....1,2,3,4&#39;) elif a&gt;10: print(&#39;a=11,12,13,....&#39;) else: print(&#39;a=5,6,7,...,10&#39;) . a=11,12,13,.... . - 예제2 . a,b=2,3 if a==b: print(&#39;a=b&#39;) else: if a&lt;b: print(&#39;a&lt;b&#39;) else: print(&#39;a&gt;b&#39;) . a&lt;b . - 예제3 . a=2 if a==1: print(&#39;a=1&#39;) . 2이면 뭐 하라고 한 적 없으니까 그냥 아무것도 실행하지 않음 . for &#47928; . - 예제1-리스트! . for i in [1,2,3,4]: print(i) . 1 2 3 4 . i . 4 . i는 4로 저장되고 종료 . - 예제2- 튜플! . for i in (1,2,3,4): print(i) . 1 2 3 4 . - 예제3-스트링! . for i in &#39;1234&#39;: print(i) . 1 2 3 4 . - 의문 . for i in ???: print(i) . 에서 물음표 자리에 올 수 있는 것이 무엇일까? . - 예제4 . a=5 for i in a: print(i) . 이렇게 입력하면 에러 발생 . 5라고 출력될 줄 알았는데 아니었다. . 무슨 차이인가? . 1차원 이상의 자료에서 for문 정의가 가능하다 . - 예제5 . L=[[1,2,3],[3,4,5]] . for i in L: print(i) . [1, 2, 3] [3, 4, 5] . import pandas as pd df=pd.DataFrame(L) . df . 0 1 2 . 0 1 | 2 | 3 | . 1 3 | 4 | 5 | . for i in df: print(i) . 0 1 2 . column명 불러오는 건가? . import numpy as np ndr=np.array(L) . ndr . array([[1, 2, 3], [3, 4, 5]]) . for i in ndr: print(i) . [1 2 3] [3 4 5] . i . array([3, 4, 5]) . for&#47928;&#51032; &#46041;&#51089;&#50896;&#47532; . for i in ???: print(i) . ??? 자리에 올 수 있는 것은 dir()하여 __iter__()라는 메서드가 있는 object이다. . 이러한 오브젝트를 iterable한 object라 한다 . a=1 . dir(a) . [&#39;__abs__&#39;, &#39;__add__&#39;, &#39;__and__&#39;, &#39;__bool__&#39;, &#39;__ceil__&#39;, &#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dir__&#39;, &#39;__divmod__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__float__&#39;, &#39;__floor__&#39;, &#39;__floordiv__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__getnewargs__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__index__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__int__&#39;, &#39;__invert__&#39;, &#39;__le__&#39;, &#39;__lshift__&#39;, &#39;__lt__&#39;, &#39;__mod__&#39;, &#39;__mul__&#39;, &#39;__ne__&#39;, &#39;__neg__&#39;, &#39;__new__&#39;, &#39;__or__&#39;, &#39;__pos__&#39;, &#39;__pow__&#39;, &#39;__radd__&#39;, &#39;__rand__&#39;, &#39;__rdivmod__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__rfloordiv__&#39;, &#39;__rlshift__&#39;, &#39;__rmod__&#39;, &#39;__rmul__&#39;, &#39;__ror__&#39;, &#39;__round__&#39;, &#39;__rpow__&#39;, &#39;__rrshift__&#39;, &#39;__rshift__&#39;, &#39;__rsub__&#39;, &#39;__rtruediv__&#39;, &#39;__rxor__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__sub__&#39;, &#39;__subclasshook__&#39;, &#39;__truediv__&#39;, &#39;__trunc__&#39;, &#39;__xor__&#39;, &#39;as_integer_ratio&#39;, &#39;bit_length&#39;, &#39;conjugate&#39;, &#39;denominator&#39;, &#39;from_bytes&#39;, &#39;imag&#39;, &#39;numerator&#39;, &#39;real&#39;, &#39;to_bytes&#39;] . 예상대로 int클래스의 인스턴스는 __iter__()가 없다. . - 위에서 정의한 L(list), df, ndr(ndarray) 는 모두 __iter__() 함수가 있다. 따라서 iterable한 오브젝트이다. . iterable한 오브젝트는 iterator로 만들 수 있는 특징이 있다. . iterable한 오브젝트를 어떻게 iterator로 만드는가? . df . 0 1 2 . 0 1 | 2 | 3 | . 1 3 | 4 | 5 | . dfiter1=df.__iter__() . dfiter2=iter(df) . dfiter1? . Type: generator String form: &lt;generator object RangeIndex.__iter__ at 0x0000028645753270&gt; Docstring: &lt;no docstring&gt; . - dfiter1은 generator라는 클래스에서 만들어진 인스턴스 오브젝트이다. . dir(dfiter1) . [&#39;__class__&#39;, &#39;__del__&#39;, &#39;__delattr__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__iter__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__name__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__next__&#39;, &#39;__qualname__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;close&#39;, &#39;gi_code&#39;, &#39;gi_frame&#39;, &#39;gi_running&#39;, &#39;gi_yieldfrom&#39;, &#39;send&#39;, &#39;throw&#39;] . dfiter1.__next__() . 1 . next 메소드? 카운트 느낌!, BUT 영구적인 것은 아니고 STOP하게 됨 . . – for 문의 작동원리 . for i in L: print(i) . (1) iter함수를 사용해서 L이라는 오브젝트를 iterator로 만든다. L이라는 오브젝트가 이터러블하기 때문에 가능 . (2) iterator에서 .__next__()함수를 호출하고 결과를 i에 저장한뒤에 for문 블락안에 있는 내용(들여쓰기 된 내용)을 실행한다. . (3) StopIteration 에러가 발생하면 for 문을 멈춘다. . 이런 원리로 for문이 돌아가는 듯! . . Liter=iter(L) . Liter.__next__() . [1, 2, 3] . 123나오고 345 나오고 STOP . ndriter=iter(ndr) . print(ndriter.__next__()) . [1 2 3] . range() . - for문의 정석은 아래와 같이 range()를 사용하는 것이다. . for i in range(5): print(i) . 0 1 2 3 4 . in 다음애는 iterable만 가능 . - range(5)의 정체는 그냥 iterable object이다. . a=range(5) . - 그래서 언제든지 iterator로 바꿀 수 있다. . aiter=iter(a) . aiter.__next__() . 4 . 0~4까지 출력 후 error 출력 . &#51060;&#53552;&#47112;&#51060;&#53552;&#51032; &#44060;&#45392;&#51008; &#46356;&#48260;&#44613;&#50640; &#51025;&#50857;&#44032;&#45733; . for i in zip([1,2,3],&#39;abc&#39;): print(i) . (1, &#39;a&#39;) (2, &#39;b&#39;) (3, &#39;c&#39;) . zip([1,2,3],&#39;abc&#39;) . &lt;zip at 0x28645783d80&gt; . 어차피 for i in ????: ????의 자리는 iterable object 자리이다. . z=zip([1,2,3],&#39;abc&#39;) . dir(z) . [&#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__iter__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__next__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;] . - __next__()함수가 있음 $ to$ z자체가 iterator였다. (iterable object 이면서) . z.__next__() . (2, &#39;b&#39;) . 첫번째, 두번째, 세번째 그리고 마지막엔 에러 . for i in ???: print(i) . - ??? 자리에 iterator 자체가와도 무방한 듯!!! . - 확인 . L=iter([1,2,3,4]) for i in L: print(i) . 1 2 3 4 . i . 4 .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/05/intro3.html",
            "relUrl": "/2022/01/05/intro3.html",
            "date": " • Jan 5, 2022"
        }
        
    
  
    
        ,"post16": {
            "title": "2022/01/05/WED",
            "content": "&#54632;&#49688;&#46020; OBJECT&#51060;&#45796; . def myadd(a,b): return a+b . myadd(1,2) . 3 . myadd? . Signature: myadd(a, b) Docstring: &lt;no docstring&gt; File: c: users ehfus appdata local temp ipykernel_16584 4154224718.py Type: function . - Type이 function . - myadd 는 function class의 instance이다. . - 결국 myadd 역시 하나의 오브젝트에 불과하다. . higher-order function . myadd의 입력 1,2는 int class의 인스턴스 오브젝트였음. . 즉 문법의 논리로 보면 함수의 입력에 들어갈 수 있는것은 오브젝트이면 된다. . 그런데 함수 자체도 오브젝트이다 $ to$ 함수도 함수의 입력으로 쓸 수 있다? . - 예제1 . def calc(function,a,b): return function(a,b) . calc(myadd,-3,3) . 0 . 이처럼 함수자체를 입력으로 받거나 출력으로 보내는 함수를 higher-order function이라고 한다. . - 예제2 . 미분: 아래의 함수 . $$f(x)=3x^2-2x+5$$ . 에서 $x=2$에의 접선의 기울기는 아래와 같이 대략적으로 구할 수 있다. . $$ frac{f(2+h)-f(2)}{h}, quad h=0.0000001$$ . $h$의 값을 더 0에 가깝게 만든다면 접선의 기울기의 정확도는 올라간다. . 미분에 익숙하다면 이론적으로 아래와 같이 $x=2$일때 접선의 기울기를 구할 수 있다. . $f&#39;(x)=6x-2$ | $f&#39;(2)=12-2=10$ | . 즉 $x=2$일때 이론적으로 구한 접선의 기울기값은 10이다. . 미분을 계산해주는 코드를 구현하자. . def f(x): return 3*x**2-2*x+5 . def derivative(fx,x): h=0.00000001 return (fx(x+h)-fx(x))/h . derivative(f,2) . 9.99999993922529 . - $g(x)=x^2$와 같은 함수를 미분하고 싶다면? . def g(x): return x**2 . derivative(g,0) . 1e-08 .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/05/intro3-1.html",
            "relUrl": "/2022/01/05/intro3-1.html",
            "date": " • Jan 5, 2022"
        }
        
    
  
    
        ,"post17": {
            "title": "2022/01/05/WED",
            "content": "maplotlib + seaborn . import matplotlib.pyplot as plt import numpy as np import seaborn as sns . x=[44,48,49,58,62,68,69,70,76,79] # 몸무게 y=[159,160,162,165,167,162,165,175,165,172] #키 g=&#39;F&#39;,&#39;F&#39;,&#39;F&#39;,&#39;F&#39;,&#39;F&#39;,&#39;M&#39;,&#39;M&#39;,&#39;M&#39;,&#39;M&#39;,&#39;M&#39; . plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x1decec2b6a0&gt;] . sns.scatterplot(x=x,y=y,hue=g) . &lt;AxesSubplot:&gt; . - 두 그림을 나란히 겹쳐 그릴수 있을까? . fig, (ax1,ax2) = plt.subplots(1,2) ax1.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x1decf4e8700&gt;] . sns.scatterplot(x=x,y=y,hue=g,ax=ax2) # ax=ax2 이 부분 추가 . &lt;AxesSubplot:&gt; . fig . fig.set_figwidth(8) . fig . ax1.set_title(&#39;matplotlib&#39;) ax2.set_title(&#39;seaborn&#39;) . Text(0.5, 1.0, &#39;seaborn&#39;) . fig . - 마치 matplotlib에 seaborn을 plugin하듯이 사용할 수 있다. . matplotlib vs seaborn . plt.plot([1,2,3],[3,4,5],&#39;x:r&#39;) . [&lt;matplotlib.lines.Line2D at 0x1decf720490&gt;] . &#50696;&#51228; . np.random.seed(43052) x=np.random.normal(size=1000,loc=2,scale=15) . - 이 자료가 정규분포를 따르는지 어떻게 체크할 수 있을까? . plt.hist(x) . (array([ 10., 24., 99., 176., 232., 222., 165., 53., 16., 3.]), array([-42.43984464, -33.38324282, -24.326641 , -15.27003917, -6.21343735, 2.84316447, 11.89976629, 20.95636811, 30.01296994, 39.06957176, 48.12617358]), &lt;BarContainer object of 10 artists&gt;) . - 종모양이므로 정규분포인듯 하다. . - 밀도추정곡선이 있었으면 좋겠다. (KDE로 추정) $ to$ seaborn을 활용하여 그려보자. . sns.histplot(x,kde=True) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . - 종모양인것 같다. . - 그렇다면 아래는 어떤가? . np.random.seed(43052) from scipy.stats import t . y=t.rvs(10,size=1000) # rvs? random varieties of given type . sns.histplot(y,kde=True) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . - 종모양이다..? . - 비교 . fig, (ax1,ax2) = plt.subplots(1,2) sns.histplot(x,kde=True,ax=ax1) sns.histplot(y,kde=True,ax=ax2) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . xx= (x-np.mean(x)) / np.std(x,ddof=1) yy= (y-np.mean(y)) / np.std(y,ddof=1) fig, (ax1,ax2) = plt.subplots(1,2) sns.histplot(xx,kde=True,ax=ax1) sns.histplot(yy,kde=True,ax=ax2) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . xx= (x-np.mean(x)) / np.std(x,ddof=1) yy= (y-np.mean(y)) / np.std(y,ddof=1) fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2) ax1.boxplot(xx) sns.histplot(xx,kde=True,ax=ax2) ax3.boxplot(yy) sns.histplot(yy,kde=True,ax=ax4) . &lt;AxesSubplot:ylabel=&#39;Count&#39;&gt; . fig.tight_layout() . fig . - 주의: 아래와 같이 해석하면 잘못된 해석이다. . $y$ 히스토그램을 그려보니 모양이 종모양이다. $ to$ $y$는 정규분포이다 | . - 관찰: boxplot을 그려보니 $y$의 꼬리가 정규분포보다 두꺼워 보인다. .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/05/intro2.html",
            "relUrl": "/2022/01/05/intro2.html",
            "date": " • Jan 5, 2022"
        }
        
    
  
    
        ,"post18": {
            "title": "2022/01/04/TUE",
            "content": "&#46972;&#51064;&#54540;&#46991; . import matplotlib.pyplot as plt x=[1,2,3,4] y=[1,2,4,3] plt.plot(x,y,&#39;:ok&#39;) . [&lt;matplotlib.lines.Line2D at 0x20657010eb0&gt;] . (1) &#44217;&#52432;&#44536;&#47532;&#44592; . import numpy as np x=np.arange(-5,5,0.1) y=2*x+np.random.normal(loc=0,scale=1,size=100) plt.plot(x,y,&#39;.:b&#39;) plt.plot(x,2*x,&#39;--r&#39;) . [&lt;matplotlib.lines.Line2D at 0x206585533d0&gt;] . (2) &#46384;&#47196;&#44536;&#47532;&#44592; - subplots . x=[1,2,3,4] y=[1,2,4,3] _ , s = plt.subplots(2,2) # subplots의 리턴값=(fig,axs) s[0,0].plot(x,y,&#39;o:r&#39;) s[0,1].plot(x,y,&#39;Xb&#39;) s[1,0].plot(x,y,&#39;xm&#39;) s[1,1].plot(x,y,&#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x20658669190&gt;] . Anscombe&#39;s quartet . x = [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5] y1 = [8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68] y2 = [9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74] y3 = [7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73] x4 = [8, 8, 8, 8, 8, 8, 8, 19, 8, 8, 8] y4 = [6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89] . _,s = plt.subplots(2,2) s[0,0].plot(x,y1,&#39;o&#39;) s[0,1].plot(x,y2,&#39;.&#39;) s[1,0].plot(x,y3,&#39;x&#39;) s[1,1].plot(x4,y4,&#39;X&#39;) . [&lt;matplotlib.lines.Line2D at 0x2065890b520&gt;] . 상관계수 | . - -1 ~ 1 사이의 값 . - 완전한 직선 = 상관계수가 1 또는 -1 . - 상관계수가 1에 가까우면 양의 상관관계에 있다고 말하고 -1에 가까우면 음의 상관관계 . - 자료의 모양이 직선모양에 가까우면 상관계수가 큰것이 맞나? . $x,y$ 값이 모두 큰 하나의 관측치가 상관계수값을 키울 수 있지 않나? | . - 상관계수가 좋은것은 맞나? (=상관계수는 두 변수의 관계를 설명하기에 충분히 적절한 통계량인가?) . n=len(x) xtilde = (x-np.mean(x)) / (np.std(x)*np.sqrt(n)) y1tilde = (y1-np.mean(y1)) / (np.std(y1)*np.sqrt(n)) . sum(xtilde*y1tilde) . 0.81642051634484 . np.corrcoef(x4,y4) . array([[1. , 0.81652144], [0.81652144, 1. ]]) . np.corrcoef([x,y1,y2,y3]) . array([[1. , 0.81642052, 0.81623651, 0.81628674], [0.81642052, 1. , 0.7500054 , 0.46871668], [0.81623651, 0.7500054 , 1. , 0.58791933], [0.81628674, 0.46871668, 0.58791933, 1. ]]) . - 위의 4개의 그림에 대한 상관계수는 모두 같다. (0.816) . - 상관계수는 두 변수의 관계를 설명하기에 부적절하다. . 상관계수는 1번그림과 같이 두 변수가 선형관계에 있을때 그 정도를 나타내는 통계량일뿐이다. | 선형관계가 아닌것처럼 보이는 자료에서는 상관계수를 계산할수는 있겠으나 의미가 없다. | .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/04/intro2.html",
            "relUrl": "/2022/01/04/intro2.html",
            "date": " • Jan 4, 2022"
        }
        
    
  
    
        ,"post19": {
            "title": "2022/01/03/MON",
            "content": "matplotlib &#49324;&#50857;&#48277; . &#50696;&#51228; 1: &#50529;&#49884;&#51592;&#47484; &#51060;&#50857;&#54620; &#54540;&#46991; . - 구조 : axis $ subset$ axes $ subset$ figure . import matplotlib.pyplot as plt . fig = plt.figure() # 도화지를 준비한다. . &lt;Figure size 432x288 with 0 Axes&gt; . fig # 현재 도화지상태를 체크 . &lt;Figure size 432x288 with 0 Axes&gt; . - 그림객체를 출력해봐야 아무것도 나오지 않는다. (아무것도 없으니까) . fig.add_axes() # fig에 액시즈를 추가 fig.axes # 현재 fig에 있는 액시즈 정보 . fig.axes # 현재 fig에 있는 액시즈 정보 . [] . fig.add_axes([0,0,1,1]) . &lt;Axes:&gt; . 도화지안에 (0,0) 위치에 길이가 (1,1) 인 네모틀을 만듦 . fig.axes # 현재 네모틀 상태를 체크 -&gt; 네모틀이 하나 있음. . [&lt;Axes:&gt;] . fig # 현재 도화지 상태 체크 -&gt; 도화지에 (하나의) 네모틀이 잘 들어가 있음 . axs1=fig.axes[0] ## 첫번째 액시즈 . axs1.plot([1,2,3],&#39;or:&#39;) # 첫번째 액시즈에 접근하여 그림을 그림 . [&lt;matplotlib.lines.Line2D at 0x19a41260d00&gt;] . fig #현재 도화지 상태 체크 --&gt; 그림이 잘 그려짐 . &#50696;&#51228;2: &#50529;&#49884;&#51592;&#47484; &#51060;&#50857;&#54620; &#49436;&#48652;&#54540;&#46991; (&#48169;&#48277;1) . fig # 현재 도화지 출력 . - 액시즈추가 . fig.add_axes([1,0,1,1]) # 1,0 위치에 길이 1,1 짜리 틀 추가 . &lt;Axes:&gt; . fig.axes . [&lt;Axes:&gt;, &lt;Axes:&gt;] . fig . axs2=fig.axes[1] ## 두번째 액시즈 . - 두번째 액시즈에 그림그림 . axs2.plot([1,2,3],&#39;ok&#39;) ## 두번째 액시즈에 그림그림 . [&lt;matplotlib.lines.Line2D at 0x19a413bdfd0&gt;] . fig ## 현재 도화지 체크 . - 첫번째 액시즈에 그림추가 . axs1.plot([1,2,3],&#39;--&#39;) ### 액시즈1에 점선추가 . [&lt;matplotlib.lines.Line2D at 0x19a413bd460&gt;] . fig ## 현재 도화지 체크 . &#50696;&#51228;3: &#50529;&#49884;&#51592;&#47484; &#51060;&#50857;&#54616;&#50668; &#49436;&#48652;&#54540;&#46991; (&#48169;&#48277;2) . fig = plt.figure() # 새로운 도화지 . &lt;Figure size 432x288 with 0 Axes&gt; . fig.axes . [] . fig.subplots(1,2) # default는 1,1 . array([&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;], dtype=object) . fig.axes . [&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;] . ax1,ax2 = fig.axes . ax1.plot([1,2,3],&#39;or&#39;) ax2.plot([1,2,3],&#39;ob&#39;) . [&lt;matplotlib.lines.Line2D at 0x19a416ba820&gt;] . fig . fig.set_figwidth(12) # 도화지 늘려보자 . fig . ax1.plot([1,2,3],&#39;--&#39;) . [&lt;matplotlib.lines.Line2D at 0x19a413341c0&gt;] . fig . &#50696;&#51228;4: &#50529;&#49884;&#51592;&#47484; &#51060;&#50857;&#54616;&#50668; 2$ times$2 &#49436;&#48652;&#54540;&#46991; &#44536;&#47532;&#44592; . fig = plt.figure() fig.axes . [] . &lt;Figure size 432x288 with 0 Axes&gt; . fig.subplots(2,2) fig.axes . [&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;] . ax1,ax2,ax3,ax4=fig.axes . ax1.plot([1,2,3],&#39;ob&#39;) ax2.plot([1,2,3],&#39;or&#39;) ax3.plot([1,2,3],&#39;ok&#39;) ax4.plot([1,2,3],&#39;oy&#39;) . [&lt;matplotlib.lines.Line2D at 0x19a417ffd60&gt;] . fig . &#50696;&#51228;5: plt.subplots()&#47484; &#51060;&#50857;&#54616;&#50668; 2$ times$2 &#49436;&#48652;&#54540;&#46991; . x=[1,2,3,4] y=[1,2,4,3] _, axs = plt.subplots(2,2) axs[0,0].plot(x,y,&#39;o:r&#39;) axs[0,1].plot(x,y,&#39;Xb&#39;) axs[1,0].plot(x,y,&#39;xm&#39;) axs[1,1].plot(x,y,&#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x19a41aab370&gt;] . 주의 . x=[1,2,3,4] y=[1,2,4,3] . _, axs = plt.subplots(2,2) . axs[0,0].plot(x,y,&#39;o:r&#39;) axs[0,1].plot(x,y,&#39;Xb&#39;) axs[1,0].plot(x,y,&#39;xm&#39;) axs[1,1].plot(x,y,&#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x19a43184370&gt;] . _ . &#50696;&#51228;6: plt.subplots()&#47484; 2$ times$2 subplot &#44536;&#47532;&#44592; - &#50529;&#49884;&#51592;&#47484; &#44033;&#44033; &#48320;&#49688;&#47749;&#51004;&#47196; &#51200;&#51109; . x=[1,2,3,4] y=[1,2,4,3] fig, axs = plt.subplots(2,2) . axs # 중첩 리스트 형태로 들어가있음 . array([[&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;], [&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;]], dtype=object) . . 중첩리스트 형태라 . ax1,ax2,ax3,ax4 =axs . 이렇게하면 error . . (ax1,ax2), (ax3,ax4) = axs . ax1.plot(x,y,&#39;o:r&#39;) ax2.plot(x,y,&#39;Xb&#39;) ax3.plot(x,y,&#39;xm&#39;) ax4.plot(x,y,&#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x23b4236a880&gt;] . fig . &#50696;&#51228;7: plt.subplots()&#47484; &#51060;&#50857;&#54616;&#50668; 2$ times$2 &#49436;&#48652;&#54540;&#46991; &#44536;&#47532;&#44592; - fig.axes&#50640;&#49436; &#51217;&#44540; . fig, _ = plt.subplots(2,2) . fig.axes . [&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;] . ax1, ax2, ax3, ax4= fig.axes . ax1.plot(x,y,&#39;o:r&#39;) ax2.plot(x,y,&#39;Xb&#39;) ax3.plot(x,y,&#39;xm&#39;) ax4.plot(x,y,&#39;.--k&#39;) . [&lt;matplotlib.lines.Line2D at 0x19a435783d0&gt;] . fig . title &#49444;&#51221; . &#50696;&#51228;1: plt.plot() . x=[1,2,3] y=[1,2,2] . plt.plot(x,y,&#39;o:k&#39;) plt.title(&#39;fuck&#39;) . Text(0.5, 1.0, &#39;fuck&#39;) . &#50696;&#51228;2: &#50529;&#49884;&#51592;&#47484; &#51060;&#50857; . 기본적으로 1개 설정됨 . fig = plt.figure() fig.subplots() . &lt;AxesSubplot:&gt; . ax1=fig.axes[0] . ax1.set_title(&#39;title&#39;) . Text(0.5, 1.0, &#39;title&#39;) . fig . &#50696;&#51228;3: subplot&#50640;&#49436; &#44033;&#44033;&#51032; &#51228;&#47785;&#49444;&#51221; . fig, ax = plt.subplots(2,2) . axs . array([[&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;], [&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;]], dtype=object) . (ax1,ax2),(ax3,ax4) =ax . ax1.set_title(&#39;title1&#39;) ax2.set_title(&#39;title2&#39;) ax3.set_title(&#39;title3&#39;) ax4.set_title(&#39;title4&#39;) . Text(0.5, 1.0, &#39;title4&#39;) . fig . fig.tight_layout() # 암기 . fig . &#50696;&#51228;4 : &#50529;&#49884;&#51592;&#51032; &#51228;&#47785; + Figure&#51228;&#47785; . 슈퍼타이틀=도화지 전체의 제목 명명 . fig.suptitle(&#39;sup title&#39;) . Text(0.5, 0.98, &#39;sup title&#39;) . fig . fig.tight_layout() . fig . 그냥 x=[1,2,3]만 입력해주면 (1,1)(2,2)(3,3)으로 값 설정됨 . x=[1,2,3] y=[4,5,6] . plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x19a43700430&gt;] . 축 범위 재조정 中 . plt.plot(x,y,&#39;o&#39;) plt.xlim(-1,5) plt.ylim(3,7) . (3.0, 7.0) . &#50696;&#51228;2 . fig = plt.figure() fig.subplots() . &lt;AxesSubplot:&gt; . ax1=fig.axes[0] . import numpy as np . ax1.plot(np.random.normal(size=100),&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x19a437edf40&gt;] . fig . ax1.set_xlim(-10,110) ax1.set_ylim(-5,5) . (-5.0, 5.0) . fig . &#50696;&#51228;1 . np.linspace(-1,1,100,endpoint=True) . = start는 배열 시작값, stop은 배열의 끝 값, num은 start와 stop사이를 몇 개의 일정한 간격으로 요소를 만들 것인지, 만일 num을 생략하면 디폴트로 50개의 수열을 만들며, 마지막 endpoint가 의미하는 것은 stop으로 주어진 값을 포함시킬 것인지 아닌지를 선택하는 옵션 . np.random.seed(43052) x1=np.linspace(-1,1,100,endpoint=True) y1=x1**2+np.random.normal(scale=0.1,size=100) . axs1=plt.plot(x1,y1,&#39;o:m&#39;) axs1=plt.title(&#39;y=x**2&#39;) . np.corrcoef(x1,y1) . array([[1. , 0.00688718], [0.00688718, 1. ]]) . 상관계수의 값이 0에 가까운 것은 두 변수의 직선관계가 약한것을 의미하는 것, 두 변수 사이에 아무런 함수관계가 없다는 것을 의미하는 것은 아니다. | . &#50696;&#51228;2 . - 아래와 같은 자료를 고려하자. . np.random.seed(43052) x2=np.random.uniform(low=-1,high=1,size=100000) y2=np.random.uniform(low=-1,high=1,size=100000) . axs2=plt.plot(x2,y2,&#39;.&#39;) axs2=plt.title(&#39;rect&#39;) . np.corrcoef(x2,y2) . array([[1. , 0.00521001], [0.00521001, 1. ]]) . &#50696;&#51228;3 . np.random.seed(43052) _x3=np.random.uniform(low=-1,high=1,size=100000) _y3=np.random.uniform(low=-1,high=1,size=100000) . plt.plot(_x3,_y3,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x19a44dae280&gt;] . radius = _x3**2+_y3**2 . x3=_x3[radius&lt;1] y3=_y3[radius&lt;1] plt.plot(_x3,_y3,&#39;.&#39;) plt.plot(x3,y3,&#39;.&#39;) . [&lt;matplotlib.lines.Line2D at 0x19a44e281f0&gt;] . axs3=plt.plot(x3,y3,&#39;.&#39;) axs3=plt.title(&#39;circ&#39;) . np.corrcoef(x3,y3) . array([[ 1. , -0.00362687], [-0.00362687, 1. ]]) .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/03/intro2.html",
            "relUrl": "/2022/01/03/intro2.html",
            "date": " • Jan 3, 2022"
        }
        
    
  
    
        ,"post20": {
            "title": "2022/01/02/SUN",
            "content": "Class &#44256;&#44553; . - 오브젝트 . 클래스 오브젝트 | 인스턴스 오브젝트 | . - 클래스 (=클래스 오브젝트) . - 인스턴스 (=인스턴스 오브젝트) . &#53364;&#47000;&#49828; &#49549;&#49457; vs &#51064;&#49828;&#53556;&#49828; &#49549;&#49457; . &#50696;&#51228;1 . class Testclass1: x=0 y=0 def my_print(self): self.x += 1 Testclass1.y +=1 print(&quot;현재 인스턴스에서 %s 회 출력&quot; % self.x) print(&quot;전체 인스턴스에서 총 %s 회 출력&quot; % self.y) . f=Testclass1 . a=Testclass1() . b=f() . a.my_print() . 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 1 회 출력 . b.my_print() . 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 2 회 출력 . b.my_print() . 현재 인스턴스에서 2 회 출력 전체 인스턴스에서 총 3 회 출력 . a.my_print() . 현재 인스턴스에서 2 회 출력 전체 인스턴스에서 총 4 회 출력 . a.my_print() . 현재 인스턴스에서 3 회 출력 전체 인스턴스에서 총 5 회 출력 . - 신기한점: 각 인스턴스에서 instance.my_print()를 실행한 횟수를 서로 공유하는 듯 하다. . &#48516;&#49437; . - 코드를 시점별로 분석해보자. . - 분석을 위해서 커널을 재시작한다. . [&#49884;&#51216;1] : Testclass1&#47484; &#49440;&#50616;&#54616;&#45716; &#49884;&#51216; . class Testclass1: x=0 y=0 def my_print(self): self.x += 1 Testclass1.y +=1 print(&quot;현재 인스턴스에서 %s 회 출력&quot; % self.x) print(&quot;전체 인스턴스에서 총 %s 회 출력&quot; % self.y) . dir(Testclass1) . [&#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;my_print&#39;, &#39;x&#39;, &#39;y&#39;] . # dir(b) # 이 둘은 아직 존재 X . – 이 시점에는 Testclass1만이 존재한다. Testclass1를 바로 클래스 오브젝트라고 부름. . Testclass1.x . 0 . Testclass1.y . 0 . – 현재시점에서는 클래스 오브젝트의 수 1개, 인스턴스 오브젝트의 수 0개, 따라서 총 오브젝트 수는 1개임. . [&#49884;&#51216;2] &#53364;&#47000;&#49828;&#50640; &#48324;&#52845;&#51012; &#51648;&#51221;&#54616;&#45716; &#49884;&#51216; . f=Testclass1 . f.x . 0 . f.y . 0 . Testclass1.x . 0 . Testclass1.y . 0 . – 이 시점에서 클래스 오브젝트는 2개가 있는 것 처럼 보인다. . - 그렇다면 이 2개의 클래스 오브젝트는 컴퓨터의 어딘가에 저장이 되어 있을 것이다. . - 구체적으로는 메모리에 저장되어있을것. . - 2개의 클래스오브젝트는 서로 다른 메모리 공간에 저장되어 있을것이다. . - 진짜인가? 확인해보자. id()는 오브젝트(클래스 오브젝트, 인스턴스 오브젝트)가 저장된 메모리 주소를 확인하는 명령어이다. . id(f) . 2274923570048 . – f라는 오브젝트는 93967322676384 메모리에 저장되어 있다. . id(Testclass1) . 2274923570048 . - 어? 그런데 Testclass1의 오브젝트 역시 93967322676384 메모리에 저장되어 있다. . - 추론: 사실 93967322676384라는 메모리공간에 저장된 어떠한 것은 동일한데, 그것을 어떤사람은 Testclass1 이라고 부르고 어떤사람은 f라고 부른다. . - 이는 마치 별명이랑 비슷하다. 나라는 오브젝트를 어떤사람은 최규빈이라고 부르고, 어떤사람은 팬더라고 부른다. 부르는 이름이 2개라고 해서 나라는 오브젝트가 2개가 있는것은 아니다. . - 결국 이 시점에서 클래스 오브젝트의 수는 여전히 1개라고 볼 수 있다. (인스턴스 오브젝트의 수는 0개) . [&#49884;&#51216;3] : &#53364;&#47000;&#49828; &#50724;&#48652;&#51229;&#53944;&#47196;&#48512;&#53552; &#51064;&#49828;&#53556;&#49828; &#50724;&#48652;&#51229;&#53944;&#47484; &#47564;&#46300;&#45716; &#49884;&#51216; . a=Testclass1() # 인스턴스 object 만듦 b=f() # 인스턴스 object 만듦 . id(Testclass1),id(f),id(a),id(b) . (2274923570048, 2274923570048, 2274938585920, 2274938586544) . – 이 순간에는 클래스 오브젝트 1개, 인스턴스 오브젝트 2개 존재한다. 즉 총 3개의 오브젝트가 존재한다. . - 메모리주소 93967322676384 에 존재하는 오브젝트는 클래스 오브젝트이며 Testclass1 또는 f 라고 불린다. . - 메모리주소 139694857660688 에 존재하는 오브젝트는 인스턴스 오브젝트이며 a라고 불린다. . - 메모리주소 139694848860656 에 존재하는 오브젝트는 인스턴스 오브젝트이며 b라고 불린다. . . Testclass1.x, Testclass1.y . (0, 0) . f.x,f.y . (0, 0) . . a.x,a.y . (0, 0) . b.x,b.y . (0, 0) . [&#49884;&#51216;4] . a.my_print() . 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 1 회 출력 . (f.x,f.y),(a.x,a.y),(b.x,b.y) . ((0, 1), (1, 1), (0, 1)) . - 특징 . a.my_print()를 실행하면 a.x 의 값이 1이 증가한다. | a.my_print()를 실행하면 f.y, a.y, b.y 의 값이 동시에 1이 증가한다. (공유가 되는 느낌) | . [&#49884;&#51216;5] . b.my_print() . 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 2 회 출력 . (f.x,f.y),(a.x,a.y),(b.x,b.y) . ((0, 2), (1, 2), (1, 2)) . [&#49884;&#51216;6] . b.my_print() . 현재 인스턴스에서 2 회 출력 전체 인스턴스에서 총 3 회 출력 . (f.x,f.y),(a.x,a.y),(b.x,b.y) . ((0, 3), (1, 3), (2, 3)) . [&#49884;&#51216;7] . a.my_print() . 현재 인스턴스에서 2 회 출력 전체 인스턴스에서 총 4 회 출력 . (f.x,f.y),(a.x,a.y),(b.x,b.y) . ((0, 4), (2, 4), (2, 4)) . [&#49884;&#51216;8] . a.my_print() . 현재 인스턴스에서 3 회 출력 전체 인스턴스에서 총 5 회 출력 . (f.x,f.y),(a.x,a.y),(b.x,b.y) . ((0, 5), (3, 5), (2, 5)) . &#50696;&#51228;2 . - 아래처럼 코드를 바꿔도 잘 동작할것 같다. . class Testclass2: def __init__(self): # 클래스가 생성되는 시점에서는 실행되지 않고, 인스턴스가 생성되는 시점에서 실행될 것 self.x=0 self.y=0 def my_print(self): self.x += 1 Testclass2.y +=1 print(&quot;현재 인스턴스에서 %s 회 출력&quot; % self.x) print(&quot;전체 인스턴스에서 총 %s 회 출력&quot; % self.y) . c=Testclass2() # 인스턴스 object 생성 . . – 왜 에러가 나는가? . dir(Testclass2) . [&#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;my_print&#39;] . dir(Testclass1) . [&#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;my_print&#39;, &#39;x&#39;, &#39;y&#39;] . - 관찰1: Testclass2에서는 Testclass1과는 다르게 x,y가 없다. . dir(c) . [&#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;, &#39;my_print&#39;, &#39;x&#39;, &#39;y&#39;] . – 관찰2: 그런데 c라는 인스턴스 오브젝트에서는 x,y가 있다. . - 추론: __init__함수는 클래스 오브젝트가 만들어지는 시점에서는 실행되지 않고, 인스텐스 오브젝트가 만들어지는 시점에 실행된다. . - 결국 __init__ 함수의 역할은 클래스 오브젝트에서 인스턴스 오브젝트를 만든후에 초기화를 위해서 실행하는 어떠한 일련의 명령들을 묶어놓은 것에 불과하다. . – 즉 위의 코드는 굳이 따지면 아래를 실행한 것과 동일하다. . class Testclass2: # def __init__(self): # self.x=0 # self.y=0 def my_print(self): self.x += 1 Testclass2.y +=1 print(&quot;현재 인스턴스에서 %s 회 출력&quot; % self.x) print(&quot;전체 인스턴스에서 총 %s 회 출력&quot; % self.y) . c=Testclass2() . c.x=0 c.y=0 . - 이 상황에서 . c.my_print() . 를 실행하면 . c.x += 1 Testclass2.y +=1 print(&quot;현재 인스턴스에서 %s 회 출력&quot; % c.x) print(&quot;전체 인스턴스에서 총 %s 회 출력&quot; % c.y) . 이 실행되는데, 이때 Testclass2.y 이 정의되어 있지 않으므로 . Testclass2.y +=1 . 에서 에러가 난다. . &#50696;&#51228; 3 . - 그렇다면 아래와 같이 수정하면 어떨까? . class Testclass3: def __init__(self): self.x=0 Testclass3.y=0 def my_print(self): self.x += 1 Testclass3.y +=1 print(&quot;현재 인스턴스에서 %s 회 출력&quot; % self.x) print(&quot;전체 인스턴스에서 총 %s 회 출력&quot; % self.y) . # def __init__(self): # 클래스가 생성되는 시점에서는 실행되지 않고, 인스턴스가 생성되는 시점에서 실행될 것 # self.x=0 # self.y=0 # def my_print(self): # self.x += 1 # Testclass2.y +=1 # print(&quot;현재 인스턴스에서 %s 회 출력&quot; % self.x) # print(&quot;전체 인스턴스에서 총 %s 회 출력&quot; % self.y) . a=Testclass3() b=Testclass3() . a.my_print() . 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 1 회 출력 . b.my_print() . 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 2 회 출력 . a.my_print() . 현재 인스턴스에서 2 회 출력 전체 인스턴스에서 총 3 회 출력 . a.my_print() . 현재 인스턴스에서 3 회 출력 전체 인스턴스에서 총 4 회 출력 . b.my_print() . 현재 인스턴스에서 2 회 출력 전체 인스턴스에서 총 5 회 출력 . b.my_print() . 현재 인스턴스에서 3 회 출력 전체 인스턴스에서 총 6 회 출력 . – Testclass1과 동일한 기능이 수행되는것 같다. . - 그런데 조금만 생각해보면 엉터리라는 것을 알 수 있다. 아래의 코드를 관찰하여보자. . class Testclass3: def __init__(self): self.x=0 Testclass3.y=0 def my_print(self): self.x += 1 Testclass3.y +=1 print(&quot;현재 인스턴스에서 %s 회 출력&quot; % self.x) print(&quot;전체 인스턴스에서 총 %s 회 출력&quot; % self.y) a=Testclass3() a.my_print() a.my_print() b=Testclass3() # 초기화 b.my_print() . 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 1 회 출력 현재 인스턴스에서 2 회 출력 전체 인스턴스에서 총 2 회 출력 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 1 회 출력 . - Testclass3는 인스턴스를 생성할때마다 y=0이 설정된다. 그래서 . b=Testclass3() . 이 시점에서 의도하지 않게 &#39;전체 인스턴스에서 출력된 횟수&#39;를 의미하는 y가 초기화되었다. . - 코드는 엉터리이지만, Testclass3은 의외로 분석할만한 가치가 있다. 특히 위의 실행결과를 시점별로 Testclass1과 비교해보면 재미있다. . - Testclass1 . ### Testclass1 ## 시점1: 클래스 오브젝트 생성 class Testclass1: x=0 y=0 def my_print(self): self.x += 1 Testclass1.y +=1 print(&quot;현재 인스턴스에서 %s 회 출력&quot; % self.x) print(&quot;전체 인스턴스에서 총 %s 회 출력&quot; % self.y) ## 시점2: 인스턴스 오브젝트 a를 생성 a=Testclass1() ## 시점3: a에서 메소드 실행 a.my_print() ## 시점4: a에서 메소드를 한번 더 실행 a.my_print() ## 시점5: 인스턴스 오브젝트 b를 생성 b=Testclass1() ## 시점6: b에서 메소드를 실행 b.my_print() . 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 1 회 출력 현재 인스턴스에서 2 회 출력 전체 인스턴스에서 총 2 회 출력 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 3 회 출력 . 시점1 시점2 시점3 시점4 시점5 시점6 . Testclass1.x | 0 | 0 | 0 | 0 | 0 | 0 | . Testclass1.y | 0 | 0 | 1 | 2 | 2 | 3 | . a.x | 값없음 | 0 | 1 | 2 | 2 | 2 | . a.y | 값없음 | 0 | 1 | 2 | 2 | 3 | . b.x | 값없음 | 값없음 | 값없음 | 값없음 | 0 | 1 | . b.y | 값없음 | 값없음 | 값없음 | 값없음 | 2 | 3 | . – Testclass3 . #### Testclass3 ## 시점1: 클래스 오브젝트 생성 class Testclass3: def __init__(self): self.x=0 Testclass3.y=0 def my_print(self): self.x += 1 Testclass3.y +=1 print(&quot;현재 인스턴스에서 %s 회 출력&quot; % self.x) print(&quot;전체 인스턴스에서 총 %s 회 출력&quot; % self.y) ## 시점2: 인스턴스 오브젝트 a를 생성 a=Testclass3() ## 시점3: a에서 메소드 실행 a.my_print() ## 시점4: a에서 메소드를 한번 더 실행 a.my_print() ## 시점5: 인스턴스 오브젝트 b를 생성 b=Testclass3() ## 시점6: b에서 메소드를 실행 b.my_print() . 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 1 회 출력 현재 인스턴스에서 2 회 출력 전체 인스턴스에서 총 2 회 출력 현재 인스턴스에서 1 회 출력 전체 인스턴스에서 총 1 회 출력 . 시점1 시점2 시점3 시점4 시점5 시점6 . Testclass3.x | 값없음 | 값없음 | 값없음 | 값없음 | 값없음 | 값없음 | . Testclass3.y | 값없음 | 0 | 1 | 2 | 0 | 1 | . a.x | 값없음 | 0 | 1 | 2 | 2 | 2 | . a.y | 값없음 | 0 | 1 | 2 | 0 | 1 | . b.x | 값없음 | 값없음 | 값없음 | 값없음 | 0 | 1 | . b.y | 값없음 | 값없음 | 값없음 | 값없음 | 0 | 1 | . – Testclass3.y가 업데이트 되면 a.y, b.y도 자동으로 업데이트 된다. . &#45348;&#51076;&#49828;&#54168;&#51060;&#49828; . &#50696;&#51228;1 . class Testclass1: x=0 . Testclass1.x . 0 . a=Testclass1() # 인스턴스 . a.x . 0 . – Testclass1.x를 수정하면 a.x가 강제로 수정된다. . Testclass1.x=100 . a.x . 100 . - a.x를 수정한다고 하여 Testclass1.x가 강제로 수정되는 것은 아님 . a.x=200 . Testclass1.x . 100 . a.x . 200 . - 이건 왜이러지? . Testclass1.x=300 . a.x . 200 . - 아래의 상황과 비슷하다. . x=39 def nextyear(): y=x+1 print(x,y) nextyear() . 39 40 . x . 39 . # x=39 # def nextyear(): # y=x+1 # print(x,y) # x=0 # nextyear() . - [code2]와 [code1]의 차이점은 x=0이라는 코드가 추가로 포함되었는지 유무다. . - code1에서는 x는 global variable, code2에서는 x가 local variable 이라서 생기는 문제점이다. . x=39 def nextyear(): x=0 y=x+1 print(x,y) nextyear() . 0 1 . x . 39 . – 다시 우리의 예제로 돌아오자. . ### 시점1 class Testclass1: x=0 ### 시점2 a=Testclass1() ### 시점3 Testclass1.x=100 ### 시점4 a.x=200 `이 순간 a.x의 속성이 instance로 변함` ### 시점5 Testclass1.x=300 . 시점1 시점2 시점3 시점4 시점5 . Testclass1.x | 0 | 0 | 100 | 100 | 300 | . a.x | 값없음 | 0 | 100 | 200 | 200 | . a.x의 속성 | - | class | class | instance | instance | . – a.x가 클래스로부터 물려받은 속성인지 (그래서 클래스와 연결되어있는지) 아니면 instance가 독자적으로 가지고 있는 속성인지 어떻게 알 수 있을까? . class Testclass1: x=0 print(&#39;시점1&#39;,Testclass1.x) ### 시점2 a=Testclass1() print(&#39;시점2&#39;,Testclass1.x,a.x,a.__dict__) ### 시점3 Testclass1.x=100 print(&#39;시점3&#39;,Testclass1.x,a.x,a.__dict__) ### 시점4 a.x=200 print(&#39;시점4&#39;,Testclass1.x,a.x,a.__dict__) # 이젠 독자성을 지님 ### 시점5 Testclass1.x=300 print(&#39;시점5&#39;,Testclass1.x,a.x,a.__dict__) . 시점1 0 시점2 0 0 {} 시점3 100 100 {} 시점4 100 200 {&#39;x&#39;: 200} 시점5 300 200 {&#39;x&#39;: 200} . 참고 : _dict__ 용도? 클래스 객체의 속성 정보를 확인하기 위해 사용. 객체가 가진 여러가지 속성들을 딕셔너리 형태로 편하게 확인할 수 있다. . &#50696;&#51228;2 . x=11 ## 전역변수 ... A def f(): x=22 ## 함수 f안에 설정된 지역변수 print(x) ## 전역에 x=11 있지만 함수안에 x=22가 있으므로 x=22를 사용. --&gt; 22출력됨 def g(): print(x) ## 함수 g안에 x를 찾아봤는데 없음 --&gt; 전역에서 x를 찾음 --&gt; x=11 --&gt; 11출력함. class Testclass2: x=33 ## 클래스 변수 ... B def m1(self): x=44 ## 메소드 변수 ... C def m2(self): self.x=44 ## 인스턴스 변수 ... D . - 결과를 관찰하고 해석해보자. . print(x) . 11 . . Note: 전역변수 출력 . f() . 22 . . Note: $f$ 에서 설정된 지역변수 22가 출력됨 . x . 11 . . Note: $f$ 내의 지역변수를 사용하여도 전역변수는 변하지 않음. (함수내부에서 선언된 x=22는 함수외부에 영향을 주지못함) . g() . 11 . . Note: g에서 설정된 지역변수가 따로 없으므로 전역변수 출력 . x,Testclass2.x . (11, 33) . . Note: 전역변수 x와 클래스오브젝트에 설정된 변수 x . a=Testclass2() (x,Testclass2.x,a.x),a.__dict__ . ((11, 33, 33), {}) . . Note: 전역변수, 클래스 오브젝트내의 변수, 인스턴스내의 변수(a.__dict__의 결과로 보아 인스턴스내의 변수는 클래스 오브젝트내의 변수를 빌려쓰고 있다. ). . Testclass2.x=200 (x,Testclass2.x,a.x),a.__dict__ . ((11, 200, 200), {}) . . Note: 클래스오브젝트에서 변수를 고치면 인스턴스에 영향을 미침, 아직 인스턴스가 독자성을 갖지 않음 . a.m1() (x,Testclass2.x,a.x),a.__dict__ . ((11, 200, 200), {}) . . Note: 메소드 m1내에서 선언된 x=44라는 선언은 아무것도 변화시킬수 없음. . a.m2() (x,Testclass2.x,a.x),a.__dict__ # 독자성을 갖는 것 . ((11, 200, 44), {&#39;x&#39;: 44}) . . Note: 메소드 m2에 있는 self.x는 결국 a.x라는 의미이고, 이 선언은 클래스오브젝트 내의 변수와 독립적으로 인스턴스오브젝트 내에서 통용되는 변수를 선언하는 것임. 이 선언의 결과는 a.__dict__의 출력결과에서도 확인가능. . Testclass2.x=300 (x,Testclass2.x,a.x),a.__dict__ . ((11, 300, 44), {&#39;x&#39;: 44}) . . Note: 이제는 a.x와 Testclass2.x 는 분리된 상태이므로, Testclass2.x의 값을 바꾸어도 a.x에는 값의 변화가 없음. . 전역변수(A), 클래스 변수(B), 메소드 변수(C), 인스턴스 변수(D) . A&gt;B&gt;D&gt;C . &#50672;&#49328;&#51088; &#50724;&#48260;&#47196;&#46377; . - 아래의 코드를 관찰하자. . 1+1 . 2 . - 생각해보니까 1은 int class 에서 생성된 인스턴스이다. . - 코드를 관찰하니 instance와 instance를 +라는 연산이 연결하는 형태임. . class Student: def __init__(self,age=20.0,semester=1): self.age=age self.semester=semester def __add__(self,val): # val==0: 휴학 # val==1: 등록 if val==0: self.age=self.age +0.5 elif val==1: self.age=self.age+0.5 self.semester=self.semester+1 return self def __repr__(self): return &#39;나이: %s n학기: %s&#39; % (self.age,self.semester) . guebin=Student() . guebin.age . 20.0 . guebin.semester . 1 . guebin . 나이: 20.0 학기: 1 . guebin+1 . 나이: 20.5 학기: 2 . guebin+0 . 나이: 21.0 학기: 2 . guebin+0+0+0+0+1+0+1 . 나이: 24.5 학기: 4 . - 연산자 오버로드 핵심아이디어 . 클래스가 일반적인 파이썬 연산을 재정의하는 것, 즉 가로채는 것이라고 생각해도 됨 | 여기에서 연산은 단순히 덧셈, 뺄셈을 의미하는게 아니라, print(), +, [0](인덱싱) 와 같은 파이썬 내장문법을 모두 포괄하는 개념이라 이해하는 것이 옳다. | . class Student2(Student): def __getitem__(self,index): return [self.age,self.semester][index] . hynn=Student2() . hynn+1+1+0+0 . 나이: 22.0 학기: 3 . hynn[0] . 22.0 . hynn[1] . 3 . hynn[:] . [22.0, 3] . &#46020;&#50880;&#47568; &#51089;&#49457;&#48169;&#48277; . - 넘파이의 경우 아래와 같이 도움말이 잘 작성되어 있다. . import numpy as np a=np.array([1,2,3]) # a? . - 하지만 우리는? . hynn? . Type: Student2 String form: 나이: 22.0 학기: 3 Docstring: &lt;no docstring&gt; . - 우리도 도움말을 작성하고 싶다. . class Student2(Student): &#39;&#39;&#39; Student2는 Student의 개선 # Student 클래스의 기능 1. 출력기능 (__repr__) 2. 연산기능 (__add__): 학기와 나이를 카운트 Examples -- &gt;&gt;&gt; hynn=Student2() &gt;&gt;&gt; hynn+1 나이: 20.5 학기: 2 # Student2에서 추가된 기능 1. 인덱싱 &#39;&#39;&#39; def __getitem__(self,index): return [self.age,self.semester][index] . hynn=Student2() . hynn? . Type: Student2 String form: 나이: 20.0 학기: 1 Docstring: Student2는 Student의 개선 # Student 클래스의 기능 1. 출력기능 (__repr__) 2. 연산기능 (__add__): 학기와 나이를 카운트 Examples -- &gt;&gt;&gt; hynn=Student2() &gt;&gt;&gt; hynn+1 나이: 20.5 학기: 2 # Student2에서 추가된 기능 1. 인덱싱 . hynn=Student2(21,1) . hynn . 나이: 21 학기: 1 . hynn? . Type: Student2 String form: 나이: 21 학기: 1 Docstring: Student2는 Student의 개선 # Student 클래스의 기능 1. 출력기능 (__repr__) 2. 연산기능 (__add__): 학기와 나이를 카운트 Examples -- &gt;&gt;&gt; hynn=Student2() &gt;&gt;&gt; hynn+1 나이: 20.5 학기: 2 # Student2에서 추가된 기능 1. 인덱싱 . self&#50640; &#45824;&#54620; &#51652;&#49892; . – 사실 이름이 self가 아니어도 된다. . -클래스의 첫번째 인자는 굳이 self가 아니라 임의로 a라고 명명해도 됨 . class MooYaHo: &#39;&#39;&#39; 201821994 &#39;&#39;&#39; def __init__(a): a.text=&#39;mooyaho&#39; . moo1=MooYaHo() . moo1? . Type: MooYaHo String form: &lt;__main__.MooYaHo object at 0x00000211AF1B7C10&gt; Docstring: 201821994 . moo1=MooYaHo() . moo1.text . &#39;mooyaho&#39; . – 그런데 self를 많이 쓴다. .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/02/intro3.html",
            "relUrl": "/2022/01/02/intro3.html",
            "date": " • Jan 2, 2022"
        }
        
    
  
    
        ,"post21": {
            "title": "2022/01/02/SUN",
            "content": "흑백 $ to$ 차원: 세로픽셀수 $ times$ 가로픽셀수, 값: 0~255 (값이 클수록 흰색) | . 칼라 $ to$ 차원: 세로픽셀수 $ times$ 가로픽셀수 $ times$ 3, 값: 0~255 (값이 클수록 진한빨강, 진한파랑, 진한녹색) | . import cv2 as cv . bd=cv.imread(&#39;KakaoTalk_20210927_192557462.jpg&#39;) . import matplotlib.pyplot as plt plt.imshow(bd) . &lt;matplotlib.image.AxesImage at 0x1df8e565d90&gt; . bd.shape . (1084, 1084, 3) . (1084, 1084, 3) -&gt; 빨강으로만 표현된 사진, 파랑, 초록 각각으로 표현된 사진, 세사진이 겹쳐진 것을 의미 | . zeros_like -&gt; 초기화 | . [ : , : , 0 ] =&gt; 첫부분하고 두번째 부분은 세로,가로 픽셀수를 의미 마지막 숫자가 0,1,2순서대로 RGB임 | . import numpy as np bd_red=np.zeros_like(bd) #아예 초기화 bd_green=np.zeros_like(bd) #아예 초기화 bd_blue=np.zeros_like(bd) #아예 초기화 bd_red[:,:,0]=bd[:,:,0] bd_green[:,:,1]=bd[:,:,1] bd_blue[:,:,2]=bd[:,:,2] . plt.imshow(bd_red) . &lt;matplotlib.image.AxesImage at 0x1df8fab19a0&gt; . plt.imshow(bd_blue+bd_red) . &lt;matplotlib.image.AxesImage at 0x1df901f81c0&gt; . &#49328;&#51216;&#46020; (scatter plot) . import matplotlib.pyplot as plt . x=[1,2,3,4] y=[2,3,4,5] plt.plot(x,y,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x1df8feb2ee0&gt;] . deafult : line | 산점도는 보통 X와 Y의 관계를 알고 싶을 경우 그린다. | 박스플랏, 히스토그램은 그림을 그리기 위해서 하나의 변수만 필요함 | 따라서 산점도를 위해서는 두개의 변수가 필요함. | . x=[44,48,49,58,62,68,69,70,76,79] y=[159,160,162,165,167,162,165,175,165,172] . plt.plot(x,y,&#39;ok&#39;) . [&lt;matplotlib.lines.Line2D at 0x1df8ff27940&gt;] . 키가 큰 사람일수록 몸무게도 많이 나간다. (반대도 성립) | 키와 몸무게는 관계가 있어보인다. (정비례) | . 얼만큼 정비례인지? | 이 질문에 대답하기 위해서는 상관계수의 개념을 알아야 한다. | 상관계수에 대한 개념은 산점도를 이해함에 있어서 핵심개념이다. | . $$ (표본)상관계수 $$ . $$r= frac{ sum_{i=1}^{n}(x_i- bar{x})(y_i- bar{y}) }{ sqrt{ sum_{i=1}^{n}(x_i- bar{x})^2 sum_{i=1}^{n}(y_i- bar{y})^2 }} $$ . $$r= sum_{i=1}^{n} frac{1}{c}(x_i- bar{x})(y_i- bar{y}) $$ . $$r= sum_{i=1}^{n} left( frac{(x_i- bar{x})}{ sqrt{ sum_{i=1}^{n}(x_i- bar{x})^2}} frac{(y_i- bar{y})}{ sqrt{ sum_{i=1}^{n}(y_i- bar{y})^2}} right)$$ . $$ tilde{x}_i= frac{(x_i- bar{x})}{ sqrt{ sum_{i=1}^n(x_i- bar{x})^2}}, tilde{y}_i= frac{(y_i- bar{y})}{ sqrt{ sum_{i=1}^n(y_i- bar{y})^2}}$$ . $$r= sum_{i=1}^{n} tilde{x}_i tilde{y}_i $$ . import numpy as np x=np.array(x) y=np.array(y) . plt.plot(x-np.mean(x), y-np.mean(y),&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x1df8ff989a0&gt;] . - $a= sqrt{ sum_{i=1}^{n}(x_i- bar{x})^2}, b= sqrt{ sum_{i=1}^{n}(y_i- bar{y})^2}$ . a=np.sqrt(np.sum((x-np.mean(x))**2)) b=np.sqrt(np.sum((y-np.mean(y))**2)) a,b . (36.58004920718396, 15.218409903797438) . $a&gt;b$ 이므로 $ {x_i }$들이 $ {y_i }$들 보다 좀 더 퍼져있다. . $a= sqrt{n} times{ tt np.std(x)}$ . $b= sqrt{n} times{ tt np.std(y)}$ . std = 표준편차 . n=len(x) np.sqrt(n)*np.std(x), np.sqrt(n)*np.std(y) . (36.58004920718397, 15.21840990379744) . ${ tt np.std(x)}= sqrt{ frac{1}{n} sum_{i=1}^{n}(x_i- bar{x})^2}$ | ${ tt np.std(y)}= sqrt{ frac{1}{n} sum_{i=1}^{n}(y_i- bar{y})^2}$ | . - 이제 $( tilde{x}_i, tilde{y}_i)$를 그려보자. . xx= (x-np.mean(x))/a yy= (y-np.mean(y))/b plt.plot(xx,yy,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x1df90009e80&gt;] . 평균도 비슷하고 퍼진정도도 비슷하다. | . - 질문1: $r$의 값이 양수인가? 음수인가? . plotly 사용하여 그려보자. . # px.scatter(x=xx, y=yy) . $ tilde{x}_i$, $ tilde{y}_i$ 를 곱한값이 양수인것과 음수인것을 체크해보자. | 양수인쪽이 많은지 음수인쪽이 많은지 생각해보자. | $r= sum_{i=1}^{n} tilde{x}_i tilde{y}_i$ 의 부호는? +가 -보다 많은 것으로 보아 상관계수의 부호는 +임을 알 수 있다 | . - 질문2 : 아래와 같은 두개의 데이터 set이 있다고 하자. . x1=np.arange(0,10,0.1) y1=x1+np.random.normal(loc=0,scale=1.0,size=len(x1)) . plt.plot(x1,y1,&#39;o&#39;) . [&lt;matplotlib.lines.Line2D at 0x1df92eb2a90&gt;] . x2=np.arange(0,10,0.1) y2=x2+np.random.normal(loc=0,scale=7.0,size=len(x2)) # 표준편차 업그레이드 plt.plot(x2,y2,&#39;x&#39;) . [&lt;matplotlib.lines.Line2D at 0x1df92f209d0&gt;] . 아래는 겹쳐 그린 것 . plt.plot(x1,y1,&#39;o&#39;) plt.plot(x2,y2,&#39;x&#39;) . [&lt;matplotlib.lines.Line2D at 0x1df92f901c0&gt;] . n=len(x1) xx1= (x1-np.mean(x1)) / (np.std(x1) * np.sqrt(n)) yy1= (y1-np.mean(y1)) / (np.std(y1) * np.sqrt(n)) xx2= (x2-np.mean(x2)) / (np.std(x2) * np.sqrt(n)) yy2= (y2-np.mean(y2)) / (np.std(y2) * np.sqrt(n)) . plt.plot(xx1,yy1,&#39;o&#39;) plt.plot(xx2,yy2,&#39;x&#39;) . [&lt;matplotlib.lines.Line2D at 0x1df92feef70&gt;] . (1) $r_1$, $r_2$의 부호는 양수인가? 음수인가? . $r_1$ 의 부호는 양수 $r_2$ 의 부호도 대충 양수임을 알 수 있음 $ to$ 1,2,3,4분면으로 나눠서 1,3사분면에 많은 분포가 있을수록 상관계수의 부호는 양수일 확률이 높다 | . (2) $r_1,r_2$의 값중 어떠한 값이 더 절대값이 큰가? . r1의 절댓값이 더 클 것. 왜냐하면 r2는 2사분면 4사분면이 값이 음수라 양수값들을 상쇄시키기 때문에 절댓값의 크기 또한 작아질 것이다. | . sum(xx1*yy1),sum(xx2*yy2) . (0.9381086706782814, 0.36042715437479517) . 파란색의 계수값이 더 크므로 더 강한 직선성을 띈다고 할 수 있다 .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/02/intro2.html",
            "relUrl": "/2022/01/02/intro2.html",
            "date": " • Jan 2, 2022"
        }
        
    
  
    
        ,"post22": {
            "title": "2022/01/01/SAT",
            "content": "참고 : github.com/guebin 최규빈 교수님 강의 자료 | . - &#48136;? &#51064;&#53552;&#45367; &#48136;? . &#48136; . 한 사람 혹은 집단에서 다른 지성으로 생각 혹은 믿음이 전달될 때 전달되는 모방 가능한 사회적 단위를 총칭 | . &#51064;&#53552;&#45367; &#48136; . 밈의 한 형태 | 인터넷을 통해 사람들에게 전파되는 어떤 생각, 행동, 스타일 등 | . . &#53364;&#47000;&#49828; . 많은 교재에서 정의를 회피함 | 비유적 설명 , 다른 대상을 가져와서 설명 클래스는 과자틀과 비슷하다. 클래스란 똑같은 무엇인가를 계속 만들어 낼 수도 있는 설계도면이고 객체란 클래스로 만든 피조물을 뜻한다. | . | . 직접적 설명 복제를 위한 확장가능한 프로그램 코드의 유닛 | . | . . 밈의 예제로 돌아가보자. . (1) 무야호 원본 시청 . (2) 복사하고 싶은 속성을 추림 . (3) 복제가능한 어떤 밈(틀)을 만듬 . 틀1: 무야호~~~ -&gt; 그만큼 ~하셨다는거지? | 틀2: 무야호 + 영상샘플링 + 음악샘플링 | . (4) 밈으로부터 짤을 만든다. . . 좀더 정리하여 말하면, . (1) 개념의 인지 . (2) 복사하고 싶은 속성을 추림 . (3) 복사가능한 어떤 틀을 만듬 (=클래스를 정의) . (4) 틀에서 인스턴스를 만든다 (=클래스에서 인스턴스를 만든다) . . [&#50696;&#51228;1] . 농심에서 나온 무파마를 먹고, 너무 맛있어서 갑자기 밈으로 놀고 싶어졌다. . from PIL import Image Image.open(&#39;mooyaho1.jpg&#39;).resize((200,200)) . &#52395; &#49884;&#46020;: &#45800;&#49692;&#47924;&#49885; . title=&quot;농심 무파마&quot; img=Image.open(&#39;mooyaho1.jpg&#39;).resize((200,200)) don=&quot;그만큼 맛있으시단거지&quot; . print(title) display(img) print(don) . 농심 무파마 . 그만큼 맛있으시단거지 . 짤을 변경하고 싶다면, 아래와 같이 수행하자. | . title=&quot;속 시원한 농심 무야호&quot; print(title) display(img) print(don) . 속 시원한 농심 무야호 . 그만큼 맛있으시단거지 . 첫 시도의 허점 . 변용 가능한 여러개 짤을 관리하기 힘들다. | 불필요한 반복도 많다. print, display, print &lt;-- 짤을 만들때마다 반복 | 코드가 지저분하다. (디버깅이 힘들다) | . &#46160;&#48264;&#51704; &#49884;&#46020;: &#47784;&#46280; . import mooyaho . mooyaho.memeshow(mooyaho.title, mooyaho.img,mooyaho.don) . 농심 무파마 . 그만큼 맛있으시단거지 . 타이틀을 바꾸고싶다면? | . mooyaho.title=&#39;속시원한 농심 무야호&#39; mooyaho.memeshow(mooyaho.title, mooyaho.img, mooyaho.don) . 속시원한 농심 무야호 . 그만큼 맛있으시단거지 . 두 번째 시도의 아쉬운 점 코드는 상대적으로 깔끔하지만, 함수부분이 조금 아쉽다. | 코드를 수정할때마 커널재시작을 해야한다. | . | . &#49464;&#48264;&#51704; &#49884;&#46020;: &#53364;&#47000;&#49828; . &#48373;&#51228;&#44032;&#45733;&#54620; &#53952;&#51012; &#47564;&#46308;&#51088; = &#53364;&#47000;&#49828;&#47484; &#49440;&#50616;&#54616;&#51088; . class MooYaHo(): ### MooYaHo라는 이름을 가진 클래스 선언 title=&quot;농심 무파마&quot; ### 클래스안에서 정의된 변수1 img=Image.open(&#39;mooyaho1.jpg&#39;).resize((200,200)) ### 클래스안에서 정의된 변수2 don=&quot;그만큼 맛있으시단거지&quot; ### 클래스안에서 정의된 변수3 def memeshow(self): ### 클래스안에서 정의된 함수* print(self.title) display(self.img) print(self.don) . 모듈버전과 비교해보자. | . from PIL import Image title=&quot;농심 무파마&quot; ### 모듈안에서 정의된 변수1 img=Image.open(&#39;mooyaho1.jpg&#39;).resize((200,200)) ### 모듈안에서 정의된 변수2 don=&quot;그만큼 맛있으시단거지&quot; ### 모듈안에서 정의된 변수3 def memeshow(title,img,don): ### 모듈안에서 정의된 함수 print(title) display(img) print(don) . $ to$ 모듈버전이랑 비교하니까 함수부분이 조금 다르다. . $ to$ 혹시 모듈처럼 아래와 같이 클래스를 선언해도 되지 않나? . class MooYaHo(): ### MooYaHo라는 이름을 가진 클래스 선언 title=&quot;농심 무파마&quot; ### 클래스안에서 정의된 변수1 img=Image.open(&#39;mooyaho1.jpg&#39;).resize((200,200)) ### 클래스안에서 정의된 변수2 don=&quot;그만큼 맛있으시단거지&quot; ### 클래스안에서 정의된 변수3 def memeshow(title,img,don): ### 클래스안에서 정의된 함수 print(title) display(img) print(don) . $ to$ 안 됨 (자세한 이유는 나중에) . 규칙1: 클래스내에서 함수를 선언하면 반드시 첫번째 인자는 self를 넣어야 한다. --&gt; self가 뭘까? . 규칙2: 클래스 내에서 정의한 변수 (예를들면 title, img, don)를 사용하려면 . self.title, self.img, self.don | MooYaHo.title, MooYaHo.img, MooYaHo.don | . &#48136;&#51004;&#47196; &#48512;&#53552; &#51684;&#51012; &#47564;&#46304;&#45796;. (&#53364;&#47000;&#49828;&#47196;&#48512;&#53552; &#51064;&#49828;&#53556;&#49828;&#47484; &#49373;&#49457;&#54620;&#45796;.) . Step1: 클래스에서 인스턴스를 만듬 . Step2: 인스턴스에서 memeshow라는 함수를 사용 . 클래스에서 인스턴스를 찍어내는 방법 . 함수사용법과 비슷 | 클래스 이름을 쓰고 콘텐츠를 구체화시키는 과정에서 필요한 입력1, 입력2를 ()에 넣는다. | MooYaHo의 경우는 따로 입력이 없으므로, 그냥 MooYaHo하고 입력을 비워둔다. 즉 MooYaHo()로 생성 | . moo1=MooYaHo() ### 첫번째 인스턴스 생성 . moo1? . Type: MooYaHo String form: &lt;__main__.MooYaHo object at 0x0000024E7565C730&gt; Docstring: &lt;no docstring&gt; . Type이 MooYaHo $ dots$ . 원래 Type은 int, float, list 이어야 할텐데..? int 가 클래스이름이었나? $ to$ 일단 나중에 . 밈의 속성 확인 . moo1.하고 탭을 눌러봤더니 아래 같은 것들이 나왔다 . 주황색: don, img, title | 파란식: memeshow &lt;- 함수 함수의 입력: self | 함수의 기능: print, display, print | . | . moo1.memeshow() . 농심 무파마 . 그만큼 맛있으시단거지 . &#53364;&#47000;&#49828;&#51032; &#50948;&#47141; . 성능1: 인스턴스에서 .을 찍고 접근할 수 있는 여러 자료들을 정의할 수 있다. . moo1.title . &#39;농심 무파마&#39; . 성능2: 인스턴스에서 .을 찍고 쓸 수 있는 자체적인 함수(=method라고 함)를 정의할 수 있다. . moo1.memeshow() . 농심 무파마 . 그만큼 맛있으시단거지 . 성능3: 짤의 내용을 쉽게 바꿀 수 있다. . moo1.title=&quot;속까지 시원해지는 농심 무야호&quot; . moo1.memeshow() . 속까지 시원해지는 농심 무야호 . 그만큼 맛있으시단거지 . moo1.don=&quot;그만큼 시원하시다는 거지&quot; moo1.memeshow() . 속까지 시원해지는 농심 무야호 . 그만큼 시원하시다는 거지 . 성능4: 여러짤을 동시에 쉽게 컨트롤 할 수 있다. . moo2=MooYaHo() moo3=MooYaHo() . moo2.title=&quot;오뚜기 진야호&quot; moo2.don=&quot;그만큼 진하시다는 거지~&quot; moo2.memeshow() . 오뚜기 진야호 . 그만큼 진하시다는 거지~ . moo3.title=&quot;팔도 비야호&quot; moo3.don=&quot;그만큼 비비고 싶으셨단 거지~&quot; moo3.memeshow() . 팔도 비야호 . 그만큼 비비고 싶으셨단 거지~ . moo2.memeshow() . 오뚜기 진야호 . 그만큼 진하시다는 거지~ . 성능 5: 틀의 재설계(밈의 재설계) $ star$$ star$$ star$ . 출력만 살짝 바꾸어서 MooYaHo2를 만들고 싶다. --&gt; MooYaHo의 모든 내용은 그대로 가져오고, 그 살짝만 다시 조정하면 된다. . #### 이런식으로 할 필요 없다. class MooYaHo2(): ### MooYaHo라는 이름을 가진 클래스 선언 title=&quot;농심 무파마&quot; ### 클래스안에서 정의된 변수1 img=Image.open(&#39;mooyaho1.jpg&#39;).resize((200,200)) ### 클래스안에서 정의된 변수2 don=&quot;그만큼 맛있으시단거지&quot; ### 클래스안에서 정의된 변수3 def memeshow(self): ### 클래스안에서 정의된 함수* print(&#39;☆☆☆☆☆☆[&#39;+self.title+&#39;]☆☆☆☆☆☆&#39;) display(self.img) print(&#39;형돈:&#39;+self.don) . class MooYaHo2(MooYaHo): choi=&#39;무야~~~~~호~~~!!!&#39; def memeshow(self): ### 클래스안에서 정의된 함수* print(&#39;☆☆☆☆☆☆[&#39;+self.title+&#39;]☆☆☆☆☆☆&#39;) display(self.img) print(self.choi) print(&#39;형돈:&#39;+self.don) . moo4=MooYaHo2() . moo4.memeshow() . ☆☆☆☆☆☆[농심 무파마]☆☆☆☆☆☆ . 무야~~~~~호~~~!!! 형돈:그만큼 맛있으시단거지 . moo5=MooYaHo2() . moo5.title=&#39;오뚜기 진야호&#39; moo5.don=&#39;그만큼 진하시다는 거지&#39; moo5.memeshow() . ☆☆☆☆☆☆[오뚜기 진야호]☆☆☆☆☆☆ . 무야~~~~~호~~~!!! 형돈:그만큼 진하시다는 거지 . . &#50696;&#51228;2 . clss안에 있는 함수는 첫번째 인자로 self를 받고 변수 사용할 때는 self.이라고 사용 . 아래 셀에서 Meme은 class의 name이다 . import numpy class Meme: # class Meme(): n=0 #짤 생성 횟수 title=&quot;농심&quot; def memeshow(self): self.n+=1 print(self.title) print(&quot;*****&quot;) print(numpy.random.normal()) print(&quot;*****&quot;) print(str(self.n)+&#39;번째 짤&#39;) . ins1=Meme() . ins1.memeshow() . 농심 ***** 0.2916597433173283 ***** 2번째 짤 . ins2=Meme() . ins2.title=&#39;삼양&#39; . ins2.memeshow() . 삼양 ***** 0.608642243170386 ***** 1번째 짤 . ins2.n . 1 . ins1.n . 2 . ㄴㅇㄱ 아?! self에 들어가야했던것은 사실 인스턴스 이름이었음. . 그런데 인스턴스 이름은 모른다. (내가 뭘로 만들지 알고? ) . 그래서 그냥 self로 하는것임. . #### &#50696;&#51228;3 . 아래코드가 아쉽다. . $ to$ 왜 아쉽지? . $ to$ 왜 굳이 default가 농심이여서 instanc 생설할 때마다 title을 수정해줘야지? . ins2=Meme() ins2.title=&#39;삼양&#39; . title이 無디폴트였으면 좋겠다. . &#51064;&#49828;&#53556;&#49828;&#47484; &#47564;&#46308;&#46412;&#47560;&#45796; &#53440;&#51060;&#53952;&#51012; &#49352;&#47196; &#51221;&#54616;&#45716; &#48169;&#49885;&#51060; &#51080;&#51004;&#47732; &#51339;&#44192;&#45796;. . &#44536; &#45824;&#50504;&#51060; : __init__ . __init__ . 인스턴스가 생성되는 시점에 자동 실행 | 특별한 첫번째 인자를 가진다(self) | 클래스를 인스턴스화 할때 ( )의 값들을 함수의 입력으로 받는다. | . Meme2 라는 새로운 class를 정의中 . *&#51452;&#51032;* . def `__init__`(self,title): . 에서 self.title이 아니라 self,title같이 콤마를 사용해야한다. . 그런데 첫번째 인자를 굳이 self로 안 받아도 되는 것 같긴 함 . class Meme2: n=0 def __init__(a,title): a.title=title def memeshow(a): a.n=a.n+1 print(a.title) print(&quot;*****&quot;) print(numpy.random.normal()) print(&quot;*****&quot;) print(str(a.n)+&#39;번째 짤&#39;) . ins3=Meme2(&#39;팔도&#39;) . ins3.title . &#39;팔도&#39; . ins3.memeshow() . 팔도 ***** -1.9895310742180208 ***** 3번째 짤 . . (1) Meme2()를 인스턴스화 하는 순간에 __init__ 이 실행되어야함. . (2) 그런데 __init__의 첫번째 인자인 self는 입력 안해도 된다고 치고, 두번째 인수인 title은 입력으로 받았어야만 하는것인데, 입력으로 받지못하여 에러메시지 발생. . (3) 도대체 그럼 언제 __init__의 두번째 인수인 title을 넣어야할까? 곰곰히 생각해보니 Meme2를 인스턴스화 하는 순간에 입력으로 넣었어야 논리적으로 맞다. 즉 ins3=Meme2(&#39;팔도&#39;)와 같은 식으로 생성하는 순간 입력으로 넣어야 하는 것이었음. . (4) __init__의 두번째 인자가 &#39;팔도&#39;로 입력되었고, 이것이 self.title 즉 ins3.title에 바로 업데이트 된 상황임. . . 코드의 효율적인 수정 . Meme2는 Meme을 상속받는 中 . class Meme2(Meme): def __init__(self,title): self.title=title . ins3=Meme2(&#39;팔도&#39;) . ins3.memeshow() . 팔도 ***** -2.1018660318391236 ***** 1번째 짤 . ins4=Meme2(&#39;오뚜기&#39;) . ins4.memeshow() . 오뚜기 ***** 0.25483170477981176 ***** 1번째 짤 . . 욕심: 타이틀이 없다고 에러메시지를 띄우는것 보다 없으면 없는대로 만들어도 되지 않을까? . class Meme3(Meme): def __init__(self,title=None): self.title=title . ins5=Meme3() . ins5.title . title을 None으로 설정해놔서 title이 출력되지 않은 상황임 . ins5.memeshow() . None ***** 0.6307634191745345 ***** 1번째 짤 . ins5.title=&#39;야구르트&#39; . ins5.title . &#39;야구르트&#39; . ins5.memeshow() . 야구르트 ***** -1.3387268900814815 ***** 2번째 짤 .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/01/intro3.html",
            "relUrl": "/2022/01/01/intro3.html",
            "date": " • Jan 1, 2022"
        }
        
    
  
    
        ,"post23": {
            "title": "2022/01/01/SAT(HappyNewYear)",
            "content": "Histogram Equalization, HE :&#51060;&#48120;&#51648; &#47749;&#50516;&#45824;&#48708; &#44060;&#49440; . import cv2 as cv import matplotlib.pyplot as plt import pandas as pd . img = cv.imread(&#39;KakaoTalk_20210927_192557462.jpg&#39;,0) # 이미지 저장하는 과정 . 마지막 숫자 0 : 이미지를 흑백으로 저장 | cmap = &#39;gray&#39; =&gt; 흑백으로 불러와라 . | vmin &amp; vmax의 범위는 명암 범위? 뭐 이런 것 같음 . | . plt.imshow(img,cmap=&#39;gray&#39;,vmin=0,vmax=255) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x25cfb4eeaf0&gt; . img . array([[235, 233, 228, ..., 224, 224, 224], [229, 231, 231, ..., 222, 222, 222], [226, 227, 231, ..., 223, 223, 223], ..., [227, 231, 224, ..., 29, 20, 26], [230, 235, 229, ..., 21, 10, 15], [238, 239, 233, ..., 19, 14, 20]], dtype=uint8) . - 이미지자료 : 0(검정)~255(흰색) 사이의 어떠한 숫자들이 포함된 매트릭스 . 2차원으로 이루어졌음 . plt.imshow(img[500:600,500:600],cmap=&#39;gray&#39;,vmin=0,vmax=255) . &lt;matplotlib.image.AxesImage at 0x25cfb57e2b0&gt; . img.shape . (1084, 1084) . 이미지는 1084x1084=1175056 개의 숫자의 모임 | 벡터로 만든다음 히스토그램을 그려보자 | . fig1=plt.hist(img.flatten(),256,[0,256]) #0부터 256까지 256개로 잘라서 각 범주당 개수를 표현 . - 히스토그램을 그려보니 특정 구간에 너무 값들이 모여있음 . - 원래 0~255까지의 색을 표현할 수 있는데 컴퓨터가 표현가능한 색상보다 적은 조합만을 사용하고 있음. . - 아이디어: 좀 더 많은 색상을 표현할 수 없을까? $ to$ 위의 히스토그램은 좀 평평하게 만들면 되지 않을까? . img2=cv.equalizeHist(img) . fig2_1=plt.hist(img2.flatten(),256,[0,256]) . 값의 분포도가 커졌음 | . plt.imshow(img2,cmap=&#39;gray&#39;,vmin=0,vmax=255) plt.colorbar() . &lt;matplotlib.colorbar.Colorbar at 0x25cfdad86d0&gt; . import numpy as np _img=np.hstack((img,img2)) . plt.imshow(_img,cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x25cfdc80ac0&gt; .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2022/01/01/intro2.html",
            "relUrl": "/2022/01/01/intro2.html",
            "date": " • Jan 1, 2022"
        }
        
    
  
    
        ,"post24": {
            "title": "2021/12/30/THU",
            "content": "import pandas as pd . df=pd.read_csv(&#39;WEOApr2020all.csv&#39;) . df.describe() . WEO Country Code Estimates Start After . count 1552.000000 | 1466.000000 | . mean 553.670103 | 2018.291951 | . std 261.437803 | 1.075652 | . min 111.000000 | 2009.000000 | . 25% 314.000000 | 2018.000000 | . 50% 571.000000 | 2018.000000 | . 75% 734.000000 | 2019.000000 | . max 968.000000 | 2020.000000 | . df.index . RangeIndex(start=0, stop=1552, step=1) . pd.Series(df.index) . 0 0 1 1 2 2 3 3 4 4 ... 1547 1547 1548 1548 1549 1549 1550 1550 1551 1551 Length: 1552, dtype: int64 . df.columns . Index([&#39;WEO Country Code&#39;, &#39;ISO&#39;, &#39;WEO Subject Code&#39;, &#39;Country&#39;, &#39;Subject Descriptor&#39;, &#39;Subject Notes&#39;, &#39;Units&#39;, &#39;Scale&#39;, &#39;Country/Series-specific Notes&#39;, &#39;1980&#39;, &#39;1981&#39;, &#39;1982&#39;, &#39;1983&#39;, &#39;1984&#39;, &#39;1985&#39;, &#39;1986&#39;, &#39;1987&#39;, &#39;1988&#39;, &#39;1989&#39;, &#39;1990&#39;, &#39;1991&#39;, &#39;1992&#39;, &#39;1993&#39;, &#39;1994&#39;, &#39;1995&#39;, &#39;1996&#39;, &#39;1997&#39;, &#39;1998&#39;, &#39;1999&#39;, &#39;2000&#39;, &#39;2001&#39;, &#39;2002&#39;, &#39;2003&#39;, &#39;2004&#39;, &#39;2005&#39;, &#39;2006&#39;, &#39;2007&#39;, &#39;2008&#39;, &#39;2009&#39;, &#39;2010&#39;, &#39;2011&#39;, &#39;2012&#39;, &#39;2013&#39;, &#39;2014&#39;, &#39;2015&#39;, &#39;2016&#39;, &#39;2017&#39;, &#39;2018&#39;, &#39;2019&#39;, &#39;2020&#39;, &#39;2021&#39;, &#39;Estimates Start After&#39;], dtype=&#39;object&#39;) . pd.Series(df.columns) . 0 WEO Country Code 1 ISO 2 WEO Subject Code 3 Country 4 Subject Descriptor 5 Subject Notes 6 Units 7 Scale 8 Country/Series-specific Notes 9 1980 10 1981 11 1982 12 1983 13 1984 14 1985 15 1986 16 1987 17 1988 18 1989 19 1990 20 1991 21 1992 22 1993 23 1994 24 1995 25 1996 26 1997 27 1998 28 1999 29 2000 30 2001 31 2002 32 2003 33 2004 34 2005 35 2006 36 2007 37 2008 38 2009 39 2010 40 2011 41 2012 42 2013 43 2014 44 2015 45 2016 46 2017 47 2018 48 2019 49 2020 50 2021 51 Estimates Start After dtype: object . len(df[&#39;Country&#39;].unique()) . 194 . df[&#39;Country&#39;].nunique() # 194개 나라의 data가 들어있음을 알 수 있다 . 194 . df.iloc[:,3] . 0 Afghanistan 1 Afghanistan 2 Afghanistan 3 Afghanistan 4 Afghanistan ... 1547 Zimbabwe 1548 Zimbabwe 1549 Zimbabwe 1550 Zimbabwe 1551 Zimbabwe Name: Country, Length: 1552, dtype: object . df.Country . 0 Afghanistan 1 Afghanistan 2 Afghanistan 3 Afghanistan 4 Afghanistan ... 1547 Zimbabwe 1548 Zimbabwe 1549 Zimbabwe 1550 Zimbabwe 1551 Zimbabwe Name: Country, Length: 1552, dtype: object . df[[&#39;Country&#39;]] . Country . 0 Afghanistan | . 1 Afghanistan | . 2 Afghanistan | . 3 Afghanistan | . 4 Afghanistan | . ... ... | . 1547 Zimbabwe | . 1548 Zimbabwe | . 1549 Zimbabwe | . 1550 Zimbabwe | . 1551 Zimbabwe | . 1552 rows × 1 columns . df[[&#39;Subject Descriptor&#39;]].head(7) . Subject Descriptor . 0 Gross domestic product, constant prices | . 1 Gross domestic product, current prices | . 2 Gross domestic product per capita, constant pr... | . 3 Inflation, average consumer prices | . 4 Inflation, end of period consumer prices | . 5 Unemployment rate | . 6 General government net lending/borrowing | . df[[&#39;Subject Descriptor&#39;,&#39;2020&#39;]] . Subject Descriptor 2020 . 0 Gross domestic product, constant prices | -3.007 | . 1 Gross domestic product, current prices | 74.792 | . 2 Gross domestic product per capita, constant pr... | -4.291 | . 3 Inflation, average consumer prices | 4.711 | . 4 Inflation, end of period consumer prices | 4.5 | . ... ... | ... | . 1547 Inflation, average consumer prices | 319.036 | . 1548 Inflation, end of period consumer prices | 154.297 | . 1549 Unemployment rate | NaN | . 1550 General government net lending/borrowing | -4.931 | . 1551 Current account balance | -1.914 | . 1552 rows × 2 columns . df[[&#39;Subject Descriptor&#39;,&#39;2020&#39;,&#39;Country&#39;]] . Subject Descriptor 2020 Country . 0 Gross domestic product, constant prices | -3.007 | Afghanistan | . 1 Gross domestic product, current prices | 74.792 | Afghanistan | . 2 Gross domestic product per capita, constant pr... | -4.291 | Afghanistan | . 3 Inflation, average consumer prices | 4.711 | Afghanistan | . 4 Inflation, end of period consumer prices | 4.5 | Afghanistan | . ... ... | ... | ... | . 1547 Inflation, average consumer prices | 319.036 | Zimbabwe | . 1548 Inflation, end of period consumer prices | 154.297 | Zimbabwe | . 1549 Unemployment rate | NaN | Zimbabwe | . 1550 General government net lending/borrowing | -4.931 | Zimbabwe | . 1551 Current account balance | -1.914 | Zimbabwe | . 1552 rows × 3 columns . Inflation . . df[&#39;Subject Descriptor&#39;].str . create a new string object from the given object | 판다스에서 문자열 관련 함수를 사용하거나 전처리를 하기 위해서는 함수 및 명령어 앞에 str을 붙여주어야 한다. | . . df[&#39;Subject Descriptor&#39;].str.contains() . 지정한 문자열이 포함되어 있는지 알 수 있다. . . idx_inf=df[&#39;Subject Descriptor&#39;].str.contains(&#39;Inflation, end of&#39;) idx_inf . 0 False 1 False 2 False 3 False 4 True ... 1547 False 1548 True 1549 False 1550 False 1551 False Name: Subject Descriptor, Length: 1552, dtype: bool . sum(idx_inf) . 194 . df.loc[idx_inf] . WEO Country Code ISO WEO Subject Code Country Subject Descriptor Subject Notes Units Scale Country/Series-specific Notes 1980 ... 2013 2014 2015 2016 2017 2018 2019 2020 2021 Estimates Start After . 4 512 | AFG | PCPIEPCH | Afghanistan | Inflation, end of period consumer prices | Annual percentages of end of period consumer ... | Percent change | NaN | Source: National Statistics Office Latest actu... | NaN | ... | 7.241 | 1.487 | 1.131 | 4.588 | 3.041 | 0.755 | 2.773 | 4.5 | 5 | 2018.0 | . 12 914 | ALB | PCPIEPCH | Albania | Inflation, end of period consumer prices | Annual percentages of end of period consumer ... | Percent change | NaN | Source: National Statistics Office Latest actu... | NaN | ... | 1.776 | 0.719 | 1.937 | 2.176 | 1.798 | 1.799 | 1.15 | 2.6 | 2.9 | 2019.0 | . 20 612 | DZA | PCPIEPCH | Algeria | Inflation, end of period consumer prices | Annual percentages of end of period consumer ... | Percent change | NaN | Source: National Statistics Office Latest actu... | 14.143 | ... | 1.148 | 5.253 | 4.362 | 6.957 | 4.933 | 2.702 | 2.434 | 3.3 | 4 | 2019.0 | . 28 614 | AGO | PCPIEPCH | Angola | Inflation, end of period consumer prices | Annual percentages of end of period consumer ... | Percent change | NaN | Source: National Statistics Office Latest actu... | NaN | ... | 7.687 | 7.498 | 12.091 | 41.125 | 23.667 | 18.604 | 16.893 | 20.979 | 23.981 | 2019.0 | . 36 311 | ATG | PCPIEPCH | Antigua and Barbuda | Inflation, end of period consumer prices | Annual percentages of end of period consumer ... | Percent change | NaN | Source: Central Bank Latest actual data: 2018 ... | 17.71 | ... | 1.059 | 1.327 | 0.9 | -1.121 | 2.356 | 1.741 | 1.574 | 1.348 | 2.008 | 2018.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1516 299 | VEN | PCPIEPCH | Venezuela | Inflation, end of period consumer prices | Annual percentages of end of period consumer ... | Percent change | NaN | Source: Central Bank Latest actual data: 2019 ... | NaN | ... | 56.193 | 68.54 | 180.87 | 274.354 | 862.629 | 130,060.24 | 9,585.49 | 15,000.00 | 15,000.00 | 2019.0 | . 1524 582 | VNM | PCPIEPCH | Vietnam | Inflation, end of period consumer prices | Annual percentages of end of period consumer ... | Percent change | NaN | Source: National Statistics Office Latest actu... | NaN | ... | 6.036 | 1.839 | 0.597 | 4.737 | 2.597 | 2.983 | 5.237 | 2 | 4.3 | 2018.0 | . 1532 474 | YEM | PCPIEPCH | Yemen | Inflation, end of period consumer prices | Annual percentages of end of period consumer ... | Percent change | NaN | Source: National Statistics Office. Central Ba... | NaN | ... | 8.14 | 10.005 | 34 | 11.9 | 47 | 14.3 | 6.2 | 46 | 5 | 2017.0 | . 1540 754 | ZMB | PCPIEPCH | Zambia | Inflation, end of period consumer prices | Annual percentages of end of period consumer ... | Percent change | NaN | Source: National Statistics Office Latest actu... | NaN | ... | 7.14 | 7.862 | 21.112 | 7.469 | 6.085 | 7.9 | 11.7 | 12.7 | 11.4 | 2019.0 | . 1548 698 | ZWE | PCPIEPCH | Zimbabwe | Inflation, end of period consumer prices | Annual percentages of end of period consumer ... | Percent change | NaN | Source: National Statistics Office Latest actu... | NaN | ... | 0.331 | -0.796 | -2.473 | -0.898 | 3.43 | 42.074 | 521.15 | 154.297 | 3 | 2019.0 | . 194 rows × 52 columns . df_inf=df[idx_inf] . df_inf_2021=df_inf[[&#39;Country&#39;,&#39;2021&#39;]] . df_inf_2021 . Country 2021 . 4 Afghanistan | 5 | . 12 Albania | 2.9 | . 20 Algeria | 4 | . 28 Angola | 23.981 | . 36 Antigua and Barbuda | 2.008 | . ... ... | ... | . 1516 Venezuela | 15,000.00 | . 1524 Vietnam | 4.3 | . 1532 Yemen | 5 | . 1540 Zambia | 11.4 | . 1548 Zimbabwe | 3 | . 194 rows × 2 columns . (구) 인덱스drop | . df_inf_2021.reset_index(drop=True,inplace=True) . df_inf_2021 . Country 2021 . 0 Afghanistan | 5 | . 1 Albania | 2.9 | . 2 Algeria | 4 | . 3 Angola | 23.981 | . 4 Antigua and Barbuda | 2.008 | . ... ... | ... | . 189 Venezuela | 15,000.00 | . 190 Vietnam | 4.3 | . 191 Yemen | 5 | . 192 Zambia | 11.4 | . 193 Zimbabwe | 3 | . 194 rows × 2 columns . df_inf_2021.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 194 entries, 0 to 193 Data columns (total 2 columns): # Column Non-Null Count Dtype -- -- 0 Country 194 non-null object 1 2021 190 non-null object dtypes: object(2) memory usage: 3.2+ KB . 2021 null data가 4개임을 알 수 있다 | . . notnull() = null 아닌 것만 | . df_inf_2021=df_inf_2021.loc[df_inf_2021[&#39;2021&#39;].notnull()] . df_inf_2021 . Country 2021 . 0 Afghanistan | 5 | . 1 Albania | 2.9 | . 2 Algeria | 4 | . 3 Angola | 23.981 | . 4 Antigua and Barbuda | 2.008 | . ... ... | ... | . 189 Venezuela | 15,000.00 | . 190 Vietnam | 4.3 | . 191 Yemen | 5 | . 192 Zambia | 11.4 | . 193 Zimbabwe | 3 | . 190 rows × 2 columns . null data가 빠졌음 | . df_inf_2021.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 190 entries, 0 to 193 Data columns (total 2 columns): # Column Non-Null Count Dtype -- -- 0 Country 190 non-null object 1 2021 190 non-null object dtypes: object(2) memory usage: 4.5+ KB . data에 큰 숫자마다 comma가 들어가 있음 $ to$ 없애주자 | regex=True 정규표현식 사용하도록. | 굳이 없어도 되는 것 같은데.... | . df_inf_2021=df_inf_2021.replace(&#39;,&#39;,&#39;&#39;) df_inf_2021 . Country 2021 . 0 Afghanistan | 5 | . 1 Albania | 2.9 | . 2 Algeria | 4 | . 3 Angola | 23.981 | . 4 Antigua and Barbuda | 2.008 | . ... ... | ... | . 189 Venezuela | 15000.00 | . 190 Vietnam | 4.3 | . 191 Yemen | 5 | . 192 Zambia | 11.4 | . 193 Zimbabwe | 3 | . 190 rows × 2 columns . 이제 numeric data로 바꿔보자 | . df_inf_2021[&#39;2021&#39;]=pd.to_numeric(df_inf_2021[&#39;2021&#39;]) . 확인해보자 | . df_inf_2021.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 190 entries, 0 to 193 Data columns (total 2 columns): # Column Non-Null Count Dtype -- -- 0 Country 190 non-null object 1 2021 190 non-null float64 dtypes: float64(1), object(1) memory usage: 4.5+ KB . float64로 잘 바뀌었음 | . df_inf_2021.sort_values(&#39;2021&#39;).plot.bar(x=&#39;Country&#39;) . &lt;AxesSubplot:xlabel=&#39;Country&#39;&gt; . 무용지물의 그래프가 나왔다 | . df_inf_2021.sort_values(&#39;2021&#39;).iloc[0:20,:].plot.bar(x=&#39;Country&#39;) . &lt;AxesSubplot:xlabel=&#39;Country&#39;&gt; . &#49892;&#50629;&#47456; . df_ur=df[df[&#39;Subject Descriptor&#39;].str.contains(&#39;Unemployment&#39;)] df_ur . WEO Country Code ISO WEO Subject Code Country Subject Descriptor Subject Notes Units Scale Country/Series-specific Notes 1980 ... 2013 2014 2015 2016 2017 2018 2019 2020 2021 Estimates Start After . 5 512 | AFG | LUR | Afghanistan | Unemployment rate | Unemployment rate can be defined by either the... | Percent of total labor force | NaN | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 13 914 | ALB | LUR | Albania | Unemployment rate | Unemployment rate can be defined by either the... | Percent of total labor force | NaN | Source: National Statistics Office Latest actu... | 5.028 | ... | 15.9 | 17.5 | 17.1 | 15.2 | 13.7 | 12.3 | 12 | 11.8 | 11.5 | 2019.0 | . 21 612 | DZA | LUR | Algeria | Unemployment rate | Unemployment rate can be defined by either the... | Percent of total labor force | NaN | Source: National Statistics Office Latest actu... | 15.789 | ... | 9.829 | 10.6 | 11.214 | 10.498 | 11.709 | 11.731 | 11.383 | 15.091 | 13.909 | 2019.0 | . 29 614 | AGO | LUR | Angola | Unemployment rate | Unemployment rate can be defined by either the... | Percent of total labor force | NaN | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 37 311 | ATG | LUR | Antigua and Barbuda | Unemployment rate | Unemployment rate can be defined by either the... | Percent of total labor force | NaN | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1517 299 | VEN | LUR | Venezuela | Unemployment rate | Unemployment rate can be defined by either the... | Percent of total labor force | NaN | Source: National Statistics Office Latest actu... | NaN | ... | 7.47 | 6.7 | 7.4 | 20.863 | 27.886 | 35.543 | NaN | NaN | NaN | 2011.0 | . 1525 582 | VNM | LUR | Vietnam | Unemployment rate | Unemployment rate can be defined by either the... | Percent of total labor force | NaN | Source: Other Latest actual data: 2019 Employm... | NaN | ... | 2.75 | 2.1 | 2.33 | 2.33 | 2.21 | 2.21 | 2.21 | NaN | NaN | 2019.0 | . 1533 474 | YEM | LUR | Yemen | Unemployment rate | Unemployment rate can be defined by either the... | Percent of total labor force | NaN | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 1541 754 | ZMB | LUR | Zambia | Unemployment rate | Unemployment rate can be defined by either the... | Percent of total labor force | NaN | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 1549 698 | ZWE | LUR | Zimbabwe | Unemployment rate | Unemployment rate can be defined by either the... | Percent of total labor force | NaN | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 194 rows × 52 columns . df_ur=df_ur[[&#39;Country&#39;,&#39;2021&#39;]] . df_ur.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 194 entries, 5 to 1549 Data columns (total 2 columns): # Column Non-Null Count Dtype -- -- 0 Country 194 non-null object 1 2021 100 non-null object dtypes: object(2) memory usage: 4.5+ KB . 94개의 null data 발견 | . df_ur=df_ur.loc[df_ur[&#39;2021&#39;].notnull()] . df_ur.reset_index(drop=True,inplace=True) df_ur . Country 2021 . 0 Albania | 11.5 | . 1 Algeria | 13.909 | . 2 Argentina | 10.084 | . 3 Armenia | 18.389 | . 4 Aruba | 7.458 | . ... ... | ... | . 95 Turkey | 15.567 | . 96 Ukraine | 9.318 | . 97 United Kingdom | 4.375 | . 98 United States | 9.135 | . 99 Uruguay | 8.098 | . 100 rows × 2 columns . null data가 잘 빠졌음 | 이제 numeric으로 변형해주자 | . df_ur[&#39;2021&#39;]=pd.to_numeric(df_ur[&#39;2021&#39;]) . df_ur.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 100 entries, 0 to 99 Data columns (total 2 columns): # Column Non-Null Count Dtype -- -- 0 Country 100 non-null object 1 2021 100 non-null float64 dtypes: float64(1), object(1) memory usage: 1.7+ KB . df_ur.plot.bar(x=&#39;Country&#39;) . &lt;AxesSubplot:xlabel=&#39;Country&#39;&gt; . df_ur.sort_values(&#39;2021&#39;,ascending=False).plot.bar(x=&#39;Country&#39;, title=&#39;Unemployment Rate&#39;,figsize=(15,5)) . &lt;AxesSubplot:title={&#39;center&#39;:&#39;Unemployment Rate&#39;}, xlabel=&#39;Country&#39;&gt; . 관심있는 나라만 따로 표시해보자 | . df_ur_np=df_ur.sort_values(&#39;2021&#39;,ascending=False).to_numpy() . plt.plot()에서 figsize를 기본 크기를 지정할 수도 있지만, 매번 그릴 때마다 크기를 지정해야 하는 불편함이 있다. 특히 시계열 차트를 많이 그리는 경우 시간에 따른 변화를 보기 위해 가로로 긴 차트를 그리는 경우가 더 많다. 따라서 rcParams를 이용하여 차트 그림(figure)의 기본 설정을 지정할 수 있다. | . plt.rcParams[&#39;figure.figsize&#39;]=(20,3) plt.xticks(rotation=&#39;vertical&#39;) # x축명 세로로? plt.bar(df_ur_np[:,0],df_ur_np[:,1]) # x축, y축 plt.title(&#39;2021 Unemployment Rate - IMF World Economics Outlook Database, April 2020&#39;) idx=np.where(df_ur_np==&#39;Korea&#39;) plt.bar(df_ur_np[idx[0],0],df_ur_np[idx[0],1],label=&#39;Korea&#39;) idx=np.where(df_ur_np==&#39;United States&#39;) plt.bar(df_ur_np[idx[0],0],df_ur_np[idx[0],1],label=&#39;United States&#39;) idx=np.where(df_ur_np==&#39;China&#39;) plt.bar(df_ur_np[idx[0],0],df_ur_np[idx[0],1],label=&#39;China&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1a08f3edeb0&gt; . . TIP . df.head(3) . WEO Country Code ISO WEO Subject Code Country Subject Descriptor Subject Notes Units Scale Country/Series-specific Notes 1980 ... 2013 2014 2015 2016 2017 2018 2019 2020 2021 Estimates Start After . 0 512 | AFG | NGDP_RPCH | Afghanistan | Gross domestic product, constant prices | Annual percentages of constant price GDP are y... | Percent change | NaN | Source: National Statistics Office Latest actu... | NaN | ... | 5.683 | 2.697 | 0.988 | 2.164 | 2.889 | 2.664 | 3.037 | -3.007 | 4.495 | 2018.0 | . 1 512 | AFG | PPPGDP | Afghanistan | Gross domestic product, current prices | These data form the basis for the country weig... | Purchasing power parity; international dollars | Billions | Source: National Statistics Office Latest actu... | NaN | ... | 60.181 | 62.948 | 64.231 | 66.301 | 69.501 | 73.091 | 76.624 | 74.792 | 79.678 | 2018.0 | . 2 512 | AFG | NGDPRPPPPCPCH | Afghanistan | Gross domestic product per capita, constant pr... | GDP is expressed in constant international dol... | Purchasing power parity; percent change | NaN | Source: National Statistics Office Latest actu... | NaN | ... | 2.236 | -0.521 | -1.941 | -0.547 | 0.358 | 1.268 | 1.654 | -4.291 | 3.063 | 2018.0 | . 3 rows × 52 columns . len(df.columns) . 52 . idx = list(range(0,52)) . idx[3]=0 idx[0]=3 print(idx) . [3, 1, 2, 0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51] . df.iloc[:,idx] . Country ISO WEO Subject Code WEO Country Code Subject Descriptor Subject Notes Units Scale Country/Series-specific Notes 1980 ... 2013 2014 2015 2016 2017 2018 2019 2020 2021 Estimates Start After . 0 Afghanistan | AFG | NGDP_RPCH | 512 | Gross domestic product, constant prices | Annual percentages of constant price GDP are y... | Percent change | NaN | Source: National Statistics Office Latest actu... | NaN | ... | 5.683 | 2.697 | 0.988 | 2.164 | 2.889 | 2.664 | 3.037 | -3.007 | 4.495 | 2018.0 | . 1 Afghanistan | AFG | PPPGDP | 512 | Gross domestic product, current prices | These data form the basis for the country weig... | Purchasing power parity; international dollars | Billions | Source: National Statistics Office Latest actu... | NaN | ... | 60.181 | 62.948 | 64.231 | 66.301 | 69.501 | 73.091 | 76.624 | 74.792 | 79.678 | 2018.0 | . 2 Afghanistan | AFG | NGDPRPPPPCPCH | 512 | Gross domestic product per capita, constant pr... | GDP is expressed in constant international dol... | Purchasing power parity; percent change | NaN | Source: National Statistics Office Latest actu... | NaN | ... | 2.236 | -0.521 | -1.941 | -0.547 | 0.358 | 1.268 | 1.654 | -4.291 | 3.063 | 2018.0 | . 3 Afghanistan | AFG | PCPIPCH | 512 | Inflation, average consumer prices | Annual percentages of average consumer prices ... | Percent change | NaN | Source: National Statistics Office Latest actu... | NaN | ... | 7.386 | 4.674 | -0.662 | 4.384 | 4.976 | 0.626 | 2.302 | 4.711 | 4.451 | 2018.0 | . 4 Afghanistan | AFG | PCPIEPCH | 512 | Inflation, end of period consumer prices | Annual percentages of end of period consumer ... | Percent change | NaN | Source: National Statistics Office Latest actu... | NaN | ... | 7.241 | 1.487 | 1.131 | 4.588 | 3.041 | 0.755 | 2.773 | 4.5 | 5 | 2018.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1547 Zimbabwe | ZWE | PCPIPCH | 698 | Inflation, average consumer prices | Annual percentages of average consumer prices ... | Percent change | NaN | Source: National Statistics Office Latest actu... | NaN | ... | 1.632 | -0.213 | -2.41 | -1.558 | 0.907 | 10.607 | 255.292 | 319.036 | 3.7 | 2019.0 | . 1548 Zimbabwe | ZWE | PCPIEPCH | 698 | Inflation, end of period consumer prices | Annual percentages of end of period consumer ... | Percent change | NaN | Source: National Statistics Office Latest actu... | NaN | ... | 0.331 | -0.796 | -2.473 | -0.898 | 3.43 | 42.074 | 521.15 | 154.297 | 3 | 2019.0 | . 1549 Zimbabwe | ZWE | LUR | 698 | Unemployment rate | Unemployment rate can be defined by either the... | Percent of total labor force | NaN | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 1550 Zimbabwe | ZWE | GGXCNL_NGDP | 698 | General government net lending/borrowing | Net lending (+)/ borrowing (?) is calculated a... | Percent of GDP | NaN | Source: Ministry of Finance or Treasury Latest... | NaN | ... | -0.621 | -0.421 | -1.418 | -6.242 | -8.113 | -4.499 | -2.575 | -4.931 | -1.518 | 2018.0 | . 1551 Zimbabwe | ZWE | BCA_NGDPD | 698 | Current account balance | Current account is all transactions other than... | Percent of GDP | NaN | Source: Reserve Bank of Zimbabwe and Ministry ... | NaN | ... | -13.23 | -11.563 | -7.617 | -3.58 | -1.299 | -5.896 | 1.133 | -1.914 | -1.894 | 2018.0 | . 1552 rows × 52 columns . 이렇게 원하는 순서로 열을 배열해보았음 | . . Grouping . df_ur[&#39;Criteria&#39;]=0 . df_ur.loc[ df_ur[&#39;2021&#39;] &lt; 5 , &#39;Criteria&#39; ]=&#39;Low&#39; df_ur.loc[ (df_ur[&#39;2021&#39;] &gt;= 5) &amp; (df_ur[&#39;2021&#39;] &lt; 10) , &#39;Criteria&#39; ]=&#39;Medium&#39; # &amp;로 묶는 거 주의 df_ur.loc[ df_ur[&#39;2021&#39;] &gt;=10 , &#39;Criteria&#39; ]=&#39;High&#39; . df_ur.groupby([&#39;Criteria&#39;]).mean() . 2021 . Criteria . High 14.767680 | . Low 3.547000 | . Medium 7.100353 | . df_ur.groupby([&#39;Criteria&#39;]).mean().sort_values(&#39;2021&#39;) . 2021 . Criteria . Low 3.547000 | . Medium 7.100353 | . High 14.767680 | . df_ur.groupby([&#39;Criteria&#39;]).count() . Country 2021 . Criteria . High 25 | 25 | . Low 24 | 24 | . Medium 51 | 51 | . . 용량이 큰 csv 파일을 읽고 처리할 수 있는 방법 | . df_new=pd.DataFrame(columns=df.columns) df_new . WEO Country Code ISO WEO Subject Code Country Subject Descriptor Subject Notes Units Scale Country/Series-specific Notes 1980 ... 2013 2014 2015 2016 2017 2018 2019 2020 2021 Estimates Start After . 0 rows × 52 columns . for df_chunk in pd.read_csv(&#39;WEOApr2020all.csv&#39;,chunksize=5): temp=df_chunk.loc[df_chunk[&#39;Subject Descriptor&#39;]==&#39;Unemployment rate&#39;] df_new = pd.concat([df_new,temp]) . df_new . WEO Country Code ISO WEO Subject Code Country Subject Descriptor Subject Notes Units Scale Country/Series-specific Notes 1980 ... 2013 2014 2015 2016 2017 2018 2019 2020 2021 Estimates Start After . 5 512 | AFG | LUR | Afghanistan | Unemployment rate | Unemployment rate can be defined by either the... | Percent of total labor force | NaN | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 13 914 | ALB | LUR | Albania | Unemployment rate | Unemployment rate can be defined by either the... | Percent of total labor force | NaN | Source: National Statistics Office Latest actu... | 5.028 | ... | 15.9 | 17.5 | 17.1 | 15.2 | 13.7 | 12.3 | 12.0 | 11.8 | 11.5 | 2019 | . 21 612 | DZA | LUR | Algeria | Unemployment rate | Unemployment rate can be defined by either the... | Percent of total labor force | NaN | Source: National Statistics Office Latest actu... | 15.789 | ... | 9.829 | 10.6 | 11.214 | 10.498 | 11.709 | 11.731 | 11.383 | 15.091 | 13.909 | 2019 | . 29 614 | AGO | LUR | Angola | Unemployment rate | Unemployment rate can be defined by either the... | Percent of total labor force | NaN | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 37 311 | ATG | LUR | Antigua and Barbuda | Unemployment rate | Unemployment rate can be defined by either the... | Percent of total labor force | NaN | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 1517 299 | VEN | LUR | Venezuela | Unemployment rate | Unemployment rate can be defined by either the... | Percent of total labor force | NaN | Source: National Statistics Office Latest actu... | NaN | ... | 7.47 | 6.7 | 7.4 | 20.863 | 27.886 | 35.543 | NaN | NaN | NaN | 2011 | . 1525 582 | VNM | LUR | Vietnam | Unemployment rate | Unemployment rate can be defined by either the... | Percent of total labor force | NaN | Source: Other Latest actual data: 2019 Employm... | NaN | ... | 2.75 | 2.1 | 2.33 | 2.33 | 2.21 | 2.21 | 2.21 | NaN | NaN | 2019 | . 1533 474 | YEM | LUR | Yemen | Unemployment rate | Unemployment rate can be defined by either the... | Percent of total labor force | NaN | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 1541 754 | ZMB | LUR | Zambia | Unemployment rate | Unemployment rate can be defined by either the... | Percent of total labor force | NaN | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 1549 698 | ZWE | LUR | Zimbabwe | Unemployment rate | Unemployment rate can be defined by either the... | Percent of total labor force | NaN | NaN | NaN | ... | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | . 194 rows × 52 columns . . &#50620;&#44404; &#51064;&#49885; . import cv2 . img=cv2.imread(&#39;spurs_pic.jpg&#39;) plt.imshow(img) # BGR로 인식하기 때문에 RGB로 바꿔야 함 . &lt;matplotlib.image.AxesImage at 0x1a08fb6b4c0&gt; . rgb=cv2.cvtColor(img, cv2.COLOR_BGR2RGB) plt.imshow(rgb) . &lt;matplotlib.image.AxesImage at 0x1a08fbd5640&gt; . gray=cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY) plt.imshow(gray,cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x1a0905e15b0&gt; . classifier=cv2.CascadeClassifier(&#39;. haarcascades haarcascade_frontalface_default.xml&#39;) . 분류할 데이터가 정해졌음 . rects = classifier.detectMultiScale(gray,scaleFactor=1.2,minNeighbors=5) . print(&#39;Face found:{} &#39;.format(len(rects))) . Face found:11 . for x,y,w,h in rects: cv2.rectangle(rgb,(x,y),(x+w,y+h),(0,255,0),2) plt.imshow(rgb) . &lt;matplotlib.image.AxesImage at 0x1a090634430&gt; . #plt.imshow(rgb) . bgr=cv2.cvtColor(rgb,cv2.COLOR_RGB2BGR) cv2.imwrite(&#39;spurs_pic_faces.jpg&#39;,bgr) # 저장했음 . True .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2021/12/30/intro.html",
            "relUrl": "/2021/12/30/intro.html",
            "date": " • Dec 30, 2021"
        }
        
    
  
    
        ,"post25": {
            "title": "2021/12/29/WED",
            "content": "import matplotlib.pyplot as plt import matplotlib.cm as cm import numpy as np . height=4 width=5 depth=3 . m=np.zeros((height,width,depth)) . m . array([[[0., 0., 0.], [0., 0., 0.], [0., 0., 0.], [0., 0., 0.], [0., 0., 0.]], [[0., 0., 0.], [0., 0., 0.], [0., 0., 0.], [0., 0., 0.], [0., 0., 0.]], [[0., 0., 0.], [0., 0., 0.], [0., 0., 0.], [0., 0., 0.], [0., 0., 0.]], [[0., 0., 0.], [0., 0., 0.], [0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]]) . 4개의 row와 5개의 column 3개의 depth(각 column의) | 보기엔 그렇게 안 보이지만 첫 번째 블록을 쭉 펼치면 그게 1행인 거고(이런 행이 총 4개) 그 안에 5개의 열이 있고 한 열당 깊이가 3개다 | 다음 사진을 참고하자 | ref | | . plt.imshow(m) plt.grid() . 이미지의 시작은 좌측 상단임 | . m[:,:,0]=255 plt.imshow(m) plt.grid() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . m . array([[[255., 0., 0.], [255., 0., 0.], [255., 0., 0.], [255., 0., 0.], [255., 0., 0.]], [[255., 0., 0.], [255., 0., 0.], [255., 0., 0.], [255., 0., 0.], [255., 0., 0.]], [[255., 0., 0.], [255., 0., 0.], [255., 0., 0.], [255., 0., 0.], [255., 0., 0.]], [[255., 0., 0.], [255., 0., 0.], [255., 0., 0.], [255., 0., 0.], [255., 0., 0.]]]) . m=np.zeros((height,width,depth)) m[:,:,1]=255 plt.imshow(m) plt.grid() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . m . array([[[ 0., 255., 0.], [ 0., 255., 0.], [ 0., 255., 0.], [ 0., 255., 0.], [ 0., 255., 0.]], [[ 0., 255., 0.], [ 0., 255., 0.], [ 0., 255., 0.], [ 0., 255., 0.], [ 0., 255., 0.]], [[ 0., 255., 0.], [ 0., 255., 0.], [ 0., 255., 0.], [ 0., 255., 0.], [ 0., 255., 0.]], [[ 0., 255., 0.], [ 0., 255., 0.], [ 0., 255., 0.], [ 0., 255., 0.], [ 0., 255., 0.]]]) . m=np.zeros((height,width,depth)) m[:,:,2]=255 plt.imshow(m) plt.grid() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . m . array([[[ 0., 0., 255.], [ 0., 0., 255.], [ 0., 0., 255.], [ 0., 0., 255.], [ 0., 0., 255.]], [[ 0., 0., 255.], [ 0., 0., 255.], [ 0., 0., 255.], [ 0., 0., 255.], [ 0., 0., 255.]], [[ 0., 0., 255.], [ 0., 0., 255.], [ 0., 0., 255.], [ 0., 0., 255.], [ 0., 0., 255.]], [[ 0., 0., 255.], [ 0., 0., 255.], [ 0., 0., 255.], [ 0., 0., 255.], [ 0., 0., 255.]]]) . m=np.ones((height,width,depth)) plt.imshow(m) plt.grid() . m . array([[[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]], [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]], [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]], [[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]]) . m=np.zeros((height,width,depth)) plt.imshow(m) plt.grid() . m=np.zeros((height,width,depth)) m[0,:,:]=255 plt.imshow(m) plt.grid() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . m . array([[[255., 255., 255.], [255., 255., 255.], [255., 255., 255.], [255., 255., 255.], [255., 255., 255.]], [[ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]], [[ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]], [[ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]]]) . m=np.zeros((height,width,depth)) m[0,0,:]=255 plt.imshow(m) plt.grid() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . m # 1행 1열의 RGB를 모두 255 = 그래서 흰색이 나옴 . array([[[255., 255., 255.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]], [[ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]], [[ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]], [[ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]]]) . m=np.zeros((height,width,depth)) m[0,0,1]=255 plt.imshow(m) plt.grid() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . m=np.zeros((height,width,depth)) m[0,0,2]=255 plt.imshow(m) plt.grid() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . m=np.zeros((height,width,depth)) m[0,0,0]=255 plt.imshow(m) plt.grid() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . m=np.zeros((height,width,depth)) plt.imshow(m) plt.grid() . m=np.zeros((height,width,depth)) m[:,0,1]=255 plt.imshow(m) plt.grid() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . m . array([[[ 0., 255., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]], [[ 0., 255., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]], [[ 0., 255., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]], [[ 0., 255., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 0.]]]) . m[:,-2,2]=255 plt.imshow(m) plt.grid() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . m . array([[[ 0., 255., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 255.], [ 0., 0., 0.]], [[ 0., 255., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 255.], [ 0., 0., 0.]], [[ 0., 255., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 255.], [ 0., 0., 0.]], [[ 0., 255., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 255.], [ 0., 0., 0.]]]) . m[2,:,0]=255 m[2,:,1]=255 m[2,:,2]=0 plt.imshow(m) plt.grid() # R+G=노랑색 . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . 이미지를 세로로 두배 늘려보자 | . m_vt=np.vstack([m,m]) plt.imshow(m_vt) plt.grid() . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . 이미지를 가로로 두배 늘려보자 | . m_hz=np.hstack([m,m]) plt.imshow(m_hz) . Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). . &lt;matplotlib.image.AxesImage at 0x210807a93a0&gt; . 어둡게 해보자 . m_hz . array([[[ 0., 255., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 255.], [ 0., 0., 0.], [ 0., 255., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 255.], [ 0., 0., 0.]], [[ 0., 255., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 255.], [ 0., 0., 0.], [ 0., 255., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 255.], [ 0., 0., 0.]], [[255., 255., 0.], [255., 255., 0.], [255., 255., 0.], [255., 255., 0.], [255., 255., 0.], [255., 255., 0.], [255., 255., 0.], [255., 255., 0.], [255., 255., 0.], [255., 255., 0.]], [[ 0., 255., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 255.], [ 0., 0., 0.], [ 0., 255., 0.], [ 0., 0., 0.], [ 0., 0., 0.], [ 0., 0., 255.], [ 0., 0., 0.]]]) . m_hz=(m_hz/255)*0.5 plt.imshow(m_hz) . &lt;matplotlib.image.AxesImage at 0x210806facd0&gt; . m_hz . array([[[0. , 0.5, 0. ], [0. , 0. , 0. ], [0. , 0. , 0. ], [0. , 0. , 0.5], [0. , 0. , 0. ], [0. , 0.5, 0. ], [0. , 0. , 0. ], [0. , 0. , 0. ], [0. , 0. , 0.5], [0. , 0. , 0. ]], [[0. , 0.5, 0. ], [0. , 0. , 0. ], [0. , 0. , 0. ], [0. , 0. , 0.5], [0. , 0. , 0. ], [0. , 0.5, 0. ], [0. , 0. , 0. ], [0. , 0. , 0. ], [0. , 0. , 0.5], [0. , 0. , 0. ]], [[0.5, 0.5, 0. ], [0.5, 0.5, 0. ], [0.5, 0.5, 0. ], [0.5, 0.5, 0. ], [0.5, 0.5, 0. ], [0.5, 0.5, 0. ], [0.5, 0.5, 0. ], [0.5, 0.5, 0. ], [0.5, 0.5, 0. ], [0.5, 0.5, 0. ]], [[0. , 0.5, 0. ], [0. , 0. , 0. ], [0. , 0. , 0. ], [0. , 0. , 0.5], [0. , 0. , 0. ], [0. , 0.5, 0. ], [0. , 0. , 0. ], [0. , 0. , 0. ], [0. , 0. , 0.5], [0. , 0. , 0. ]]]) . m=np.zeros((5,5,3)) plt.imshow(m) . &lt;matplotlib.image.AxesImage at 0x21080617790&gt; . m[:,:,:]=1 plt.imshow(m) . &lt;matplotlib.image.AxesImage at 0x21080548310&gt; . m[:,:,:]=0 plt.imshow(m) . &lt;matplotlib.image.AxesImage at 0x21080405910&gt; . m[0::2,0::2,:]=1 plt.imshow(m) . &lt;matplotlib.image.AxesImage at 0x210803382e0&gt; . m[1::2,1::2,:]=1 plt.imshow(m) . &lt;matplotlib.image.AxesImage at 0x210801e9e80&gt; . 논리 연산을 사용해서 체크 무늬 만들어보자 | . n = m.copy() idx=np.where(n==1) n[idx]=0.5 plt.imshow(n) # 흰 부분만 어둡게 된 것을 알 수 있다. . &lt;matplotlib.image.AxesImage at 0x21080174d30&gt; . idx=np.where(n==0) n[idx]=1 plt.imshow(n) # 검정색 부분만 흰색으로 만들어줌 . &lt;matplotlib.image.AxesImage at 0x210805d6430&gt; . n=m.copy() plt.imshow(n) . &lt;matplotlib.image.AxesImage at 0x210805bf580&gt; . 컬러 뒤집기 | . idx1=np.where(n==1) idx2=np.where(n==0) n[idx1]=0 n[idx2]=1 plt.imshow(n) . &lt;matplotlib.image.AxesImage at 0x210805784f0&gt; . a=np.where(n==1) n[a[0],a[1],0]=0 n[a[0],a[1],2]=0 plt.imshow(n) . &lt;matplotlib.image.AxesImage at 0x2108073d0a0&gt; . a . (array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4], dtype=int64), array([1, 1, 1, 3, 3, 3, 0, 0, 0, 2, 2, 2, 4, 4, 4, 1, 1, 1, 3, 3, 3, 0, 0, 0, 2, 2, 2, 4, 4, 4, 1, 1, 1, 3, 3, 3], dtype=int64), array([0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2], dtype=int64)) . a[0] . array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4], dtype=int64) . a[1] . array([1, 1, 1, 3, 3, 3, 0, 0, 0, 2, 2, 2, 4, 4, 4, 1, 1, 1, 3, 3, 3, 0, 0, 0, 2, 2, 2, 4, 4, 4, 1, 1, 1, 3, 3, 3], dtype=int64) . 즉, a[0],a[1]은 각각 값이 1인 부분의 행 인덱싱 열 인덱싱을 의미함 | . plt.imshow(n) . &lt;matplotlib.image.AxesImage at 0x21080679ee0&gt; . 검정색 부분만 빨강으로 바꾸기 | . flag_r=(n[:,:,0]==0) flag_g=(n[:,:,1]==0) flag_b=(n[:,:,2]==0) flag_blk= flag_r&amp;flag_g&amp;flag_b idx_blk=np.where(flag_blk==True) n[idx_blk[0],idx_blk[1],0]=1 plt.imshow(n) . &lt;matplotlib.image.AxesImage at 0x21080305130&gt; . n=m.copy() plt.imshow(n) . &lt;matplotlib.image.AxesImage at 0x210805fe4f0&gt; . n . array([[[1., 1., 1.], [0., 0., 0.], [1., 1., 1.], [0., 0., 0.], [1., 1., 1.]], [[0., 0., 0.], [1., 1., 1.], [0., 0., 0.], [1., 1., 1.], [0., 0., 0.]], [[1., 1., 1.], [0., 0., 0.], [1., 1., 1.], [0., 0., 0.], [1., 1., 1.]], [[0., 0., 0.], [1., 1., 1.], [0., 0., 0.], [1., 1., 1.], [0., 0., 0.]], [[1., 1., 1.], [0., 0., 0.], [1., 1., 1.], [0., 0., 0.], [1., 1., 1.]]]) . print(np.sum(n,axis=0)) print(np.sum(n,axis=1)) print(np.sum(n,axis=2)) . [[3. 3. 3.] [2. 2. 2.] [3. 3. 3.] [2. 2. 2.] [3. 3. 3.]] [[3. 3. 3.] [2. 2. 2.] [3. 3. 3.] [2. 2. 2.] [3. 3. 3.]] [[3. 0. 3. 0. 3.] [0. 3. 0. 3. 0.] [3. 0. 3. 0. 3.] [0. 3. 0. 3. 0.] [3. 0. 3. 0. 3.]] . np.sum(n,aixs=?) | 해당 링크를 참조해보자 | . np_sum=np.sum(n,axis=2) # 색 찾기 idx_blk=np.where(np_sum==0) # 검정색인 부분만 찾는다. n[idx_blk[0],idx_blk[1],0]=1 # idx_blk[0],idx_blk[1] =&gt; 해당 위치를 알 수 있음 plt.imshow(n) . &lt;matplotlib.image.AxesImage at 0x21081876fd0&gt; . np.fill_diagonal(n[:,:,0],0) np.fill_diagonal(n[:,:,1],1) np.fill_diagonal(n[:,:,2],0) plt.imshow(n) . &lt;matplotlib.image.AxesImage at 0x210818d5bb0&gt; . m=np.linspace(0,1,10) # 1차원 m=m[:,np.newaxis] # 2차원 m=np.repeat(m,10,axis=1) plt.imshow(m,cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x210819d01c0&gt; . m . array([[0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ], [0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111, 0.11111111], [0.22222222, 0.22222222, 0.22222222, 0.22222222, 0.22222222, 0.22222222, 0.22222222, 0.22222222, 0.22222222, 0.22222222], [0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333], [0.44444444, 0.44444444, 0.44444444, 0.44444444, 0.44444444, 0.44444444, 0.44444444, 0.44444444, 0.44444444, 0.44444444], [0.55555556, 0.55555556, 0.55555556, 0.55555556, 0.55555556, 0.55555556, 0.55555556, 0.55555556, 0.55555556, 0.55555556], [0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667, 0.66666667], [0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.77777778, 0.77777778], [0.88888889, 0.88888889, 0.88888889, 0.88888889, 0.88888889, 0.88888889, 0.88888889, 0.88888889, 0.88888889, 0.88888889], [1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ]]) . m_tr=np.transpose(m) plt.imshow(m_tr,cmap=&#39;gray&#39;) . &lt;matplotlib.image.AxesImage at 0x21081a27520&gt; . m_tr=np.transpose(m) plt.imshow(m_tr,cmap=&#39;jet&#39;) . &lt;matplotlib.image.AxesImage at 0x21081a81a30&gt; . . LaTex 이용해보자 . $ begin{align} begin{cases} f(x) = frac{1}{10}x^2 &amp; text{ for } x in [0,1.5) f(x) = sum_{n=1,3,5..}^{N}{ frac{4}{ pi n} text{sin}( frac{2 pi n(x-1.5)}{T})}&amp; text{for} in[1.5,3] end{cases} end{align} $ . $ to$ 분할함수(Piecewise Function) . . x1=np.arange(0,1.5,0.0001) y1=1/10*x1**2 . x2=np.arange(1.5,3+0.01,0.0001) n= 5000 t=1 y2=np.zeros(x2.shape) for n in range(n): if n%2==1: series = 4/(np.pi*n)*np.sin((2*np.pi*n*(x2-1.5))/t) y2=y2+series . n이 커질수록 합이 커짐 . plt.plot(x1,y1) plt.plot(x2,y2) plt.xlabel(&#39;x&#39;) plt.ylabel(&#39;y&#39;) plt.title(&#39;Piecewise Functions&#39;) . Text(0.5, 1.0, &#39;Piecewise Functions&#39;) . . 세계 온도 변화 시각화 . import scipy import scipy.interpolate as interp import gzip import pickle as pkl . file=gzip.GzipFile(&#39;GlobalTemperatureData.pkl.gz&#39;,&#39;rb&#39;) df=pkl.load(file) file.close . &lt;bound method GzipFile.close of &lt;gzip _io.BufferedReader name=&#39;GlobalTemperatureData.pkl.gz&#39; 0x2108fee16a0&gt;&gt; . df.keys() . dict_keys([&#39;YR1881&#39;, &#39;YR1882&#39;, &#39;YR1883&#39;, &#39;YR1884&#39;, &#39;YR1885&#39;, &#39;YR1886&#39;, &#39;YR1887&#39;, &#39;YR1888&#39;, &#39;YR1889&#39;, &#39;YR1890&#39;, &#39;YR1891&#39;, &#39;YR1892&#39;, &#39;YR1893&#39;, &#39;YR1894&#39;, &#39;YR1895&#39;, &#39;YR1896&#39;, &#39;YR1897&#39;, &#39;YR1898&#39;, &#39;YR1899&#39;, &#39;YR1900&#39;, &#39;YR1901&#39;, &#39;YR1902&#39;, &#39;YR1903&#39;, &#39;YR1904&#39;, &#39;YR1905&#39;, &#39;YR1906&#39;, &#39;YR1907&#39;, &#39;YR1908&#39;, &#39;YR1909&#39;, &#39;YR1910&#39;, &#39;YR1911&#39;, &#39;YR1912&#39;, &#39;YR1913&#39;, &#39;YR1914&#39;, &#39;YR1915&#39;, &#39;YR1916&#39;, &#39;YR1917&#39;, &#39;YR1918&#39;, &#39;YR1919&#39;, &#39;YR1920&#39;, &#39;YR1921&#39;, &#39;YR1922&#39;, &#39;YR1923&#39;, &#39;YR1924&#39;, &#39;YR1925&#39;, &#39;YR1926&#39;, &#39;YR1927&#39;, &#39;YR1928&#39;, &#39;YR1929&#39;, &#39;YR1930&#39;, &#39;YR1931&#39;, &#39;YR1932&#39;, &#39;YR1933&#39;, &#39;YR1934&#39;, &#39;YR1935&#39;, &#39;YR1936&#39;, &#39;YR1937&#39;, &#39;YR1938&#39;, &#39;YR1939&#39;, &#39;YR1940&#39;, &#39;YR1941&#39;, &#39;YR1942&#39;, &#39;YR1943&#39;, &#39;YR1944&#39;, &#39;YR1945&#39;, &#39;YR1946&#39;, &#39;YR1947&#39;, &#39;YR1948&#39;, &#39;YR1949&#39;, &#39;YR1950&#39;, &#39;YR1951&#39;, &#39;YR1952&#39;, &#39;YR1953&#39;, &#39;YR1954&#39;, &#39;YR1955&#39;, &#39;YR1956&#39;, &#39;YR1957&#39;, &#39;YR1958&#39;, &#39;YR1959&#39;, &#39;YR1960&#39;, &#39;YR1961&#39;, &#39;YR1962&#39;, &#39;YR1963&#39;, &#39;YR1964&#39;, &#39;YR1965&#39;, &#39;YR1966&#39;, &#39;YR1967&#39;, &#39;YR1968&#39;, &#39;YR1969&#39;, &#39;YR1970&#39;, &#39;YR1971&#39;, &#39;YR1972&#39;, &#39;YR1973&#39;, &#39;YR1974&#39;, &#39;YR1975&#39;, &#39;YR1976&#39;, &#39;YR1977&#39;, &#39;YR1978&#39;, &#39;YR1979&#39;, &#39;YR1980&#39;, &#39;YR1981&#39;, &#39;YR1982&#39;, &#39;YR1983&#39;, &#39;YR1984&#39;, &#39;YR1985&#39;, &#39;YR1986&#39;, &#39;YR1987&#39;, &#39;YR1988&#39;, &#39;YR1989&#39;, &#39;YR1990&#39;, &#39;YR1991&#39;, &#39;YR1992&#39;, &#39;YR1993&#39;, &#39;YR1994&#39;, &#39;YR1995&#39;, &#39;YR1996&#39;, &#39;YR1997&#39;, &#39;YR1998&#39;, &#39;YR1999&#39;, &#39;YR2000&#39;, &#39;YR2001&#39;, &#39;YR2002&#39;, &#39;YR2003&#39;, &#39;YR2004&#39;, &#39;YR2005&#39;, &#39;YR2006&#39;, &#39;YR2007&#39;, &#39;YR2008&#39;, &#39;YR2009&#39;, &#39;YR2010&#39;, &#39;YR2011&#39;, &#39;YR2012&#39;, &#39;YR2013&#39;, &#39;YR2014&#39;, &#39;YR2015&#39;, &#39;YR2016&#39;, &#39;YR2017&#39;, &#39;YR2018&#39;, &#39;YR2019&#39;]) . 연도별로 세계온도가 들어가있음 . yr=list(df.keys()) . iyr=10 df_yr=df[yr[iyr]] . df_yr . i j lon lat Temperature(i,j) . 0 1 | 1 | -179 | -89 | 9999.0 | . 1 2 | 1 | -177 | -89 | 9999.0 | . 2 3 | 1 | -175 | -89 | 9999.0 | . 3 4 | 1 | -173 | -89 | 9999.0 | . 4 5 | 1 | -171 | -89 | 9999.0 | . ... ... | ... | ... | ... | ... | . 16195 176 | 90 | 171 | 89 | 9999.0 | . 16196 177 | 90 | 173 | 89 | 9999.0 | . 16197 178 | 90 | 175 | 89 | 9999.0 | . 16198 179 | 90 | 177 | 89 | 9999.0 | . 16199 180 | 90 | 179 | 89 | 9999.0 | . 16200 rows × 5 columns . df_yr.keys() . Index([&#39;i&#39;, &#39;j&#39;, &#39;lon&#39;, &#39;lat&#39;, &#39;Temperature(i,j)&#39;], dtype=&#39;object&#39;) . 위도, 경도, 온도만 발췌하여 numpy_array로 변형해보자 . 원래는 dict 형태였음 . df_yr[[&#39;lon&#39;,&#39;lat&#39;,&#39;Temperature(i,j)&#39;]] . lon lat Temperature(i,j) . 0 -179 | -89 | 9999.0 | . 1 -177 | -89 | 9999.0 | . 2 -175 | -89 | 9999.0 | . 3 -173 | -89 | 9999.0 | . 4 -171 | -89 | 9999.0 | . ... ... | ... | ... | . 16195 171 | 89 | 9999.0 | . 16196 173 | 89 | 9999.0 | . 16197 175 | 89 | 9999.0 | . 16198 177 | 89 | 9999.0 | . 16199 179 | 89 | 9999.0 | . 16200 rows × 3 columns . to_numpy() | . data=df_yr[[&#39;lon&#39;,&#39;lat&#39;,&#39;Temperature(i,j)&#39;]].to_numpy() . data . array([[-179., -89., 9999.], [-177., -89., 9999.], [-175., -89., 9999.], ..., [ 175., 89., 9999.], [ 177., 89., 9999.], [ 179., 89., 9999.]]) . data[np.where(data&gt;9999)]=np.nan . 9999를 nan으로 바꾼 이유는 자동으로 plot이 안 되게 하기 위해서 . x=np.linspace(-180,180,100) y=np.linspace(-90,90,100) grid_x,grid_y=np.meshgrid(x,y) . data_interp=interp.griddata(data[:,[0,1]],data[:,2],(grid_x,grid_y),method=&#39;linear&#39;) . . hfig,hax=plt.subplots() im=plt.imread(&#39;world_map.png&#39;) plt.imshow(im) . &lt;matplotlib.image.AxesImage at 0x21090f0a3a0&gt; . 좌표축의 중심을 왼쪽 아래로 . 그런데 지도까지 뒤집혀버림 . hfig,hax=plt.subplots() im=plt.imread(&#39;world_map.png&#39;) plt.imshow(im,origin=&#39;lower&#39;) . &lt;matplotlib.image.AxesImage at 0x2108feffa00&gt; . 다시 지도만 뒤집어줌 . hfig,hax=plt.subplots() im=plt.imread(&#39;world_map.png&#39;) plt.imshow(np.flipud(im),origin=&#39;lower&#39;) . &lt;matplotlib.image.AxesImage at 0x21096ed8340&gt; . size 조정 . hfig,hax=plt.subplots() im=plt.imread(&#39;world_map.png&#39;) plt.imshow(np.flipud(im),origin=&#39;lower&#39;,extent=(0,800,0,400)) . &lt;matplotlib.image.AxesImage at 0x2108edf4400&gt; . hfig,hax=plt.subplots() im=plt.imread(&#39;world_map.png&#39;) plt.imshow(np.flipud(im),origin=&#39;lower&#39;,extent=(-180,180,-90,90)) plt.pcolormesh(grid_x,grid_y,data_interp,cmap=&#39;coolwarm&#39;,alpha=0.6) plt.xlim(-180,180) plt.ylim(-90,90) plt.title(&#39;global temperature change from ty1880 to&#39;+str(yr[iyr])) plt.xlabel(&#39;Altitude&#39;) plt.xlabel(&#39;Latitude&#39;) plt.colorbar(fraction=0.022,pad=0.05) plt.clim(-4,4) . C: Users ehfus AppData Local Temp/ipykernel_17584/3478053917.py:4: MatplotlibDeprecationWarning: shading=&#39;flat&#39; when X and Y have the same dimensions as C is deprecated since 3.3. Either specify the corners of the quadrilaterals with X and Y, or pass shading=&#39;auto&#39;, &#39;nearest&#39; or &#39;gouraud&#39;, or set rcParams[&#39;pcolor.shading&#39;]. This will become an error two minor releases later. plt.pcolormesh(grid_x,grid_y,data_interp,cmap=&#39;coolwarm&#39;,alpha=0.6) .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2021/12/29/intro.html",
            "relUrl": "/2021/12/29/intro.html",
            "date": " • Dec 29, 2021"
        }
        
    
  
    
        ,"post26": {
            "title": "2021/12/28/TUE",
            "content": "Function . def f() : pass . . def f() : print(&#39;Hello&#39;) . f() . Hello . . def f_(x) : print(&#39;Hello&#39; + str(x)) . y=f_(5555) . Hello5555 . y . type(y) . NoneType . 아무것도 안 나옴 | output이 없는 함수이기 때문에 | output이 있는 함수를 만들어보자 | . def fn(x) : y=x+10 return y # OUTPUT . y=fn(3) . y . 13 . type(y) . int . return이라는 output이 생김 | . out=fn(123) . print(out) . 133 . out . 133 . . local &amp; global . # global 변수 y=5 . def fn(x) : y=x+10 print(&#39;함수 안에 있는 변수, y=&#39; + str(y)) return y # local 변수 # output . fn(2) . 함수 안에 있는 변수, y=12 . 12 . print(&#39;함수 밖에 있는 변수, y=&#39; + str(y)) . 함수 밖에 있는 변수, y=5 . . def d_is_10(): d=10 print(&#39;d 값은&#39;,d,&#39;이다&#39;) . d_is_10() . d 값은 10 이다 . . d는 d_is_10이라는 함수에서만 정의해준 지역변수이기에 함수 밖에서 d를 호출하면 반환되지 않음 . 반대로 전역변수는 언제든지 함수 안으로 끌고 들어와 지역변수로서 사용할 수 있음 . x=10 # global variable def printx(): print(x) printx() # output 없음 . 10 . 함수 안에서 전역변수를 만들 수 있음 . 즉 local을 local로도 사용하고 global로도 사용해보자 . def e_is_12(): # e라는 변수를 사용할 건데 함수 안에서 정의해주지만 , 전역변수로도 사용할 것이다라고 명해줌 global e # 이때 e는 지역변수로도, 전역변수로도 사용하겠다. e=12 print(&#39;e값은 여기서 불러도&#39;,e,&#39;로 불러와지고&#39;) e_is_12() . e값은 여기서 불러도 12 로 불러와지고 . print(&#39;함수 밖인 여기서 불러도&#39;,&#39;e는&#39;, e ,&#39;로 불러와진다&#39;) . 함수 밖인 여기서 불러도 e는 12 로 불러와진다 . e . 12 . . def f2(x): return x+10 . f2(3) . 13 . . input을 지정 안 하고 함수가 알아서 지정할 수 있게 할 수 있음 | . def f2(x=5): return x+10 . f2() . 15 . f2(40) # 함수 만들 때 지정해준 변수 값을 수정하여 input을 다시 줄 순 있음 . 50 . . def f3(x1,x2): return x1+x2 . f3(3,5) . 8 . . def f4(name,age=0,lan=&#39;NONE&#39;): print(name+&#39; &#39;+str(age)+&#39; &#39;+lan) # age와 lan은 미리 지정해줌으로서 초기화해놓았다고 생각해놓으면 됨 . f4(&#39;rhkrehtjd&#39;) # 이렇게 나이와 lan을 입력 안 해도 함수 만들 때 미리 지정해주고 시작해도 됨 . rhkrehtjd 0 NONE . f4(&#39;rhkrehtjd&#39;,2,&#39;R&#39;) # 그런데 입력값이 생겼을 땐 그 입력값을 사용할 수 있음 . rhkrehtjd 2 R . 순서를 바꿔 쓴다면? | . f4(&#39;rhkrehtjd&#39;,lan=&#39;python&#39;,age=123) . rhkrehtjd 123 python . 이렇게 순서 바꿔쓸거면 keyword만 제대로 명시해주자 . | 그런데 이렇게 순서 바꿔쓸 수 있는건 초기화로 설정된 변수에서만 사용가능함 . | 즉 이 함수 f4에선 age하고 lan만 초기화 상태로 명했고 name은 초기화해놓지 않았기 때문에 name은 그 자리에서 input해줘야 함 . | . . def ff(*x): print(x) . ff(&#39;abc&#39;,&#39;asd&#39;,&#39;qgeqve&#39;,&#39;asdasdf&#39;) . (&#39;abc&#39;, &#39;asd&#39;, &#39;qgeqve&#39;, &#39;asdasdf&#39;) . 이렇게 input이 몇개가 들어와도 해결이 가능함 | . def fff(*x): for a in x: print(a) . fff(&#39;asd&#39;,&#39;asdqw&#39;,&#39;qwg&#39;) . asd asdqw qwg . . 이런식으로 input을 몇개주더라도 그 input을 다 더해주는 함수 . def qq(*args): total = 0 for a in args: total += a return total . qq(12,12,34) . 58 . . def cc(*x): com=&#39;&#39; for a in x: com +=a return com . cc(&#39;pt&#39;,&#39;Rhkrehtjd&#39;) . &#39;ptRhkrehtjd&#39; . . a=[10,15] list(range(a[0],a[1]+1)) . [10, 11, 12, 13, 14, 15] . a[1]+=1 . a . [10, 16] . # 박스를 펼치는 것처럼 arguements를 하나로 받아서 펼치는! list(range(*a)) . [10, 11, 12, 13, 14, 15] . . def qq(): num_s=int(input(&#39;Start num: &#39;)) num_e=int(input(&#39;End num: &#39;)) num_inc=int(input(&#39;Increment: &#39;)) out_list=list(range(num_s,num_e+1,num_inc)) return out_list . qq() . [55, 709] . 입력 세번을 한 번에 할 수 있게 해보자 | . a=input() . a . &#39;5 6 8&#39; . a[1] . &#39; &#39; . input은 입력해주는대로 str으로 만들어서 반환해줌 | 즉 만약 내가 3 2 1이렇게 입력해주면 총 7개의 원소가 str안에 들어가고 | 내가 3 1 2 이렇게 입력해주면 총 5개의 원소가 str안에 들어가게 된다. | 그렇다면 내가 3,1,2 이렇게 입력해주면 콤마까지도 하나의 원소로서 들어가면서 총 5개의 원소가 str으로 입력되게 된다. | . def qq2(): print(&#39;숫자를 다음과 같이 입력해주세요 &#39;) print(&#39;시작: ,끝: ,증가단위: &#39;) print(&#39;예시: 0,5,1&#39;) ui=input(&#39;자, 이제 알려줬으니 한 번 입력해봐여: &#39;) ui_list=[int(i) for i in ui.split(&#39;,&#39;)] # ,기준으로 나눈다음(콤마는 없앰) 각각을 list의 하나의 원소로서 반환시켜준다. out_list=list(range(*ui_list)) return out_list . qq2 () . 숫자를 다음과 같이 입력해주세요 시작: ,끝: ,증가단위: 예시: 0,5,1 . [5, 7, 9] . 만약 마지막 숫자도 포함하고 싶다면? | . def qq2(): print(&#39;숫자를 다음과 같이 입력해주세요 &#39;) print(&#39;시작: ,끝: ,증가단위: &#39;) print(&#39;예시: 0,5,1&#39;) ui=input(&#39;입력해주세요: &#39;) ui_list=[int(i)for i in ui.split(&#39;,&#39;)] ui_list[1]+=1 out_list=list(range(*ui_list)) return out_list . qq2() . 숫자를 다음과 같이 입력해주세요 시작: ,끝: ,증가단위: 예시: 0,5,1 . [5, 10, 15, 20, 25] . . documentation $ to$ 함수에 도움말을 넣어보자 | . def qw(x): &quot;&quot;&quot; 여기가 함수의 도움말 &quot;&quot;&quot; return x+10 . qw? . Signature: qw(x) Docstring: 여기가 함수의 도움말 File: c: users ehfus appdata local temp ipykernel_13032 1023470262.py Type: function . help(qw) . Help on function qw in module __main__: qw(x) 여기가 함수의 도움말 . print(qw.__doc__) . 여기가 함수의 도움말 . . annotation :사용방법 달아주기, input이 들어올 때 어떤 형식으로 들어와야 하는지 주석을 달아준다고 생각하면 됨 . def fu(num): out=num+10 return out . print(fu.__annotations__) . {} . def fu(num:int): out=num+10 return out . print(fu.__annotations__) . {&#39;num&#39;: &lt;class &#39;int&#39;&gt;} . def fu(num:int)-&gt;int: out=num+10 return out . print(fu.__annotations__) . {&#39;num&#39;: &lt;class &#39;int&#39;&gt;, &#39;return&#39;: &lt;class &#39;int&#39;&gt;} . 이렇게 output의 자료형도 주석을 달듯이 알려줄 수가 있음 . . lambda . add_one = lambda x: x+1 . add_one이라는 함수를 만들어줬다고 생각하면 됨 | . add_one(1) # output이 있음 . 2 . (lambda x:x+1)(10) # lambda를 사용할 때 이렇게 한 줄로 함수와 입력을 동시에 명해줄 수가 있음 . 11 . . def a(x): return x+10 . high_ord_function=lambda x: x+a(x) . high_ord_function(2) . 14 . . high_ord_function=lambda x, ff : x+ff(x) . high_ord_function(2,lambda x:x+1) . 5 . high_ord_function(2,lambda x:x-1) . 3 . 이런식으로 lmabda를 사용하게 되면 실시간으로 함수자체를 input으로 줘서 고차원 함수를 사용할 수 있게 됨 | . . map . import numpy as np a=np.array([1,2,3,4,5]) a*2 . array([ 2, 4, 6, 8, 10]) . a=[1,2,3,4,5] a*2 # numpy에서의 결과처럼 list도 활용하고 싶다. # map을 활용한다. . [1, 2, 3, 4, 5, 1, 2, 3, 4, 5] . list(map(lambda x: x*2,[1,2,3])) . [2, 4, 6] . map은 list전체에 함수를 적용하는 게 아니라 map의 각 원소 각각에 함수를 적용해주는 것 같음 | 그렇다면 아래와 같이도 활용할 수 있겠다. | . . vip=&#39;rhkrehtjd&#39; print(vip.upper()) print(vip.capitalize()) . RHKREHTJD Rhkrehtjd . vip_list=[&#39;adqw&#39;,&#39;wfdf&#39;,&#39;sdgv&#39;] . vip_list는 list이기 때문에 upper라는 함수를 지원하지 않음 | upper는 문자열에서 지원하는 함수 | 따라서 vip_list안에 있는 str은 upper라는 함수를 사용할 수 있음 | . print(list(map(lambda x: x.upper() ,vip_list))) print(list(map(lambda x: x.capitalize() ,vip_list))) . [&#39;ADQW&#39;, &#39;WFDF&#39;, &#39;SDGV&#39;] [&#39;Adqw&#39;, &#39;Wfdf&#39;, &#39;Sdgv&#39;] . . len(vip_list) . 3 . 이건 list를 전체적인 관점에서 보고 원소가 몇개 들어있는지 알려주는 것 | . vip_list_name_len_list=list(map(lambda x:len(x), vip_list)) . vip_list_name_len_list . [4, 4, 4] . map이 list전체가 아니라 그 안으로 들어가서 적용함을 알 수 있다. | . . !중요! filter . BOOL형이 활용된다고 생각하면 될 것 같다. | . vip_list . [&#39;adqw&#39;, &#39;wfdf&#39;, &#39;sdgv&#39;] . list(filter(lambda x: &#39;P&#39; in x, vip_list)) . [] . 해당되지 않아서 빈 list가 나왔음 . list(filter(lambda x: &#39;a&#39; in x, vip_list)) . [&#39;adqw&#39;] . x=[1,2,3,4,5] list(filter(lambda x: x%2==0,x)) . [2, 4] . list(filter(lambda x: x%2!=0,x)) . [1, 3, 5] . . reduce . from functools import reduce . list_=[10,20,30] . def add(x,y): return x+y . reduce(add,list_) . 60 . reduce(lambda a,b : a+b,list_) . 60 . sum(list_) . 60 . . strlist=[&#39;p&#39;,&#39;y&#39;,&#39;t&#39;,&#39;h&#39;,&#39;o&#39;,&#39;n&#39;,] . reduce(lambda x,y:x+y,strlist) . &#39;python&#39; . . for문 $vs$ list comprehension $vs$ lambda function . letter_list=[] for letter in &#39;python&#39;: letter_list.append(letter) print(letter_list) . [&#39;p&#39;, &#39;y&#39;, &#39;t&#39;, &#39;h&#39;, &#39;o&#39;, &#39;n&#39;] . letter_list_2=[letter for letter in &#39;python&#39;] letter_list_2 . [&#39;p&#39;, &#39;y&#39;, &#39;t&#39;, &#39;h&#39;, &#39;o&#39;, &#39;n&#39;] . list(map(lambda x : x, &#39;python&#39;)) # 각 원소에 적용됨을 알 수 있다. . [&#39;p&#39;, &#39;y&#39;, &#39;t&#39;, &#39;h&#39;, &#39;o&#39;, &#39;n&#39;] . . a,b=0,1 . a . 0 . b . 1 . 이렇게 변수 두개를 한 번에 저장해줄 수 있음 (tuple을 만드는 게 아님) . . def my_fib_seq(n): a,b=0,1 seq=[a,b] for i in range(n-2): # 이미 0,1은 있으니까 -2해줌 a,b=b,a+b seq.append(b) return seq . my_fib_seq(3) . [0, 1, 1] . def my_powers(number): return number,number**2,number**3 . a=my_powers(2) . a . (2, 4, 8) . list(a) . [2, 4, 8] . . number,square,cube=my_powers(2) . cube만 필요하다? . *_, cube=my_powers(2) . cube . 8 . _ . [2, 4] . 이렇게 unpacking할 수도 있음 . . def my_sum(num_list): total = 0 for num in num_list: total+=num return total . my_sum([1,2,3]) . 6 . def my_mean(num_list): s=my_sum(num_list) # 바로 위 셀에서 정의해준 function N=len(num_list) return s/N . my_mean([8,10]) . 9.0 .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2021/12/28/intro.html",
            "relUrl": "/2021/12/28/intro.html",
            "date": " • Dec 28, 2021"
        }
        
    
  
    
        ,"post27": {
            "title": "2021/12/26/SUN",
            "content": "import numpy as np import pandas as pd from openpyxl import load_workbook . data = {&#39;Name&#39; : [&#39;S1&#39;,&#39;S2&#39;,&#39;S3&#39;], &#39;Age&#39; : [25,28,22], &#39;Score&#39; : np.array([95,80,75])} . data . {&#39;Name&#39;: [&#39;S1&#39;, &#39;S2&#39;, &#39;S3&#39;], &#39;Age&#39;: [25, 28, 22], &#39;Score&#39;: array([95, 80, 75])} . type(data) . dict . data[&#39;Name&#39;] . [&#39;S1&#39;, &#39;S2&#39;, &#39;S3&#39;] . df=pd.DataFrame(data,index=[&#39;row1&#39;,&#39;row2&#39;,&#39;row3&#39;]) df . Name Age Score . row1 S1 | 25 | 95 | . row2 S2 | 28 | 80 | . row3 S3 | 22 | 75 | . 리스트도 df로 변경 가능 | . data2=[[&#39;S1&#39;,25,95],[&#39;S2&#39;,28,80],[&#39;S3&#39;,22,75]] . data2 . [[&#39;S1&#39;, 25, 95], [&#39;S2&#39;, 28, 80], [&#39;S3&#39;, 22, 75]] . df2=pd.DataFrame(data2,index=[&#39;row1&#39;,&#39;row2&#39;,&#39;row3&#39;],columns=[&#39;Name&#39;,&#39;Age&#39;,&#39;Score&#39;]) . df2 . Name Age Score . row1 S1 | 25 | 95 | . row2 S2 | 28 | 80 | . row3 S3 | 22 | 75 | . 결론 : list와 dict은 df로 반환시킬 수 있다. | . . Subset Observation 부분 관찰해보자 | . df . Name Age Score . row1 S1 | 25 | 95 | . row2 S2 | 28 | 80 | . row3 S3 | 22 | 75 | . df[[&#39;Name&#39;]] . Name . row1 S1 | . row2 S2 | . row3 S3 | . df[&#39;Name&#39;] . row1 S1 row2 S2 row3 S3 Name: Name, dtype: object . df[[&#39;Name&#39;,&#39;Score&#39;]] # 이렇게 list안에 넣어줘야 함 . Name Score . row1 S1 | 95 | . row2 S2 | 80 | . row3 S3 | 75 | . # 행은 이렇게 추출할 수 없음 . 그렇다면 행 추출은? . df.loc[[&#39;row1&#39;]] . Name Age Score . row1 S1 | 25 | 95 | . df.loc[&#39;row1&#39;] . Name S1 Age 25 Score 95 Name: row1, dtype: object . df.loc[[&#39;row1&#39;,&#39;row2&#39;]] . Name Age Score . row1 S1 | 25 | 95 | . row2 S2 | 28 | 80 | . df.loc[&#39;row1&#39;,&#39;Name&#39;] . &#39;S1&#39; . df[&#39;Name&#39;] . row1 S1 row2 S2 row3 S3 Name: Name, dtype: object . 사용하고 싶다면 이렇게 사용 | . df.loc[:,&#39;Name&#39;] . row1 S1 row2 S2 row3 S3 Name: Name, dtype: object . df.loc[:,[&#39;Name&#39;]] . Name . row1 S1 | . row2 S2 | . row3 S3 | . df.loc[:,[&#39;Score&#39;,&#39;Name&#39;]] . Score Name . row1 95 | S1 | . row2 80 | S2 | . row3 75 | S3 | . df.loc[:,&#39;Name&#39;:&#39;Age&#39;] . Name Age . row1 S1 | 25 | . row2 S2 | 28 | . row3 S3 | 22 | . df.iloc[0,0] . &#39;S1&#39; . df.iloc[2,0] . &#39;S3&#39; . df.iloc[:,[0,2]] . Name Score . row1 S1 | 95 | . row2 S2 | 80 | . row3 S3 | 75 | . df.iloc[:,0:2] . Name Age . row1 S1 | 25 | . row2 S2 | 28 | . row3 S3 | 22 | . df.iloc[::2,[0,2]] . Name Score . row1 S1 | 95 | . row3 S3 | 75 | . df.iloc[[-1],:] . Name Age Score . row3 S3 | 22 | 75 | . df.iloc[-1,:] . Name S3 Age 22 Score 75 Name: row3, dtype: object . df . Name Age Score . row1 S1 | 25 | 95 | . row2 S2 | 28 | 80 | . row3 S3 | 22 | 75 | . df.iloc[-1::-1,:] . Name Age Score . row3 S3 | 22 | 75 | . row2 S2 | 28 | 80 | . row1 S1 | 25 | 95 | . df.head(2) . Name Age Score . row1 S1 | 25 | 95 | . row2 S2 | 28 | 80 | . df.tail(1) . Name Age Score . row3 S3 | 22 | 75 | . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Index: 3 entries, row1 to row3 Data columns (total 3 columns): # Column Non-Null Count Dtype -- -- 0 Name 3 non-null object 1 Age 3 non-null int64 2 Score 3 non-null int32 dtypes: int32(1), int64(1), object(1) memory usage: 192.0+ bytes . df.describe() # 통계적 수치들을 알 수 있음 . Age Score . count 3.0 | 3.000000 | . mean 25.0 | 83.333333 | . std 3.0 | 10.408330 | . min 22.0 | 75.000000 | . 25% 23.5 | 77.500000 | . 50% 25.0 | 80.000000 | . 75% 26.5 | 87.500000 | . max 28.0 | 95.000000 | . deep copy $ to$ copy | shallow copy $ to$ view | . df2=df.copy() . df2 . Name Age Score . row1 S1 | 25 | 95 | . row2 S2 | 28 | 80 | . row3 S3 | 22 | 75 | . df2.loc[&#39;row2&#39;,&#39;Score&#39;]=np.NaN . df2 . Name Age Score . row1 S1 | 25 | 95.0 | . row2 S2 | 28 | NaN | . row3 S3 | 22 | 75.0 | . df . Name Age Score . row1 S1 | 25 | 95 | . row2 S2 | 28 | 80 | . row3 S3 | 22 | 75 | . deep copy . df2.nunique() . Name 3 Age 3 Score 2 dtype: int64 . df2[&#39;Score&#39;].nunique() . 2 . df2 . Name Age Score . row1 S1 | 25 | 95.0 | . row2 S2 | 28 | NaN | . row3 S3 | 22 | 75.0 | . df2[&#39;Score&#39;].value_counts() # 각 값들의 갯수를 알 수 있음 . 95.0 1 75.0 1 Name: Score, dtype: int64 . df3=df2.copy() df3.loc[&#39;row3&#39;,&#39;Score&#39;]=df2.loc[&#39;row1&#39;,&#39;Score&#39;] . df3[&#39;Score&#39;].value_counts() . 95.0 2 Name: Score, dtype: int64 . df3[&#39;Score&#39;].count() . 2 . value_counts() = 각 값 별 몇 개? | count = 그냥 총 값이 몇 개 들어가 있는지? | . df3[&#39;Age&#39;].count() . 3 . df[&#39;Score&#39;].sum() . 250 . df.max() . Name S3 Age 28 Score 95 dtype: object . df[&#39;Score&#39;].std() . 10.408329997330664 . df.describe() . Age Score . count 3.0 | 3.000000 | . mean 25.0 | 83.333333 | . std 3.0 | 10.408330 | . min 22.0 | 75.000000 | . 25% 23.5 | 77.500000 | . 50% 25.0 | 80.000000 | . 75% 26.5 | 87.500000 | . max 28.0 | 95.000000 | . . df4=df.copy() . df4 . Name Age Score . row1 S1 | 25 | 95 | . row2 S2 | 28 | 80 | . row3 S3 | 22 | 75 | . df4=df4.iloc[:,[0,2,1]] . df4 . Name Age Score . row1 S1 | 25 | 95 | . row2 S2 | 28 | 80 | . row3 S3 | 22 | 75 | . df의 열을 변경해서 df4에 저장 . data={ &#39;class&#39; : [&#39;A&#39;,&#39;B&#39;,&#39;C&#39;,&#39;A&#39;,&#39;B&#39;,&#39;C&#39;,&#39;C&#39;], &#39;name&#39; : [&#39;S1&#39;,&#39;S2&#39;,&#39;S3&#39;,&#39;S4&#39;,&#39;S5&#39;,&#39;S6&#39;,&#39;S7&#39;], &#39;age&#39; : [20,19,21,22,24,25,26], &#39;score&#39; : [90,95,75,80,70,85,90]} . df=pd.DataFrame(data) df . class name age score . 0 A | S1 | 20 | 90 | . 1 B | S2 | 19 | 95 | . 2 C | S3 | 21 | 75 | . 3 A | S4 | 22 | 80 | . 4 B | S5 | 24 | 70 | . 5 C | S6 | 25 | 85 | . 6 C | S7 | 26 | 90 | . 이처럼 dict을 df에 활용할 수 있다. | . df[&#39;score&#39;]&gt;=80 . 0 True 1 True 2 False 3 True 4 False 5 True 6 True Name: score, dtype: bool . df.loc[df[&#39;score&#39;]&gt;=80] . class name age score . 0 A | S1 | 20 | 90 | . 1 B | S2 | 19 | 95 | . 3 A | S4 | 22 | 80 | . 5 C | S6 | 25 | 85 | . 6 C | S7 | 26 | 90 | . df.loc[df[&#39;score&#39;]&gt;=80,[&#39;name&#39;,&#39;age&#39;]] . name age . 0 S1 | 20 | . 1 S2 | 19 | . 3 S4 | 22 | . 5 S6 | 25 | . 6 S7 | 26 | . df[df[&#39;score&#39;]&gt;=80] . class name age score . 0 A | S1 | 20 | 90 | . 1 B | S2 | 19 | 95 | . 3 A | S4 | 22 | 80 | . 5 C | S6 | 25 | 85 | . 6 C | S7 | 26 | 90 | . df[&#39;result&#39;]=&#39;NONE&#39; . df . class name age score result . 0 A | S1 | 20 | 90 | NONE | . 1 B | S2 | 19 | 95 | NONE | . 2 C | S3 | 21 | 75 | NONE | . 3 A | S4 | 22 | 80 | NONE | . 4 B | S5 | 24 | 70 | NONE | . 5 C | S6 | 25 | 85 | NONE | . 6 C | S7 | 26 | 90 | NONE | . df.loc[df[&#39;score&#39;]&gt;=80,&#39;result&#39;]=&#39;PASS&#39; . df.loc[df[&#39;score&#39;]&lt;80,&#39;result&#39;]=&#39;FAIL&#39; . df . class name age score result . 0 A | S1 | 20 | 90 | PASS | . 1 B | S2 | 19 | 95 | PASS | . 2 C | S3 | 21 | 75 | FAIL | . 3 A | S4 | 22 | 80 | PASS | . 4 B | S5 | 24 | 70 | FAIL | . 5 C | S6 | 25 | 85 | PASS | . 6 C | S7 | 26 | 90 | PASS | . idx = df[&#39;result&#39;] == &#39;PASS&#39; . df.loc[idx] . class name age score result . 0 A | S1 | 20 | 90 | PASS | . 1 B | S2 | 19 | 95 | PASS | . 3 A | S4 | 22 | 80 | PASS | . 5 C | S6 | 25 | 85 | PASS | . 6 C | S7 | 26 | 90 | PASS | . df_sorted=df.loc[idx].sort_values(&#39;score&#39;,ascending=False) . df_sorted . class name age score result . 1 B | S2 | 19 | 95 | PASS | . 0 A | S1 | 20 | 90 | PASS | . 6 C | S7 | 26 | 90 | PASS | . 5 C | S6 | 25 | 85 | PASS | . 3 A | S4 | 22 | 80 | PASS | . excel 파일 만들고 불러오기 | . df_sorted.to_excel(&#39;data_sorted.xlsx&#39;,index=False) . df_import=pd.read_excel(&#39;data_sorted.xlsx&#39;) . df_import . class name age score result . 0 B | S2 | 19 | 95 | PASS | . 1 A | S1 | 20 | 90 | PASS | . 2 C | S7 | 26 | 90 | PASS | . 3 C | S6 | 25 | 85 | PASS | . 4 A | S4 | 22 | 80 | PASS | . df.groupby(by=&#39;class&#39;).mean() # mean처리 할 수 있는 열에 대해서만 mean 처리 함 . age score . class . A 21.0 | 85.000000 | . B 21.5 | 82.500000 | . C 24.0 | 83.333333 | . df.groupby(by=&#39;class&#39;).std() . age score . class . A 1.414214 | 7.071068 | . B 3.535534 | 17.677670 | . C 2.645751 | 7.637626 | . plotting . df . class name age score result . 0 A | S1 | 20 | 90 | PASS | . 1 B | S2 | 19 | 95 | PASS | . 2 C | S3 | 21 | 75 | FAIL | . 3 A | S4 | 22 | 80 | PASS | . 4 B | S5 | 24 | 70 | FAIL | . 5 C | S6 | 25 | 85 | PASS | . 6 C | S7 | 26 | 90 | PASS | . df.plot.bar(&#39;name&#39;,&#39;score&#39;) . &lt;AxesSubplot:xlabel=&#39;name&#39;&gt; . df.loc[[0,2],&#39;score&#39;]=np.NaN . df . class name age score result . 0 A | S1 | 20 | NaN | PASS | . 1 B | S2 | 19 | 95.0 | PASS | . 2 C | S3 | 21 | NaN | FAIL | . 3 A | S4 | 22 | 80.0 | PASS | . 4 B | S5 | 24 | 70.0 | FAIL | . 5 C | S6 | 25 | 85.0 | PASS | . 6 C | S7 | 26 | 90.0 | PASS | . df.isnull() . class name age score result . 0 False | False | False | True | False | . 1 False | False | False | False | False | . 2 False | False | False | True | False | . 3 False | False | False | False | False | . 4 False | False | False | False | False | . 5 False | False | False | False | False | . 6 False | False | False | False | False | . df.dropna() # 데이터 없는 행은 다 날림 . class name age score result . 1 B | S2 | 19 | 95.0 | PASS | . 3 A | S4 | 22 | 80.0 | PASS | . 4 B | S5 | 24 | 70.0 | FAIL | . 5 C | S6 | 25 | 85.0 | PASS | . 6 C | S7 | 26 | 90.0 | PASS | . value=0 df.fillna(value) ## NaN값만 value로 채워줌 . class name age score result . 0 A | S1 | 20 | 0.0 | PASS | . 1 B | S2 | 19 | 95.0 | PASS | . 2 C | S3 | 21 | 0.0 | FAIL | . 3 A | S4 | 22 | 80.0 | PASS | . 4 B | S5 | 24 | 70.0 | FAIL | . 5 C | S6 | 25 | 85.0 | PASS | . 6 C | S7 | 26 | 90.0 | PASS | . df.replace(np.nan,54) . class name age score result . 0 A | S1 | 20 | 54.0 | PASS | . 1 B | S2 | 19 | 95.0 | PASS | . 2 C | S3 | 21 | 54.0 | FAIL | . 3 A | S4 | 22 | 80.0 | PASS | . 4 B | S5 | 24 | 70.0 | FAIL | . 5 C | S6 | 25 | 85.0 | PASS | . 6 C | S7 | 26 | 90.0 | PASS | . df.interpolate() . class name age score result . 0 A | S1 | 20 | NaN | PASS | . 1 B | S2 | 19 | 95.0 | PASS | . 2 C | S3 | 21 | 87.5 | FAIL | . 3 A | S4 | 22 | 80.0 | PASS | . 4 B | S5 | 24 | 70.0 | FAIL | . 5 C | S6 | 25 | 85.0 | PASS | . 6 C | S7 | 26 | 90.0 | PASS | . 이렇게 위 아래 값의 평균으로 채워주기도 하는데 위아래 둘다 있는 경우에만 사용가능하다 | . def add_one(x): return x+1 . add_one(1001) . 1002 . apply 활용하기 | . df[&#39;age&#39;]=df[&#39;age&#39;].apply(add_one) . df . class name age score result . 0 A | S1 | 22 | NaN | PASS | . 1 B | S2 | 21 | 95.0 | PASS | . 2 C | S3 | 23 | NaN | FAIL | . 3 A | S4 | 24 | 80.0 | PASS | . 4 B | S5 | 26 | 70.0 | FAIL | . 5 C | S6 | 27 | 85.0 | PASS | . 6 C | S7 | 28 | 90.0 | PASS | . 이렇게 df의 age를 변경해줄 수 있음 . df[&#39;score&#39;].apply(np.square) . 0 NaN 1 9025.0 2 NaN 3 6400.0 4 4900.0 5 7225.0 6 8100.0 Name: score, dtype: float64 . . df . class name age score result . 0 A | S1 | 22 | NaN | PASS | . 1 B | S2 | 21 | 95.0 | PASS | . 2 C | S3 | 23 | NaN | FAIL | . 3 A | S4 | 24 | 80.0 | PASS | . 4 B | S5 | 26 | 70.0 | FAIL | . 5 C | S6 | 27 | 85.0 | PASS | . 6 C | S7 | 28 | 90.0 | PASS | . df.filter(regex=&#39;[rn]&#39;) # n 또는 r이 들어간 columns 추출 . name score result . 0 S1 | NaN | PASS | . 1 S2 | 95.0 | PASS | . 2 S3 | NaN | FAIL | . 3 S4 | 80.0 | PASS | . 4 S5 | 70.0 | FAIL | . 5 S6 | 85.0 | PASS | . 6 S7 | 90.0 | PASS | . df_vertical=pd.concat([df,df]) df_vertical . class name age score result . 0 A | S1 | 22 | NaN | PASS | . 1 B | S2 | 21 | 95.0 | PASS | . 2 C | S3 | 23 | NaN | FAIL | . 3 A | S4 | 24 | 80.0 | PASS | . 4 B | S5 | 26 | 70.0 | FAIL | . 5 C | S6 | 27 | 85.0 | PASS | . 6 C | S7 | 28 | 90.0 | PASS | . 0 A | S1 | 22 | NaN | PASS | . 1 B | S2 | 21 | 95.0 | PASS | . 2 C | S3 | 23 | NaN | FAIL | . 3 A | S4 | 24 | 80.0 | PASS | . 4 B | S5 | 26 | 70.0 | FAIL | . 5 C | S6 | 27 | 85.0 | PASS | . 6 C | S7 | 28 | 90.0 | PASS | . df_vertical=pd.concat([df,df],ignore_index=True) df_vertical . class name age score result . 0 A | S1 | 22 | NaN | PASS | . 1 B | S2 | 21 | 95.0 | PASS | . 2 C | S3 | 23 | NaN | FAIL | . 3 A | S4 | 24 | 80.0 | PASS | . 4 B | S5 | 26 | 70.0 | FAIL | . 5 C | S6 | 27 | 85.0 | PASS | . 6 C | S7 | 28 | 90.0 | PASS | . 7 A | S1 | 22 | NaN | PASS | . 8 B | S2 | 21 | 95.0 | PASS | . 9 C | S3 | 23 | NaN | FAIL | . 10 A | S4 | 24 | 80.0 | PASS | . 11 B | S5 | 26 | 70.0 | FAIL | . 12 C | S6 | 27 | 85.0 | PASS | . 13 C | S7 | 28 | 90.0 | PASS | . df_horizontal=pd.concat([df,df],axis=1) df_horizontal . class name age score result class name age score result . 0 A | S1 | 22 | NaN | PASS | A | S1 | 22 | NaN | PASS | . 1 B | S2 | 21 | 95.0 | PASS | B | S2 | 21 | 95.0 | PASS | . 2 C | S3 | 23 | NaN | FAIL | C | S3 | 23 | NaN | FAIL | . 3 A | S4 | 24 | 80.0 | PASS | A | S4 | 24 | 80.0 | PASS | . 4 B | S5 | 26 | 70.0 | FAIL | B | S5 | 26 | 70.0 | FAIL | . 5 C | S6 | 27 | 85.0 | PASS | C | S6 | 27 | 85.0 | PASS | . 6 C | S7 | 28 | 90.0 | PASS | C | S7 | 28 | 90.0 | PASS | . . df.to_csv(&#39;data_text.txt&#39;,sep=&#39; t&#39;,index=False) # txt파일로 변환할 때 어떻게 구분해서 타이핑해넣을 것인가 # sep= t,여기선 지금 탭으로 구분지었음 . pd.read_csv(&#39;data_text.txt&#39;,delimiter=&#39; t&#39;) # delimiter로 txt파일이 어떻게 이루어져 있나 알려줘야함 . class name age score result . 0 A | S1 | 22 | NaN | PASS | . 1 B | S2 | 21 | 95.0 | PASS | . 2 C | S3 | 23 | NaN | FAIL | . 3 A | S4 | 24 | 80.0 | PASS | . 4 B | S5 | 26 | 70.0 | FAIL | . 5 C | S6 | 27 | 85.0 | PASS | . 6 C | S7 | 28 | 90.0 | PASS | . . from sympy import symbols . x=symbols(&#39;x&#39;) . type(x) . sympy.core.symbol.Symbol . 2*x . $ displaystyle 2 x$ 즉 x자체가 symbol로 들어갔음 . expr=2*x . expr.subs(x,3) . $ displaystyle 6$ 미분해보자 . f=x**3 . from sympy import diff . df1=diff(f,x) . df1 . $ displaystyle 3 x^{2}$ df2=diff(df1,x) . df2 . $ displaystyle 6 x$ . from sympy import sin . f=sin(x) . df1=diff(f,x) . df1 . $ displaystyle cos{ left(x right)}$ . from sympy import integrate . integrate(f,(x,0,2*3.14)) . $ displaystyle 5.07308662478501 cdot 10^{-6}$ 0에 가깝게 나옴 . integrate(f,(x,0,3.14)) . $ displaystyle 1.99999873172754$ . from sympy import limit . limit(sin(x)/x,x,0) . $ displaystyle 1$ . import matplotlib.pyplot as plt from scipy import interpolate . x=np.array([1,2,3,4,5]) y=np.array([1,0.8,0.4,0.3,0.2]) . plt.plot(x,y,&#39;*&#39;) . [&lt;matplotlib.lines.Line2D at 0x1bb1062f8b0&gt;] . f_lin=interpolate.interp1d(x,y) . x_new = np.arange(1,5,0.1) . y_new = f_lin(x_new) . fig,ax=plt.subplots() ax.plot(x,y,&#39;o&#39;,label=&#39;Data&#39;) ax.plot(x_new,y_new,label=&#39;linear&#39;) ax.legend() . &lt;matplotlib.legend.Legend at 0x1bb1e842fa0&gt; . 선형 보간됨을 알 수 있다. . . tck=interpolate.splrep(x,y,s=0) y_spl=interpolate.splev(x_new,tck,der=0) fig,ax=plt.subplots() ax.plot(x,y,&#39;o&#39;,label=&#39;Data&#39;) ax.plot(x_new,y_new,label=&#39;linear&#39;) ax.plot(x_new,y_spl,label=&#39;spline&#39;) ax.legend() . &lt;matplotlib.legend.Legend at 0x1bb1e8af9a0&gt; . 원형 보간 추가 . . BGR &#54540;&#46991; . import cv2 as cv im=cv.imread(&#39;KakaoTalk_20211210_090822964.png&#39;) plt.figure() plt.imshow(im) plt.title(&#39;Original&#39;) . Text(0.5, 1.0, &#39;Original&#39;) . BGR로 들어오기 때문에 RGB로 바꿔 줄 필요가 있음 | . rgb=cv.cvtColor(im,cv.COLOR_BGR2RGB) plt.figure() plt.imshow(rgb) plt.title(&#39;RGB&#39;) . Text(0.5, 1.0, &#39;RGB&#39;) . GRAY=cv.cvtColor(im,cv.COLOR_BGR2GRAY) plt.figure() plt.imshow(GRAY,cmap=&#39;gray&#39;) plt.title(&#39;GRAY&#39;) . Text(0.5, 1.0, &#39;GRAY&#39;) . blur=cv.blur(im,(100,100)) blur=cv.cvtColor(blur,cv.COLOR_BGR2RGB) plt.subplot(121) # 가로줄 한개, 세로줄 두개, 첫번째에 놓겠다 plt.imshow(rgb) plt.title(&#39;RGB&#39;) plt.subplot(122) # 가로줄 한개, 세로줄 두개, 두번째에 놓겠다 plt.imshow(blur) plt.title(&#39;blur&#39;) . Text(0.5, 1.0, &#39;blur&#39;) . . edges=cv.Canny(GRAY,0,100) plt.subplot(121) # 가로줄 한개, 세로줄 두개, 첫번째에 놓겠다 plt.imshow(GRAY,cmap=&#39;gray&#39;) plt.title(&#39;GRAY&#39;) plt.subplot(122) # 가로줄 한개, 세로줄 두개, 두번째에 놓겠다 plt.imshow(edges) plt.title(&#39;edge detection&#39;) . Text(0.5, 1.0, &#39;edge detection&#39;) . 머신러닝과 연관하여 비디오 영상의 움직이는 사물을 찾거나 번호판 또는 숫자 인식 여러 분야에서 활용이 가능하다 .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2021/12/26/intro.html",
            "relUrl": "/2021/12/26/intro.html",
            "date": " • Dec 26, 2021"
        }
        
    
  
    
        ,"post28": {
            "title": "2021/12/25/SAT",
            "content": "import numpy as np . a=np.array([100.,101.,102.,103.]) . a.shape # 1차원 4개 요소 . (4,) . a.ndim . 1 . a[0] . 100.0 . a[1] . 101.0 . a[-1] . 103.0 . a . array([100., 101., 102., 103.]) . a[[1,3]] . array([101., 103.]) . a[-3:-1] . array([101., 102.]) . a[1:4:1] . array([101., 102., 103.]) . a[1:4] . array([101., 102., 103.]) . a[1:4:2] . array([101., 103.]) . a[:] . array([100., 101., 102., 103.]) . a[::2] . array([100., 102.]) . a[::-2] . array([103., 101.]) . a2=np.array([[11,12],[23 ,34]]) . a2 . array([[11, 12], [23, 34]]) . a2.shape . (2, 2) . a2.ndim . 2 . a2[0][1] # 겉차원 -&gt; 속차원 . 12 . a2[0,1] . 12 . a . array([100., 101., 102., 103.]) . a[[0,1]] # 인덱스 0번쨰와 1번째 거 추출 . array([100., 101.]) . # 따라서 a2의 첫 번째 원소와 두 번째 원소만 추출됨 a2[[0,1]] . array([[11, 12], [23, 34]]) . a2[:] . array([[11, 12], [23, 34]]) . a2[:,:] . array([[11, 12], [23, 34]]) . . 행렬처럼 생각하자 . a2 . array([[11, 12], [23, 34]]) . a2[0,:] . array([11, 12]) . a2[1,:] . array([23, 34]) . b=a2[:,0] . b . array([11, 23]) . b.shape . (2,) . b.ndim . 1 . . b_=b[:,np.newaxis] . b_ . array([[11], [23]]) . b_.shape . (2, 1) . b_.ndim . 2 . 또는 . b.shape=(1,2) . b . array([[11, 23]]) . a3=np.array([[[ 1,2],[3,4 ],[5,6 ],[7,8 ],[9,10]]]) . a3 . array([[[ 1, 2], [ 3, 4], [ 5, 6], [ 7, 8], [ 9, 10]]]) . a3[0,0,1] . 2 . a3.shape # 큰 덩어리 1개, 작은 덩어리 5개, 그 안에 요소 2개씩 . (1, 5, 2) . a3.ndim #3차원 . 3 . a3[0,1,1] . 4 . # 당연히 없을 것 # 큰 덩어리는 하나임 . x=np.array([12,34,14,0,34]) . idx=np.where(x==34) . idx . (array([1, 4], dtype=int64),) . x[idx] . array([34, 34]) . idx=(x==14) . idx . array([False, False, True, False, False]) . x[idx] . array([14]) . x[np.where(x==12)] . array([12]) . x . array([12, 34, 14, 0, 34]) . np.nonzero(x) . (array([0, 1, 2, 4], dtype=int64),) . x[np.nonzero(x)] . array([12, 34, 14, 34]) . x==0 . array([False, False, False, True, False]) . np.nonzero(x==14) . (array([2], dtype=int64),) . np.nonzero(x==0) . (array([3], dtype=int64),) . x[np.nonzero(x==0)] . array([0]) . x[np.nonzero(x==34)] . array([34, 34]) . image processing시, 논리연산을 통한 idexing 중요 . image=np.array([[255,0,255], [255,0,255], [255,0,255]]) . image.shape # 2차원, 큰덩어리 세개, 그 안에 요소 3개 . (3, 3) . idx=np.where(image==255) . idx . (array([0, 0, 1, 1, 2, 2], dtype=int64), array([0, 2, 0, 2, 0, 2], dtype=int64)) . (0,0)(0,2)(1,0)(1,2)(2,2) 자리에 255가 있다 . image[idx]=0 . image . array([[0, 0, 0], [0, 0, 0], [0, 0, 0]]) . 이런식으로 논리연산을 통한 indexing으로 다 검정색을 만들어버림 . . a=np.array([[10,20],[30,40]]) b=np.array([[1,2],[3,4]]) . a . array([[10, 20], [30, 40]]) . b . array([[1, 2], [3, 4]]) . a * b . array([[ 10, 40], [ 90, 160]]) . a @ b . array([[ 70, 100], [150, 220]]) . a.dot(b) #행렬 연산 . array([[ 70, 100], [150, 220]]) . a=np.zeros((3,3)) . a . array([[0., 0., 0.], [0., 0., 0.], [0., 0., 0.]]) . b=np.ones((3,3)) . b . array([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) . c=np.trace(b) . c . 3.0 . . $x@a=y$ 에서 a행렬 구해보기 . x=np.array([[1,-3],[2,4]]) y=np.array([[1],[3]]) . print(x) print(y) . [[ 1 -3] [ 2 4]] [[1] [3]] . x_inverse=np.linalg.inv(x) . a=x_inverse@y . a . array([[1.3], [0.1]]) . 혹은 . a=np.linalg.solve(x,y) . a . array([[1.3], [0.1]]) . 그 외에도 고유벡터, 고유값, 특이값 분해도 np에서 함수사용할 수 있다 . a=np.zeros((5,5)) np.fill_diagonal(a,12) . a #대각원소만 12로 변경 . array([[12., 0., 0., 0., 0.], [ 0., 12., 0., 0., 0.], [ 0., 0., 12., 0., 0.], [ 0., 0., 0., 12., 0.], [ 0., 0., 0., 0., 12.]]) . a=np.array([[1,2,3],[3,4,4],[5,43,6]]) . b=np.array([[1],[2],[3]]) . b . array([[1], [2], [3]]) . b=b.repeat(3,axis=1) . b . array([[1, 1, 1], [2, 2, 2], [3, 3, 3]]) . 이제 원소대 원소 곱해주면 된다 | . c=a*b . c . array([[ 1, 2, 3], [ 6, 8, 8], [ 15, 129, 18]]) . broadcasting : size알아서 처리해주는 기능 | . a . array([[ 1, 2, 3], [ 3, 4, 4], [ 5, 43, 6]]) . b=np.array([[1],[2],[3]]) . b . array([[1], [2], [3]]) . a*b . array([[ 1, 2, 3], [ 6, 8, 8], [ 15, 129, 18]]) . . def f(x,y): return 100*x+y . np.fromfunction(f,(4,4),dtype=int) . array([[ 0, 1, 2, 3], [100, 101, 102, 103], [200, 201, 202, 203], [300, 301, 302, 303]]) . 행이 x축 역할하고 열이 y축 역할을 함으로써, 격자로 더해준다고 생각하면 됨 | . . a=np.array([10,20,30,40,50]) b=np.array([30,50]) . np.setdiff1d(a,b) . array([10, 20, 40]) . . np.random.randint(54) . 26 . . import matplotlib.pyplot as plt . y=np.array([10,20,30]) . plt.plot(y) . [&lt;matplotlib.lines.Line2D at 0x1ed34d292b0&gt;] . x=np.array([123,413,555]) . plt.plot(x,y,&#39;r--.&#39;) #data가 들어간 곳에 dot으로 표시 . [&lt;matplotlib.lines.Line2D at 0x1ed34e3d160&gt;] . plt.plot(x,y,&#39;b-o&#39;,label=&#39;fuck&#39;) plt.ylabel(&#39;sd&#39;) plt.xlabel(&#39;SD&#39;) plt.legend() plt.title(&#39;What &#39;s this?&#39;) . Text(0.5, 1.0, &#34;What&#39;s this?&#34;) . hf=plt.figure() # 도화지 ha1 = hf.add_axes([0,0,1,1]) # 0,0자리에 1,1크기만큼 ha2 = hf.add_axes([1,1,1,1]) # 0,0자리에 1,1크기만큼 ha1.plot(x,y,&#39;o-r&#39;) ha2.plot(x,y,&#39;x:b&#39;) . [&lt;matplotlib.lines.Line2D at 0x1ed37a58430&gt;] . aa,bb=plt.subplots() hong,=bb.plot(x,y) # 이렇게 aa,bb는 임의로 지명 가능 . 위 그래프 update | . a_new=np.array([200,331,335]) b_new=np.array([10,50,10]) hong.set_data(a_new,b_new) aa . 주의 :애초에 aa라는 도화지에 정해진 축이 있기 때문에 그 축에서 너무 멀어지는 값들을 넣어주면 aa라는 도화지에 보이지 않을 수 있음 . PLUS=1.5 a_new=np.array([200,331,335]) b_new=np.array([10,50,10]) hong.set_data(a_new,PLUS*b_new) aa . 그래프가 올라간 것을 확인할 수 있음 . a=np.linspace(0,2,100) y1=0.5*a y2=0.5*a**2 y3=0.5*a**3 plt.plot(a,y1,label=&#39;1D&#39;) plt.plot(a,y2,label=&#39;2D&#39;) plt.plot(a,y3,label=&#39;3D&#39;) plt.legend() plt.xlabel(&#39;X&#39;) plt.ylabel(&#39;Y&#39;) plt.title(&#39;GRAPH&#39;) . Text(0.5, 1.0, &#39;GRAPH&#39;) . fig,ax=plt.subplots() ax1,=ax.plot(a,y1) # comma 입력해주면 나중에 update 가능 ax2,=ax.plot(a,y2) ax3,=ax.plot(a,y3) ax.set_xlabel(&#39;X&#39;) # plt가 아닐 땐 set을 입력해줘야 함 ax.set_ylabel(&#39;Y&#39;) ax1.set_label(&#39;1&#39;) ax2.set_label(&#39;2&#39;) ax3.set_label(&#39;3&#39;) ax.legend() . &lt;matplotlib.legend.Legend at 0x1ed37aa5e20&gt; . ax1.set_color(&#39;k&#39;) ax2.set_color(&#39;b&#39;) ax3.set_color(&#39;r&#39;) ax.grid() ax.legend() fig . decay sin . t=np.linspace(0,100,1000) tau= 60 y=np.sin(t)*np.exp(-t/tau) plt.plot(t,y,label=&#39;Decay Oscillating Response&#39;) plt.ylabel(&#39;y[m]&#39;) plt.xlabel(&#39;t[s]&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1ed36bc0070&gt; . Euler eq . t=np.linspace(0,1,100) f= 1 # 주파수 y_euler=np.exp(1j*2*np.pi**f*t) y_cos = np.real(y_euler) y_sin=np.imag(y_euler) fig,ax=plt.subplots() ax.plot(t,y_cos,&#39;-r&#39;,label=&#39;cos&#39;) ax.plot(t,y_sin,&#39;--b&#39;,label=&#39;sin&#39;) ax.grid() ax.legend() . &lt;matplotlib.legend.Legend at 0x1ed36cbe280&gt; . fig,ax=plt.subplots(2,) ax[0].plot(t,y_cos,&#39;-r&#39;,label=&#39;cos&#39;) ax[1].plot(t,y_sin,&#39;--b&#39;,label=&#39;sin&#39;) ax[0].grid() ax[0].legend() ax[1].grid() ax[1].legend() . &lt;matplotlib.legend.Legend at 0x1ed38d1e850&gt; . Histogram . data=np.random.randn(500000) plt.hist(data,100,density=True) # 100개의 막대로 나누겠다, 확률밀도함수로 그리겠다 x=np.linspace(-4,4,100) sigma=1 mean=0 nd=(1/(sigma*np.sqrt(2*np.pi)))*np.exp(-0.5*((x-mean)/sigma)**2) plt.plot(x,nd,&#39;r&#39;,label=&#39;Std Normal Dist&#39;) plt.ylabel(&#39;PSD&#39;) plt.xlabel(&#39;X&#39;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1ed3929cfd0&gt; . 3D plot . x=np.linspace(0,2*np.pi,10) y=np.linspace(0,2*np.pi,10) grid_x,grid_y=np.meshgrid(x,y) # 1차원 array를 통해 2차원 grid를 만들어줌 z=np.sin(grid_x)*np.sin(grid_y) fig=plt.figure() ax=fig.gca(projection=&#39;3d&#39;) # Get Current Axis=gca ax.plot_surface(grid_x,grid_y,z,cmap=&#39;jet&#39;) ax.set_xlabel(&#39;x&#39;) ax.set_ylabel(&#39;y&#39;) ax.set_zlabel(&#39;z&#39;) . C: Users ehfus AppData Local Temp/ipykernel_20060/1177705184.py:6: MatplotlibDeprecationWarning: Calling gca() with keyword arguments was deprecated in Matplotlib 3.4. Starting two minor releases later, gca() will take no keyword arguments. The gca() function should only be used to get the current axes, or if no axes exist, create new axes with default keyword arguments. To create a new axes with non-default arguments, use plt.axes() or plt.subplot(). ax=fig.gca(projection=&#39;3d&#39;) # Get Current Axis=gca . Text(0.5, 0, &#39;z&#39;) . Animation . # x=np.array([1,2,3,4,5]) # y=np.array([1,1,1,1,1]) # ax1, = ax.plot(x,y) # ax.set_ybound([0,11]) # for i in range(0,11,1): # ax1.set_ydata(i*y) # plt.pause(0.3) # 원래는 animation기능으로 움직여야 함 .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2021/12/25/intro.html",
            "relUrl": "/2021/12/25/intro.html",
            "date": " • Dec 25, 2021"
        }
        
    
  
    
        ,"post29": {
            "title": "2022/12/23/THU",
            "content": "s=&#39;python n n&#39; # 직접 enter로 다음 줄로 넘겨도 됨 . s . &#39;python n n&#39; . print(s) . python . &#39;&#39;&#39; =&gt; 긴 str배정시에 사용 | . s=&#39;python&#39; . s.capitalize() . &#39;Python&#39; . s.find(&#39;t&#39;) . 2 . s.count(&#39;y&#39;) . 1 . s.count(&#39;x&#39;) . 0 . s.count(&#39;p&#39;) # 대소문자 구분X . 1 . s.find(&#39;a&#39;) . -1 . s.index(&#39;t&#39;) . 2 . a=&#39;pyathaon&#39; . a.find(&#39;a&#39;) . 2 . a.index(&#39;a&#39;) . 2 . a.isalpha() . True . s=&#39;asd342&#39; . s.isalnum() . True . a=&#39;python 3&#39; . a.isalnum() . False . s=&#39;123&#39; . # 십진법! s.isdecimal() . True . s=&#39;223311.3&#39; . s.isdecimal() . False . s.isdigit() . False . s.isnumeric() . False . s=&#39;123123123&#39; . s.isdecimal() . True . a=&#39;2034&#39; . a.isdigit() . True . a=&#39;3 u00B3&#39; . a . &#39;3³&#39; . # 십진법 a.isdecimal() . False . a.isdigit() . True . a.isnumeric() . True . a=&#39; u00BC&#39; . a . &#39;¼&#39; . a.isdecimal() . False . a.isdigit() . False . a.isnumeric() . True . a=&#39;Python&#39; . a.islower() . False . a.isupper() . False . 중요 | . a=&#39;PythonP&#39; . a.replace(&#39;P&#39;,&#39;Q&#39;) . &#39;QythonQ&#39; . 중요 | . a=&#39;I like python&#39; . # space 기준으로 나눈 뒤 리스트化 a.split(&#39; &#39;) . [&#39;I&#39;, &#39;like&#39;, &#39;python&#39;] . a=&#39;I,like,python&#39; . a.split(&#39;,&#39;) . [&#39;I&#39;, &#39;like&#39;, &#39;python&#39;] . str에서 다음줄로 내릴 때 . a=&#39;I like python nHe likes python nfucking python&#39; . a . &#39;I like python nHe likes python nfucking python&#39; . print(a) . I like python He likes python fucking python . a.splitlines() . [&#39;I like python&#39;, &#39;He likes python&#39;, &#39;fucking python&#39;] . b=a.splitlines() . b[0] . &#39;I like python&#39; . # 맨 앞만 대문자로 변경하는 건 Caitalize b[0].upper() . &#39;I LIKE PYTHON&#39; . b[0].count(&#39;L&#39;) . 0 . . s=&#39;python&#39; . a=3 . print(s,a) . python 3 . print(s,str(a)) . python 3 . print(s+str(a)) . python3 . print(s + &#39; &#39; + str(a)) . python 3 . Format* . &#39;Python {}&#39;.format(25) . &#39;Python 25&#39; . &#39;Python {1} + {0}&#39;.format(3,&#39;asdas&#39;) . &#39;Python asdas + 3&#39; . &#39;Python {} {}&#39;.format(3,&#39;asd&#39;) . &#39;Python 3 asd&#39; . s=&#39;Python {1} {0}&#39; . s.format(3,&#39;asd&#39;) . &#39;Python asd 3&#39; . s= &#39;My name is {} I am {} years old&#39; . s.format(&#39;asd&#39;,12) . &#39;My name is asd I am 12 years old&#39; . ver=3.8 . print(&#39;python&#39;, ver) . python 3.8 . print(&#39;python&#39; + str(ver)) . python3.8 . print(&#39;python{}&#39;.format(ver)) . python3.8 . s=&#39;python{}&#39;.format(ver) . print(s) . python3.8 . . data=4321.123456 . print(&#39;DATA&#39;+str(data)) . DATA4321.123456 . print(&#39;DATA&#39;, data) . DATA 4321.123456 . print(&#39;DATA &#39;+str(data)) . DATA 4321.123456 . print(&#39;DATA= &#39;+str(data)) . DATA= 4321.123456 . print(&#39;DATA={}&#39;.format(data)) . DATA=4321.123456 . . 참고 . {0:&lt;10} =&gt; {0} 위치의 값을 &quot;:&lt;10&quot; 10자리로 표현할건데 왼쪽 정렬 | {1:&gt;5} =&gt; {1} 위치의 값을 &quot;:&gt;5&quot; 5자리로 표현할건데 오른쪽 정렬 | {0:^10} =&gt; {0} 위치의 값을 &quot;:^10&quot; 10 자리로 표현할 건데 가운데 정렬 | . . print(&#39;DATA= {:.2f}&#39;.format(data)) . DATA= 4321.12 . print(&#39;DATA= {:.0f}&#39;.format(data)) . DATA= 4321 . print(&#39;DATA={:4.0f}&#39;.format(data)) . DATA=4321 . print(&#39;DATA={:5.0f}&#39;.format(data)) . DATA= 4321 . print(&#39;DATA={:6.0f}&#39;.format(data)) . DATA= 4321 . print(&#39;DATA={:7.0f}&#39;.format(data)) . DATA= 4321 . print(&#39;DATA={:,}&#39;.format(data)) . DATA=4,321.123456 . data2=454654456.1213546 . print(&#39;DATA={:,}&#39;.format(data2)) . DATA=454,654,456.1213546 . . data자체가 float이라서 d입력하면 오류가 발생 | int는 소수점 없으니까 .4d 이렇게 입력하면 오류 그냥 4d로 입력해야 함 | . data . 4321.123456 . print(&#39;DATA={:4d}&#39;.format(int(data))) . DATA=4321 . print(&#39;DATA={:5d}&#39;.format(int(data))) . DATA= 4321 . print(&#39;DATA={:8d}&#39;.format(int(data))) . DATA= 4321 . . scientific notation : e라는 것을 사용하여 수를 표현해줌 | . print(&#39;data = {:e}&#39;.format(data)) . data = 4.321123e+03 . . % 이용해보자 | . print(&#39;DATA=%(x)f&#39; % {&#39;x&#39; : data}) . DATA=4321.123456 . print(&#39;DATA=%(x).0f&#39; % {&#39;x&#39; : data}) . DATA=4321 . print(&#39;DATA=%(x).2f&#39; % {&#39;x&#39; : data}) . DATA=4321.12 . print(&#39;DATA=%(x)7.0f&#39; % {&#39;x&#39; : data}) . DATA= 4321 . print(&#39;DATA=%(x)8.3f&#39; % {&#39;x&#39; : data}) . DATA=4321.123 . print(&#39;DATA=%(x)8.0f&#39; % {&#39;x&#39; : data}) . DATA= 4321 . . import math print(math.pi) import numpy as np print(np.pi) . 3.141592653589793 3.141592653589793 . math.inf . inf . np.inf . inf . math.nan #숫자가 아님을 표현할 때 . nan . np.nan . nan . math.e . 2.718281828459045 . # 올림, 반올림과 다름 math.floor(math.pi) . 3 . # 버림, 반올림과다름 math.ceil(math.pi) . 4 . round(math.pi,0) . 3.0 . math.trunc(math.pi) . 3 . int(math.pi) . 3 . math.sqrt(math.pi) . 1.7724538509055159 . np.sqrt(math.pi) . 1.7724538509055159 . math.log(10) . 2.302585092994046 . math.log10(10) . 1.0 . math.log(math.e) . 1.0 . p=math.pi . math.sin(p/2) . 1.0 . math.sin(2*p) . -2.4492935982947064e-16 . x_degree=90 . x_radian=x_degree*(math.pi/180) . x_radian #pi/2랑 동일 . 1.5707963267948966 . math.radians(90) . 1.5707963267948966 . math.pow(2,3) . 8.0 . pow(2,3) . 8 . 2**3 . 8 . x=2 . math.isinf(x) . False . math.isnan(x) . False . *중요 . print(math.fsum([1,2,3])) print(int(math.fsum([1,2,3]))) . 6.0 6 . # error 발생 # 원소가 int일때만 가능 . . file - input &amp; output . import os . os.chdir(&#39;c: test&#39;) . os.mkdir(&#39;temp4&#39;) . os.chdir(&#39;temp4&#39;) . os.getcwd() . &#39;c: test temp4&#39; . os.chdir(&#39;..&#39;) . os.getcwd() . &#39;c: test&#39; . os.chdir(&#39;temp&#39;) . os.getcwd() . &#39;c: test temp&#39; . os.chdir(&#39;.&#39;) . os.getcwd() . &#39;c: test temp&#39; . os.mkdir(&#39;dir0&#39;) . os.mkdir(&#39;dir3&#39;) . os.mkdir(&#39;dir4&#39;) . os.getcwd() . &#39;c: test temp&#39; . os.listdir() . [&#39;dir0&#39;, &#39;dir1&#39;, &#39;dir2&#39;, &#39;dir3&#39;, &#39;dir4&#39;, &#39;file1.txt&#39;, &#39;file2.txt&#39;, &#39;file3.txt&#39;, &#39;file4.txt&#39;] . os.rename(&#39;dir0&#39;,&#39;dir100&#39;) . os.listdir() . [&#39;dir1&#39;, &#39;dir100&#39;, &#39;dir2&#39;, &#39;dir3&#39;, &#39;dir4&#39;, &#39;file1.txt&#39;, &#39;file2.txt&#39;, &#39;file3.txt&#39;, &#39;file4.txt&#39;] . os.rmdir(&#39;dir100&#39;) . os.listdir() . [&#39;dir1&#39;, &#39;dir2&#39;, &#39;dir3&#39;, &#39;dir4&#39;, &#39;file1.txt&#39;, &#39;file2.txt&#39;, &#39;file3.txt&#39;, &#39;file4.txt&#39;] . import sys . # 파이썬에서 사용가능한 모듈들을 불러준 것 . # sys.path . os.chdir(&#39;C: Users ehfus Downloads python Introduction&#39;) . os.chdir(&#39;c: test temp&#39;) . os.getcwd() . &#39;c: test temp&#39; . . f=open(&#39;file1.txt&#39;,&#39;w&#39;)#파일 작성 . f.closed . False . f.write(&#39;fucking&#39;) . 7 . f.close() . f.closed . True . with open(&#39;file2.txt&#39;,&#39;w&#39;) as f: f.write(&#39;sibal n&#39;) f.write(&#39;jotgatne n&#39;) f.write(&#39;just joke n&#39;) . f.closed . True . fid=open(&#39;file2.txt&#39;,&#39;r&#39;) . fid.read() . &#39;sibal njotgatne njust joke n&#39; . fid.close() . fid.closed . True . fid=open(&#39;file2.txt&#39;,&#39;r&#39;) . fid.readline() . &#39;sibal n&#39; . fid.readline() . &#39;jotgatne n&#39; . fid.readline() . &#39;just joke n&#39; . fid.readline() . &#39;&#39; . 한 줄씩 불러옴 . fid.close() . fid=open(&#39;file2.txt&#39;,&#39;r&#39;) . data=[] . data.append(fid.readline()) . data.append(fid.readline()) . data.append(fid.readline()) . data . [&#39;sibal n&#39;, &#39;jotgatne n&#39;, &#39;just joke n&#39;] . 자동화 . data=[&#39;string1&#39;,&#39;string2&#39;,&#39;string3&#39;] . import json . f=open(&#39;file3.txt&#39;,&#39;w&#39;) . json.dump(data,f) . f.close() . f=open(&#39;file3.txt&#39;,&#39;r&#39;) . x=json.load(f) . x . [&#39;string1&#39;, &#39;string2&#39;, &#39;string3&#39;] . f.close() . import pickle . f=open(&#39;file4.txt&#39;,&#39;wb&#39;) # 바이너리로 쓰겠다 . 용량을 작게 할 수 있다는 장점이 있음 . pickle.dump(data,f) . f.close() . f=open(&#39;file4.txt&#39;,&#39;rb&#39;) # 바이너리 불러옴 . x= pickle.load(f) . x . [&#39;string1&#39;, &#39;string2&#39;, &#39;string3&#39;] . f.close() .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2021/12/23/intro.html",
            "relUrl": "/2021/12/23/intro.html",
            "date": " • Dec 23, 2021"
        }
        
    
  
    
        ,"post30": {
            "title": "2021/12/22/WED",
            "content": "정수(int), 소수(float), 복소수(complex), 참거짓(bool,True,False), 문자(str) | . &#39;a&#39;,&quot;hello&quot; # str이 tuple로 묶여있음 . (&#39;a&#39;, &#39;hello&#39;) . 자료의 형태를 알고 싶을 때 | . type(True) . bool . 자료형 변환 | . int() . 0 . str() . &#39;&#39; . bool() . False . int(1) . 1 . int(1.3) . 1 . 그런데 소수점 떼는 방법에는 여러가지가 있음 . import math math.ceil(i) # 소수점 아래 다 올려버러기 math.floor(i) # 소수점 아래 다 내리기 math.trunc(i) # 소수점 아래 다 버리기 # 또는 round(a,b)를 통해서 원하는 자릿수까지 반올림 처리 할 수도 있다. # 그런데 사실 그냥 int로 다 버리는 방법도 있음 . import math print(math.trunc(2.345)) print(int(2.345)) . 2 2 . round(2.345,2) # 소수점 아래 둘째자리까지 반올림해라 # 즉 소수점 아래 둘째자리까지 살아남는 거 . 2.35 . str -&gt; int 또는 float | . int(&#39;1&#39;) . 1 . float(&#39;3.14&#39;) . 3.14 . . float(&#39;-inf&#39;) . -inf . complex(1) . (1+0j) . complex(3+5j) . (3+5j) . complex(3,5.5) . (3+5.5j) . complex(&#39;1+3j&#39;) . (1+3j) . int -&gt; str | . str(1) . &#39;1&#39; . str(2+5j) # 괄호랑 +,j모두 원소 하나하나로 반환 . &#39;(2+5j)&#39; . bool(-0.8) . True . bool(0) . False . bool(554) . True . 0 제외하고 전부 True 처리 . bool(&#39;&#39;) . False . bool(123) # 0이 아닌 다른 수는 모두 True . True . bool(&#39;aasdss&#39;) . True . bool(0) . False . bool(float(&#39;inf&#39;)) . True . float(&#39;inf&#39;),bool(&#39;-inf&#39;),complex(&#39;inf&#39;) . (inf, True, (inf+0j)) . &#50672;&#49328; . 1+1,3-2,5*2,5/2 . (2, 1, 10, 2.5) . 5//2 . 2 . 5%2 . 1 . divmod(5,3) # 원소 2개인 tuple로 들어감 . (1, 2) . abs(-232) . 232 . pow(5,4),5**4 . (625, 625) . &#39;asdasd&#39;+&#39;asdfeq&#39; . &#39;asdasdasdfeq&#39; . &#39;asdasd&#39;*2 . &#39;asdasdasdasd&#39; . 문자형이 다른 건 더할 수 없음 | . &#39;asdasd&#39;+str(235456) . &#39;asdasd235456&#39; . True+True . 2 . 비교 연산 =&gt; BOOL형태로 출력됨 | . 1&lt;0 . False . 2==3 . False . 1!=3 # 틀렸으니 맞다고 나올 것 . True . # False라고 나오긴 함 # 그런데 is나 is not은 원래 자료형이 같고 다른지를 물을 때 사용함 . type(&#39;123&#39;) is not type(True) . True . . True and False . False . True and False and True . False . 거짓이 하나라도 있으면 거짓 처리 | . . True or False . True . True or False or False . True . 참이 하나라도 있으면 참 처리 | . . not True . False . 참과 거짓을 반대로 바꿔주는 기능 (by not) | . . 100 and 5 . 5 . True and 3 . 3 . 34 and True . True . 34 and 2 . 2 . 둘다 참일 경우(1이상인 수 혹은 True)일 땐 뒤에 걸 출력하는 것 같음 | . . False and 3 . False . 0 and 100 . 0 . and 연결에 Fasle가 하나라도 있으니 당연히 Fasle 쪽으로 출력됨 | . . 1 or 100 . 1 . 100 or 1 . 100 . 100 or 1 or 300 . 100 . 3 or 1 or 45 or 0 . 3 . or 사용시엔 하나라도 참이 섞여있으면 그 중 맨 앞의 값을 출력 | and 사용시엔 둘다 참일 경우 맨 뒤 값을 출력했음 | . . 1 and 0 and 100 . 0 . 0(False)이 하나 있어서 0 출력 | . . Bitwise :&#51060;&#51652;&#48277; . 2 #십진법 . 2 . bin(2) # 이진법 . &#39;0b10&#39; . bin(3) . &#39;0b11&#39; . bin(12) . &#39;0b1100&#39; . . &amp; $ to$ and&#46993; &#54775;&#44040;&#47532;&#51648; &#47568;&#51088; . 10&amp;6 . 2 . 10과 6을 2진법으로 처리한 후 겹치는 자리만 뽑아낸 것 | . bin(10) . &#39;0b1010&#39; . bin(6) . &#39;0b110&#39; . bin(10&amp;6) . &#39;0b10&#39; . 10|6 # or와 다름 . 14 . bin(10) . &#39;0b1010&#39; . bin(6) . &#39;0b110&#39; . bin(10|6) . &#39;0b1110&#39; . 10^2 # 제곱 아님 # 10**2 또는 pow(10,2)로! . 8 . print(10**2) print(pow(10,2)) . 100 100 . bin(6) . &#39;0b110&#39; . bin(10) . &#39;0b1010&#39; . bin(10^6) . &#39;0b1100&#39; . bin(6) . &#39;0b110&#39; . bin(6&lt;&lt;2) . &#39;0b11000&#39; . bin(6&gt;&gt;2) . &#39;0b1&#39; . 6&gt;&gt;2 . 1 . &#48320;&#49688; . a=1 a . 1 . print(a) . 1 . b=3.225 . type(b) . float . b=546548 . b . 546548 . d=True . print(d) . True . b=a . b # 다른 변수로 해당 변수를 업데이트 할 수 있음 . 1 . a=5 . a . 5 . b . 1 . a가 바뀌어도 a로 업데이트 된 b는 그 전 a의 자료인 1로 그대로 유지 중 . length=2 width=3 area=length*width . x=1 . y=2*x . y . 2 . a=3 . bin(a) . &#39;0b11&#39; . a.bit_length() . 2 . b=10 . bin(b) . &#39;0b1010&#39; . b.bit_length() . 4 . c=1+2j . d=c.conjugate() . d . (1-2j) . d.imag . -2.0 . c . (1+2j) . c.real # c 안의 실수 . 1.0 . c.imag # c 안의 허수 . 2.0 . a=1 . a+=1 # a에 있는 값을 1만큼 올려서 저장 . a . 2 . a-=10 . a . -8 . . 문자열 내장 함수? | . name=&#39;tom&#39; . name.capitalize() # 맨 앞을 대문자 처리 . &#39;Tom&#39; . name.count(&#39;2&#39;) #name이라는 변수에 2 몇개?, 대문자 소문자도 구별해서 카운트함 . 0 . name.count(&#39;o&#39;) . 1 . name.split(&#39;o&#39;) # &#39;o&#39; 없애고 &#39;o&#39;기준으로 나눠줌 # 리스트 형태로 저장됨 . [&#39;t&#39;, &#39;m&#39;] . a=name.split(&#39;o&#39;) . type(a[0]) . str . type(a) . list . a[1]=&#39;o&#39; . a.append(&#39;m&#39;) # list에서 가능함 . a . [&#39;t&#39;, &#39;o&#39;, &#39;m&#39;] . # split은 str에서만 가능한가봄 # split 자체가 어떤 값을 기준으로 나눠서 list로 반환해주는 것이기 때문에 list에선 사용 X . &#39;asdasd&#39;.capitalize() . &#39;Asdasd&#39; . . 백 슬러시 다음에 심볼 적으면 심볼로 인식 | . a=&#39;i &#39;m student&#39; . a . &#34;i&#39;m student&#34; . . input(&#39;enter: &#39;) . &#39;55&#39; . a=input(&#39;enter: &#39;) . a # str으로 저장됨 . &#39;55&#39; . type(a) . str . age=int(input(&#39;enter your age: &#39;)) . age # int로 저장됨 . 564 . del age . a=1 b=3 a==b . False . a.__eq__(b) # a==b랑 동일 . False . a,b=10,134 # tuple을 의미하는 건 아님 . a와 b 교환 | . a,b=b,a . . str=1 . str . 1 . # error 발생 =&gt; 원래 내장 함수인 str이 위셀에서 변수명으로 저장됨으로써 함수기능을 상실함 . 즉 파이썬과 지원되는 함수와 동일한 변수명 사용하면 안 됨 . del str . . Container . list. tuple. set. frozenset. dictionary. . list (수정 가능) | . asd=[10,25,&#39;123&#39;,True] # 자료형 혼합 가능 . asdasd=list([10,25,&#39;123&#39;,True]) # 이 방법으로 list만들 땐 꼭 대괄호로 묶어줘야 함 . tuple (수정 불가) | . qwe=(12,22.1,&#39;qwe&#39;) . qwe . (12, 22.1, &#39;qwe&#39;) . qweqwe=tuple([1,2,3,&#39;asdasd&#39;,True]) # 대괄호로 묶어줘야함 . qweqwe . (1, 2, 3, &#39;asdasd&#39;, True) . list와 tuple은 sequence자료형 | . vip_names = [&#39;c&#39;,&#39;d&#39;,&#39;a&#39;] . vip_names[0]=&#39;랴차&#39; . vip_names . [&#39;랴차&#39;, &#39;d&#39;, &#39;a&#39;] . list는 자료 수정 가능 | 하지만 tuple은 자료 수정이 안 된다 | . slicing . my_list1=[12,123,123,123,42,14] . my_list1[0:2] #0,1번 원소 추출 . [12, 123] . my_list1 . [12, 123, 123, 123, 42, 14] . my_list1[:] # 모든 자료 . [12, 123, 123, 123, 42, 14] . my_list1[::2] # 모든 자료형태에서 2단위로 추출 . [12, 123, 42] . my_list1[:3:2] # 0,1,2원소를 2단위로 추출 . [12, 123] . my_list1 . [12, 123, 123, 123, 42, 14] . my_list1[-1] . 14 . my_list1[-5:-1] # -1값은 해당 X . [123, 123, 123, 42] . my_list1[-5] . 123 . my_list1 . [12, 123, 123, 123, 42, 14] . my_list1[-1::-1] # 뒤에서부터 가져올 땐 단위도 - 붙여줘야 함 . [14, 42, 123, 123, 123, 12] . my_list1[-1:2:-1] # 두번째 인덱스 전까지 뒤로 추출 # 시작을 -1로 해서 2로 끝났으니 마지막에 호출 단위를 -붙여서 꼭 해줘야함 # 호출단위를 안 쓰거나 플러스로 하면 아무것도 출력 안 됨 # 주의 !!! . [14, 42, 123] . my_list1 . [12, 123, 123, 123, 42, 14] . my_list1[-4:5:1] # -4와 5중 list에서 원소로서 뭐가 먼저 입력되어있는지에 따라 마지막에 -1로 출력할 것인지 1로 출력할 것인지 달라짐 # 1말고 -1로 출력하면 아무것도 출력 안 됨 . [123, 123, 42] . my_list2 = [[1,2,3,4,5],[1232]] . my_list2 . [[1, 2, 3, 4, 5], [1232]] . my_list4 = [[1,2,3,4,5], [1,2,3,4], &quot;ㅁㄴㅇㅁㄴㅇ&quot;] # 이렇게 복잡할 땐 한줄 내려서 입력해도 가능하다 . my_list4 . [[1, 2, 3, 4, 5], [1, 2, 3, 4], &#39;ㅁㄴㅇㅁㄴㅇ&#39;] . . 리스트 중첩 가능 | . my_list4[0] . [1, 2, 3, 4, 5] . my_list4[0][3] . 4 . my_list4[1][::2] . [1, 3] . my_list5 = [ [10,20,[100,200,300]], [40,50,60] ] . my_list5[0][2][2] # 리스트 중첩 후 원소 불러오기 . 300 . . &#52264;&#51060;&#51216;!!!!! . a=[1,2] b=[123,2323] . a+b . [1, 2, 123, 2323] . import warnings warnings.filterwarnings(&#39;ignore&#39;) import numpy as np np.array([1,2]) + np.array([123,2323]) . array([ 124, 2325]) . 즉 리스트는 리스트끼리 더해줘도 리스트 원소 자체의 덧셈이 아니라 리스트와 리스트의 덧셈개념으로 연결해주는 것인데 넘파이는 연결이 아니라 각 원소끼리의 합을 해줌 | 그런데 넘파이에서 차원이 맞지 않으면 작동하진 않는다. | . . a=[[1,2],[1,2,3]] . b=[[1,2,&#39;s&#39;],[1,2,3]] . a+b . [[1, 2], [1, 2, 3], [1, 2, &#39;s&#39;], [1, 2, 3]] . a*2 . [[1, 2], [1, 2, 3], [1, 2], [1, 2, 3]] . . old_a=[1,2,3] . new_a=old_a . old_a[0]=2 . new_a[0] . 2 . new_a=old_a는 같은 메모리를 공유함으로써 new_a 와 old_a 모두 동시 수정됨 | . 대책은? | . new_a=old_a.copy() . new_a[0]=1 . new_a . [1, 2, 3] . old_a . [2, 2, 3] . . extend | . a=[1,2,3] b=[2,3,4] . a+b . [1, 2, 3, 2, 3, 4] . a.extend(b) . a . [&#39;asdf&#39;, &#39;k&#39;, 2, 3, 4] . a=[1,2,3] b=[2,3,4] . a+=b . a . [1, 2, 3, 2, 3, 4] . asd=[&#39;asds&#39;,&#39;sdasd&#39;,&#39;sd&#39;] . 이 자료에 원소 추가하기 | . asd.append(&#39;e&#39;) . asd . [&#39;asds&#39;, &#39;sdasd&#39;, &#39;sd&#39;, &#39;e&#39;] . str에선 안 된다!! | . asd.remove(&#39;e&#39;) . asd . [&#39;asds&#39;, &#39;sdasd&#39;, &#39;sd&#39;] . 인덱스로 원소 지우기 -&gt; pop사용 | . asd.pop(1) # &#39;sdasd&#39;가 삭제됐음 # &#39;sdasd&#39;가 삭제됐다고 반환하면서 알려주는 이 형식도 사용할 때가 있음 . &#39;sdasd&#39; . asd . [&#39;asds&#39;, &#39;sd&#39;] . 초기화 | . asd.clear() . asd . [] . asd.insert(0,&#39;sds&#39;) . asd . [&#39;sds&#39;] . asd.index(&#39;sds&#39;) # 자리 번호 알기 . 0 . asd.count(&#39;sds&#39;) # 몇번 들어가 있는지 . 1 . a=[&#39;a&#39;,&#39;c&#39;,&#39;f&#39;,&#39;b&#39;] . a.insert(2,&#39;두번째 자리&#39;) . a . [&#39;a&#39;, &#39;c&#39;, &#39;두번째 자리&#39;, &#39;f&#39;, &#39;b&#39;] . a.sort() # 정렬중 . a # 숫자와, bool도 정렬가능 . [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;f&#39;, &#39;두번째 자리&#39;] . 지금 list a에는 원소가 다섯개 있는데 전부 자료형 str이다 . 그런데 . a=[2,&#39;False&#39;] . # 이렇게 자료형이 섞여있으면 불가능 # 지금 False가 bool형태가 아니라 str형태로 들어가있음 . asf=[True,123333,0,134] . asf.sort() . asf # 자료형이 안 섞여있으면 가능 . [0, True, 134, 123333] . qwe=[1,2,3] . qwe.reverse() . qwe . [3, 2, 1] . qwe[-1::-1] # reverse와 동일 . [1, 2, 3] . . set | . my_set1={1,2,3} . my_set2={False,5,54} . my_set3={False,5,5} . my_set3 . {False, 5} . 집합처럼 중복 원소는 하나로 처리 BUT 리스트는 중복 원소 생략 안 하고 그대로 넣어준다 . set은 인덱스를 지원하지 않음 . alist=[2,3,4,1324] . my_set32412=set(alist) . my_set32412 . {2, 3, 4, 1324} . . list에선 append와 insert였음 . my_set32412.add(2525) . my_set32412 . {2, 3, 4, 1324, 2525} . my_set32412.update([546]) . my_set32412 . {2, 3, 4, 546, 1324, 2525} . 이렇게 순서대로 들어가게 됨 | . my_set32412.discard(1324) . my_set32412 . {2, 3, 4, 546, 2525} . my_set32412.remove(2525) . my_set32412 . {2, 3, 4, 546} . 즉 discard와 remove는 동일하나 remove는 이미 없는 값을 또 삭제하려 할 때 error메세지를 보여줌 . . a={1,2,3,5} b={6,5,55,4} . a or b . {1, 2, 3, 5} . b or a . {4, 5, 6, 55} . 앞에 있는 거 출력 | . . print(bin(2)) print(bin(4)) . 0b10 0b100 . 2|4 . 6 . print(bin(2|4)) . 0b110 . 이거(이진수 처리)랑 다른 거 . . a|b . {1, 2, 3, 4, 5, 6, 55} . a.union(b) . {1, 2, 3, 4, 5, 6, 55} . b.union(a) . {1, 2, 3, 4, 5, 6, 55} . a&amp;b # 교집합 . {5} . a.intersection(b) . {5} . b.intersection(a) . {5} . a-b . {1, 2, 3} . a.difference(b) . {1, 2, 3} . b.difference(a) . {4, 6, 55} . . 이것도 원래는 이진법 처리할 때 사용되는 기호임 | 따라서 숫자를 제곱할 때는 ^이걸 사용하면 안 되고 ** 사용하던가 pow를 사용했어야 했음 | . a^b # 겹치는 거 빼고 출력 . {1, 2, 3, 4, 6, 55} . a.symmetric_difference(b) ## 겹치는 거 빼고 출력 . {1, 2, 3, 4, 6, 55} . b.symmetric_difference(a) # 겹치는 거 빼고 출력 . {1, 2, 3, 4, 6, 55} . . a={1,2,3,4,5} b={1} . b.issubset(a) #b가 a의 부분집합? . True . a.issubset(b) # a가 b의 부분집합? . False . a.issuperset(b) # a는 b를 포함? . True . b.issuperset(a)# b는 a를 포함? . False . . frozenset - 추가가 안됨, 어차피 set은 index가 없어서 수정은 안 됐으니까 수정이 안 되는 문제하곤 별개임 | . a=frozenset([1,2,3,4,5]) . b=frozenset([4,5,6,7,8]) . a|b . frozenset({1, 2, 3, 4, 5, 6, 7, 8}) . a&amp;b . frozenset({4, 5}) . # 추가 불가 # frozenset이기 때문에 . c=set([1,2,3,4]) . a&amp;c . frozenset({1, 2, 3, 4}) . . asq=[&#39;qw&#39;,&#39;qwa&#39;,&#39;qwsd&#39;] . door1_list = [&#39;qw&#39;] . door2_list = [&#39;qwa&#39;] . door1_list in asq . False . 왜 false? | . door1_list[0] . &#39;qw&#39; . door1_list[0] in asq . True . 이렇게 해야 True | . . all=set(asq) . all . {&#39;qw&#39;, &#39;qwa&#39;, &#39;qwsd&#39;} . d1=set(door1_list) . d2=set(door2_list) . d1.issubset(all) . True . d2.issubset(all) . True . d_combine=d1 |d2 . d_combine . {&#39;qw&#39;, &#39;qwa&#39;} . d_combine.issubset(all) # 부분집합? . True . all-d_combine . {&#39;qwsd&#39;} . . my_dict={&#39;a&#39;:&#39;qewqwe&#39;,&#39;b&#39;:&#39;qewe&#39;,&#39;c&#39;:&#39;qwqwe&#39;} . dic =&gt; key,value로 이루어져있다 | : 이 들어가면서 set이랑은 다름 | . type(my_dict) . dict . my_dict[&#39;c&#39;] . &#39;qwqwe&#39; . 즉 따라서 순서는 중요하지 않음 . number={&#39;1&#39;:&#39;12312123123&#39;,&#39;asas&#39;:&#39;12313&#39;,&#39;asdad&#39;:&#39;12323&#39;} . number[&#39;asas&#39;] . &#39;12313&#39; . number.get(&#39;asas&#39;) . &#39;12313&#39; . number[&#39;asas&#39;]=&#39;fucking&#39; # 자료 수정 . number . {&#39;1&#39;: &#39;12312123123&#39;, &#39;asas&#39;: &#39;fucking&#39;, &#39;asdad&#39;: &#39;12323&#39;} . number.update({&#39;1&#39;:&#39;asdasdddd&#39;}) # 자료 수정 . number . {&#39;1&#39;: &#39;asdasdddd&#39;, &#39;asas&#39;: &#39;fucking&#39;, &#39;asdad&#39;: &#39;12323&#39;} . &#39;1&#39; in number # key가 들어가있는지 안 들어가 있는지 . True . &#39;fucking&#39; in number # key가 들어가있는지 안 들어가 있는지 # 그래서 value를 물어보면 다 Fasle로 출력하네 . False . number.pop(&#39;1&#39;) # 삭제 . &#39;asdasdddd&#39; . number . {&#39;asas&#39;: &#39;fucking&#39;, &#39;asdad&#39;: &#39;12323&#39;} . number.clear() . number . {} . . alist=[1,2,3,4,5] atuple=(1,2,3,4,5) aset={1,2,3,4,5} . len(alist) # 컨테이너의 값 개수를 알 수 있음 . 5 . max(aset) . 5 . min(alist) . 1 . 6 in atuple # 값 들어가있는지 체크하기 . False . 555 not in atuple . True . . list unpacking . a=[&#39;a&#39;,23,&#39;asf&#39;] . name=a[0] . age=a[1] . lan=a[2] . 이걸 한 번에 = list unpacking | . name,age,lan=a . print(name) print(age) print(lan) . a 23 asf . 리스트 a에서 처음 원소만 자료로 받고 나머지는 그에 헤당한 자료형으로 남겨놓고 싶을 때 | . name, *rest = a . 응용하면 . *rest,name=a . name . &#39;asf&#39; . first,second,*rest=a . first . &#39;a&#39; . second . 23 . 또는 | . a . [&#39;a&#39;, 23, &#39;asf&#39;] . name, _, _ = a . _ . &#39;asf&#39; . name . &#39;a&#39; . name, *_ = a . name . &#39;a&#39; . _ . [23, &#39;asf&#39;] . underbar를 활용할 수도 있겠다. | . . a=range(0,21,2) # 20까지임, 그런데 2단위로 . np.linspace(2,20,10) . array([ 2., 4., 6., 8., 10., 12., 14., 16., 18., 20.]) . 둘이 비교해보기 | . . type(a) . range . a[2] . 4 . a.index(20) . 10 . a[10] . 20 . a[:5] . range(0, 10, 2) . a[-1] . 20 . list(range(10,51,10)) . [10, 20, 30, 40, 50] . . for i in range(5) : print(i) . 0 1 2 3 4 . for i in range(2,11,2) : print(i) . 2 4 6 8 10 . for i in range(10,2,-2) : print(i) . 10 8 6 4 . for i in range(10,1,-2) : print(i) . 10 8 6 4 2 .",
            "url": "https://rhkrehtjd.github.io/INTROpython/2021/12/22/intro.html",
            "relUrl": "/2021/12/22/intro.html",
            "date": " • Dec 22, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://rhkrehtjd.github.io/INTROpython/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  

  
  

  
      ,"page12": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://rhkrehtjd.github.io/INTROpython/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}